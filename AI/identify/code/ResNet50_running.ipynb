{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CropModels\n",
    "from CropDataset import MyDataSet,normalize_torch,normalize_05,normalize_dataset,preprocess,preprocess_hflip,preprocess_with_augmentation\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import RunningMean\n",
    "import utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASS=59\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "IMAGE_SIZE=420   # 不同模型修改不同的Size\n",
    "IMAGE_TRAIN_PRE='../data/AgriculturalDisease_trainingset/images/'\n",
    "ANNOTATION_TRAIN='../data/AgriculturalDisease_trainingset/AgriculturalDisease_train_annotations_deleteNoise.json' #是否需要剔除两类异常类\n",
    "IMAGE_VAL_PRE='../data/AgriculturalDisease_validationset/images/'\n",
    "ANNOTATION_VAL='../data/AgriculturalDisease_validationset/AgriculturalDisease_validation_annotations_deleteNoise.json' #是否需要剔除两类异常类\n",
    "date=str(datetime.date.today())\n",
    "with open(ANNOTATION_TRAIN) as datafile1:\n",
    "    trainDataFram=pd.read_json(datafile1,orient='records')\n",
    "with open(ANNOTATION_VAL) as datafile2: #first check if it's a valid json file or not\n",
    "    validateDataFram =pd.read_json(datafile2,orient='records')    \n",
    "def getmodel():\n",
    "    print('[+] loading model... ', end='', flush=True)\n",
    "    model=CropModels.resnet50_finetune(NB_CLASS)\n",
    "    model.cuda()\n",
    "    print('Done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochNum):\n",
    "    writer=SummaryWriter('log/'+date+'/ResNet50/') # 创建 /log/日期/InceptionResnet的组织形式  不同模型需要修改不同名称\n",
    "    train_dataset=MyDataSet(json_Description=ANNOTATION_TRAIN,transform=preprocess_with_augmentation(normalize_torch,IMAGE_SIZE),path_pre=IMAGE_TRAIN_PRE)\n",
    "    val_dataset=MyDataSet(json_Description=ANNOTATION_VAL,transform=preprocess(normalize_torch,IMAGE_SIZE),path_pre=IMAGE_VAL_PRE)\n",
    "    train_dataLoader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,num_workers=16,shuffle=True)\n",
    "    val_dataLoader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,num_workers=1,shuffle=False)\n",
    "    model=getmodel()\n",
    "    weight=torch.Tensor([1,3,3,3,3,4,2,3,3,3,3,3,3,3,3,3,2,3,3,3,2,3,4,2,3,1,1,3,2,2,1,3,3,1,3,2,3,3,3,3,2,1,3,2,3,3,3,1,3,3,4,4,3,2,2,3,1,1,3]).cuda()\n",
    "    criterion=nn.CrossEntropyLoss(weight=weight).cuda()\n",
    "#     lx, px = utils.predict(model,val_dataLoader)\n",
    "#     min_loss = criterion(Variable(px), Variable(lx)).item()\n",
    "    min_loss=4.1\n",
    "    print('min_loss is :%f'%(min_loss))\n",
    "    min_acc=0.80\n",
    "    patience=0\n",
    "    lr=0.0\n",
    "    momentum=0.0\n",
    "    for epoch in range(epochNum):\n",
    "        print('Epoch {}/{}'.format(epoch, epochNum - 1))\n",
    "        print('-' * 10)\n",
    "        if epoch==3:\n",
    "            lr=1e-3\n",
    "            momentum=0.9\n",
    "            print('set lr=:%f,momentum=%f'%(lr,momentum))\n",
    "        if patience==2 and lr==1e-3:\n",
    "            patience=0\n",
    "            model.load_state_dict(torch.load('../model/ResNet50/'+date+'_loss_best.pth')['state_dict'])\n",
    "            lr=lr/10\n",
    "            print('loss has increased lr divide 10 lr now is :%f'%(lr))\n",
    "        if patience==2 and lr==1e-4:\n",
    "            patience=0\n",
    "            epochNum=epoch+1\n",
    "        if epoch==0 or epoch==1 or epoch==2: #第一轮首先训练全连接层\n",
    "            lr=1e-3\n",
    "#             optimizer=torch.optim.SGD(params=model.fresh_params(),lr=lr,momentum=0.9)\n",
    "            optimizer = torch.optim.Adam(model.fresh_params(),lr = lr,amsgrad=True,weight_decay=1e-4)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(model.fresh_params(),lr = lr,amsgrad=True,weight_decay=1e-4)\n",
    "#             optimizer=torch.optim.SGD(params=model.parameters(),lr=lr,momentum=momentum)\n",
    "        running_loss = RunningMean()\n",
    "        running_corrects = RunningMean()\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_dataLoader):\n",
    "            model.train(True)\n",
    "            n_batchsize=inputs.size(0)\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            if isinstance(outputs,tuple):\n",
    "                loss=sum((criterion(o,labels)) for o in outputs)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss.update(loss.item(),1)\n",
    "            running_corrects.update(torch.sum(preds == labels.data).data,n_batchsize)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx%30==29:\n",
    "                print('[epoch:%d,batch:%d]:acc: %f,loss:%f'%(epoch,batch_idx,running_corrects.value,running_loss.value))\n",
    "                if batch_idx%300==299: \n",
    "                    niter = epoch * len(train_dataset)/BATCH_SIZE + batch_idx\n",
    "                    writer.add_scalar('Train/Acc',running_corrects.value,niter)\n",
    "                    writer.add_scalar('Train/Loss',running_loss.value,niter)\n",
    "                    lx,px=utils.predict(model,val_dataLoader)\n",
    "                    log_loss = criterion(Variable(px), Variable(lx))\n",
    "                    log_loss = log_loss.item()\n",
    "                    _, preds = torch.max(px, dim=1)\n",
    "                    accuracy = torch.mean((preds == lx).float())\n",
    "                    writer.add_scalar('Val/Acc',accuracy,niter)\n",
    "                    writer.add_scalar('Val/Loss',log_loss,niter)\n",
    "                    print('[epoch:%d,batch:%d]: val_loss:%f,val_acc:%f,val_total:%d'%(epoch,batch_idx,log_loss,accuracy,len(val_dataset)))\n",
    "        print('[epoch:%d] :acc: %f,loss:%f,lr:%f,patience:%d'%(epoch,running_corrects.value,running_loss.value,lr,patience))       \n",
    "        lx,px=utils.predict(model,val_dataLoader)\n",
    "        log_loss = criterion(Variable(px), Variable(lx))\n",
    "        log_loss = log_loss.item()\n",
    "        _, preds = torch.max(px, dim=1)\n",
    "        accuracy = torch.mean((preds == lx).float())\n",
    "        writer.add_scalar('Val/Acc',accuracy,(epoch+1) * len(train_dataset)/BATCH_SIZE)\n",
    "        writer.add_scalar('Val/Loss',log_loss,(epoch+1) * len(train_dataset)/BATCH_SIZE)\n",
    "        print('[epoch:%d]: val_loss:%f,val_acc:%f,'%(epoch,log_loss,accuracy))\n",
    "        if  log_loss < min_loss:\n",
    "            utils.snapshot('../model/', 'ResNet50', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy })          \n",
    "            patience = 0\n",
    "            min_loss=log_loss\n",
    "            print('save new model loss,now loss is ',min_loss)\n",
    "        else:\n",
    "            patience += 1\n",
    "        if accuracy>min_acc:\n",
    "            utils.snapshot('../model/', 'ResNet50', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy },key='acc') \n",
    "            min_acc=accuracy\n",
    "            print('save new model acc,now acc is ',min_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reuseTrain(path,epochNum):\n",
    "    writer=SummaryWriter('log/'+date+'/ResNet50/') # 创建 /log/日期/InceptionResnet的组织形式\n",
    "    train_dataset=MyDataSet(json_Description=ANNOTATION_TRAIN,transform=preprocess_with_augmentation(normalize_torch,IMAGE_SIZE),path_pre=IMAGE_TRAIN_PRE)\n",
    "    val_dataset=MyDataSet(json_Description=ANNOTATION_VAL,transform=preprocess(normalize_torch,IMAGE_SIZE),path_pre=IMAGE_VAL_PRE)\n",
    "    train_dataLoader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,num_workers=16,shuffle=True)\n",
    "    val_dataLoader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,num_workers=1,shuffle=False)\n",
    "    model=getmodel()\n",
    "    criterion=nn.CrossEntropyLoss().cuda()\n",
    "    modelParams=torch.load(path)\n",
    "    model.load_state_dict(modelParams['state_dict'])\n",
    "    min_loss=modelParams['val_loss']\n",
    "    print('min_loss is :%f'%(min_loss))   \n",
    "    min_acc=max(modelParams['val_correct'],0.80)\n",
    "    print('val_correct is %f'%(min_acc))\n",
    "    patience=0\n",
    "    lr=1e-2\n",
    "    momentum=0.9\n",
    "    beginepoch=modelParams['epoch']\n",
    "    for epoch in range(beginepoch,epochNum):\n",
    "        print('Epoch {}/{}'.format(epoch, epochNum - 1))\n",
    "        print('-' * 10)\n",
    "        if epoch==beginepoch+2:\n",
    "            lr=lr/10\n",
    "        if epoch==beginepoch+4:\n",
    "            lr=lr/10\n",
    "        if epoch==beginepoch+6:\n",
    "            lr=1e-2\n",
    "        if epoch==beginepoch+8:\n",
    "            lr=lr/10\n",
    "        if epoch==beginepoch+10:\n",
    "            lr=lr/10\n",
    "#         if patience==3:\n",
    "#             patience=0\n",
    "#             model.load_state_dict(torch.load('../model/ResNet50/'+date+'_loss_best.pth')['state_dict'])\n",
    "#             lr=lr/10\n",
    "\n",
    "        optimizer=torch.optim.SGD(params=model.parameters(),lr=lr,momentum=0.9)\n",
    "        print('lr now is %f'%(lr))\n",
    "        print('now patience is %d '%(patience))\n",
    "        running_loss = RunningMean()\n",
    "        running_corrects = RunningMean()\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_dataLoader):\n",
    "            model.train(True)\n",
    "            n_batchsize=inputs.size(0)\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            if isinstance(outputs,tuple):\n",
    "                loss=sum((criterion(o,labels)) for o in outputs)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss.update(loss.item(),1)\n",
    "            running_corrects.update(torch.sum(preds == labels.data).data,n_batchsize)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx%30==29:\n",
    "                print('[epoch:%d,batch:%d]:acc: %f,loss:%f'%(epoch,batch_idx,running_corrects.value,running_loss.value))\n",
    "                if batch_idx%300==299: \n",
    "                    niter = epoch * len(train_dataset)/BATCH_SIZE + batch_idx\n",
    "                    writer.add_scalar('Train/Acc',running_corrects.value,niter)\n",
    "                    writer.add_scalar('Train/Loss',running_loss.value,niter)\n",
    "                    lx,px=utils.predict(model,val_dataLoader)\n",
    "                    log_loss = criterion(Variable(px), Variable(lx))\n",
    "                    log_loss = log_loss.item()\n",
    "                    _, preds = torch.max(px, dim=1)\n",
    "                    accuracy = torch.mean((preds == lx).float())\n",
    "                    writer.add_scalar('Val/Acc',accuracy,niter)\n",
    "                    writer.add_scalar('Val/Loss',log_loss,niter)\n",
    "                    print('[epoch:%d,batch:%d]: val_loss:%f,val_acc:%f,val_total:%d'%(epoch,batch_idx,log_loss,accuracy,len(val_dataset)))\n",
    "        print('[epoch:%d] :acc: %f,loss:%f,lr:%f,patience:%d'%(epoch,running_corrects.value,running_loss.value,lr,patience))      \n",
    "        lx,px=utils.predict(model,val_dataLoader)\n",
    "        log_loss = criterion(Variable(px), Variable(lx))\n",
    "        log_loss = log_loss.item()\n",
    "        _, preds = torch.max(px, dim=1)\n",
    "        accuracy = torch.mean((preds == lx).float())\n",
    "        writer.add_scalar('Val/Acc',accuracy,(epoch+1) * len(train_dataset)/BATCH_SIZE)\n",
    "        writer.add_scalar('Val/Loss',log_loss,(epoch+1) * len(train_dataset)/BATCH_SIZE)\n",
    "        print('[epoch:%d]: val_loss:%f,val_acc:%f,'%(epoch,log_loss,accuracy))\n",
    "        if  log_loss < min_loss:\n",
    "            utils.snapshot('../model/', 'ResNet50', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy })          \n",
    "            patience = 0\n",
    "            min_loss=log_loss\n",
    "            print('save new model loss,now loss is ',min_loss)\n",
    "        else:\n",
    "            patience += 1\n",
    "        if accuracy>min_acc:\n",
    "            utils.snapshot('../model/', 'ResNet50', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy },key='acc') \n",
    "            min_acc=accuracy\n",
    "            print('save new model acc,now acc is ',min_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainWithRawData(path,epochNum):\n",
    "    train_dataset=MyDataSet(json_Description=ANNOTATION_TRAIN,transform=preprocess(normalize_torch,IMAGE_SIZE),path_pre=IMAGE_TRAIN_PRE)\n",
    "    val_dataset=MyDataSet(json_Description=ANNOTATION_VAL,transform=preprocess(normalize_torch,IMAGE_SIZE),path_pre=IMAGE_VAL_PRE)\n",
    "    train_dataLoader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,num_workers=16,shuffle=True)\n",
    "    val_dataLoader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,num_workers=1,shuffle=False)\n",
    "    model=getmodel()\n",
    "    criterion=nn.CrossEntropyLoss().cuda()\n",
    "    modelParams=torch.load(path)\n",
    "    model.load_state_dict(modelParams['state_dict'])\n",
    "    min_loss=modelParams['val_loss']\n",
    "    print('min_loss is :%f'%(min_loss))\n",
    "    print('val_correct is %f'%(modelParams['val_correct']))\n",
    "    min_acc=max(modelParams['val_correct'],0.81)\n",
    "    optinizerSave=modelParams['optimizer']\n",
    "    patience=0\n",
    "    lr=1e-4\n",
    "    momentum=0.9\n",
    "    beginepoch=modelParams['epoch']\n",
    "    for epoch in range(beginepoch,epochNum):\n",
    "        print('Epoch {}/{}'.format(epoch, epochNum - 1))\n",
    "        print('-' * 10)\n",
    "        if patience==3:\n",
    "            patience=0\n",
    "            model.load_state_dict(torch.load('../model/ResNet50/'+date+'_loss_best.pth')['state_dict'])\n",
    "            lr=lr/5\n",
    "            print('loss has increased lr divide 10 lr now is :%f'%(lr))\n",
    "            optimizer=torch.optim.SGD(params=model.parameters(),lr=lr,momentum=0.9)\n",
    "#            optimizer = torch.optim.Adam(model.fresh_params(),lr = lr,amsgrad=True,weight_decay=1e-4)\n",
    "        \n",
    "        else:\n",
    "            optimizer=torch.optim.SGD(params=model.parameters(),lr=lr,momentum=0.9)\n",
    " #           optimizer = torch.optim.Adam(model.parameters(),lr = lr,amsgrad=True,weight_decay=1e-4)\n",
    "        running_loss = RunningMean()\n",
    "        running_corrects = RunningMean()\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_dataLoader):\n",
    "            model.train(True)\n",
    "            n_batchsize=inputs.size(0)\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            if isinstance(outputs,tuple):\n",
    "                loss=sum((criterion(o,labels)) for o in outputs)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss.update(loss.item(),1)\n",
    "            running_corrects.update(torch.sum(preds == labels.data).data,n_batchsize)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx%30==29:\n",
    "                print('[epoch:%d,batch:%d]:acc: %f,loss:%f'%(epoch,batch_idx,running_corrects.value,running_loss.value))\n",
    "                if batch_idx%300==299: \n",
    "                    niter = epoch * len(train_dataset)/BATCH_SIZE + batch_idx\n",
    "                    lx,px=utils.predict(model,val_dataLoader)\n",
    "                    log_loss = criterion(Variable(px), Variable(lx))\n",
    "                    log_loss = log_loss.item()\n",
    "                    _, preds = torch.max(px, dim=1)\n",
    "                    accuracy = torch.mean((preds == lx).float())\n",
    "                    print('[epoch:%d,batch:%d]: val_loss:%f,val_acc:%f,val_total:%d'%(epoch,batch_idx,log_loss,accuracy,len(val_dataset)))\n",
    "                    if  log_loss < min_loss:\n",
    "                        utils.snapshot('../model/', 'ResNet50', {\n",
    "                               'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optimizer': optimizer.state_dict(),\n",
    "                               'val_loss': log_loss,\n",
    "                               'val_correct':accuracy })          \n",
    "\n",
    "                        min_loss=log_loss\n",
    "                        patience=0\n",
    "                        print('save new model loss,now loss is ',min_loss)\n",
    "\n",
    "                    if accuracy>min_acc:\n",
    "                        utils.snapshot('../model/', 'ResNet50', {\n",
    "                               'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optimizer': optimizer.state_dict(),\n",
    "                               'val_loss': log_loss,\n",
    "                               'val_correct':accuracy },key='acc') \n",
    "                        min_acc=accuracy\n",
    "                        print('save new model acc,now acc is ',min_acc)\n",
    "        print('[epoch:%d] :acc: %f,loss:%f,lr:%f,patience:%d'%(epoch,running_corrects.value,running_loss.value,lr,patience))         \n",
    "        lx,px=utils.predict(model,val_dataLoader)\n",
    "        log_loss = criterion(Variable(px), Variable(lx))\n",
    "        log_loss = log_loss.item()\n",
    "        _, preds = torch.max(px, dim=1)\n",
    "        accuracy = torch.mean((preds == lx).float())\n",
    "        print('[epoch:%d]: val_loss:%f,val_acc:%f,'%(epoch,log_loss,accuracy))\n",
    "        if  log_loss < min_loss:\n",
    "            utils.snapshot('../model/', 'ResNet50', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy })          \n",
    "            patience = 0\n",
    "            min_loss=log_loss\n",
    "            print('save new model loss,now loss is ',min_loss)\n",
    "        else:\n",
    "            patience += 1\n",
    "        if accuracy>min_acc:\n",
    "            utils.snapshot('../model/', 'ResNet50', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy },key='acc') \n",
    "            min_acc=accuracy\n",
    "            print('save new model acc,now acc is ',min_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model... Done\n",
      "min_loss is :4.100000\n",
      "Epoch 0/59\n",
      "----------\n",
      "[epoch:0,batch:29]:acc: 0.155208,loss:5.350667\n",
      "[epoch:0,batch:59]:acc: 0.251563,loss:4.279010\n",
      "[epoch:0,batch:89]:acc: 0.323264,loss:3.730664\n",
      "[epoch:0,batch:119]:acc: 0.364583,loss:3.373821\n",
      "[epoch:0,batch:149]:acc: 0.388125,loss:3.179203\n",
      "[epoch:0,batch:179]:acc: 0.409896,loss:3.001765\n",
      "[epoch:0,batch:209]:acc: 0.426339,loss:2.867028\n",
      "[epoch:0,batch:239]:acc: 0.442188,loss:2.761445\n",
      "[epoch:0,batch:269]:acc: 0.458218,loss:2.658466\n",
      "[epoch:0,batch:299]:acc: 0.469792,loss:2.577482\n",
      "[epoch:0,batch:299]: val_loss:1.373625,val_acc:0.661599,val_total:4539\n",
      "[epoch:0,batch:329]:acc: 0.482008,loss:2.498274\n",
      "[epoch:0,batch:359]:acc: 0.491233,loss:2.436621\n",
      "[epoch:0,batch:389]:acc: 0.501522,loss:2.369601\n",
      "[epoch:0,batch:419]:acc: 0.507887,loss:2.318837\n",
      "[epoch:0,batch:449]:acc: 0.511389,loss:2.287441\n",
      "[epoch:0,batch:479]:acc: 0.518424,loss:2.245875\n",
      "[epoch:0,batch:509]:acc: 0.523039,loss:2.208880\n",
      "[epoch:0,batch:539]:acc: 0.527488,loss:2.192825\n",
      "[epoch:0,batch:569]:acc: 0.530318,loss:2.172802\n",
      "[epoch:0,batch:599]:acc: 0.534479,loss:2.144314\n",
      "[epoch:0,batch:599]: val_loss:1.142386,val_acc:0.693545,val_total:4539\n",
      "[epoch:0,batch:629]:acc: 0.538046,loss:2.121411\n",
      "[epoch:0,batch:659]:acc: 0.541098,loss:2.104306\n",
      "[epoch:0,batch:689]:acc: 0.545380,loss:2.080746\n",
      "[epoch:0,batch:719]:acc: 0.548958,loss:2.054175\n",
      "[epoch:0,batch:749]:acc: 0.552167,loss:2.041660\n",
      "[epoch:0,batch:779]:acc: 0.554768,loss:2.020775\n",
      "[epoch:0,batch:809]:acc: 0.557870,loss:2.005297\n",
      "[epoch:0,batch:839]:acc: 0.560193,loss:1.988022\n",
      "[epoch:0,batch:869]:acc: 0.563254,loss:1.969426\n",
      "[epoch:0,batch:899]:acc: 0.565660,loss:1.958554\n",
      "[epoch:0,batch:899]: val_loss:1.092578,val_acc:0.706764,val_total:4539\n",
      "[epoch:0,batch:929]:acc: 0.569321,loss:1.939526\n",
      "[epoch:0,batch:959]:acc: 0.570638,loss:1.931695\n",
      "[epoch:0,batch:989]:acc: 0.572885,loss:1.922541\n",
      "[epoch:0] :acc: 0.573163,loss:1.920192,lr:0.001000,patience:0\n",
      "[epoch:0]: val_loss:1.345611,val_acc:0.658956,\n",
      "save new model loss,now loss is  1.3456107378005981\n",
      "Epoch 1/59\n",
      "----------\n",
      "[epoch:1,batch:29]:acc: 0.575000,loss:2.303735\n",
      "[epoch:1,batch:59]:acc: 0.623958,loss:1.877172\n",
      "[epoch:1,batch:89]:acc: 0.628125,loss:1.742409\n",
      "[epoch:1,batch:119]:acc: 0.626302,loss:1.759838\n",
      "[epoch:1,batch:149]:acc: 0.622083,loss:1.806411\n",
      "[epoch:1,batch:179]:acc: 0.625521,loss:1.778370\n",
      "[epoch:1,batch:209]:acc: 0.630952,loss:1.736797\n",
      "[epoch:1,batch:239]:acc: 0.634766,loss:1.703362\n",
      "[epoch:1,batch:269]:acc: 0.636458,loss:1.700966\n",
      "[epoch:1,batch:299]:acc: 0.637396,loss:1.685956\n",
      "[epoch:1,batch:299]: val_loss:1.386461,val_acc:0.681428,val_total:4539\n",
      "[epoch:1,batch:329]:acc: 0.636364,loss:1.692750\n",
      "[epoch:1,batch:359]:acc: 0.639757,loss:1.663691\n",
      "[epoch:1,batch:389]:acc: 0.639824,loss:1.650332\n",
      "[epoch:1,batch:419]:acc: 0.640625,loss:1.642476\n",
      "[epoch:1,batch:449]:acc: 0.637639,loss:1.661917\n",
      "[epoch:1,batch:479]:acc: 0.638607,loss:1.664308\n",
      "[epoch:1,batch:509]:acc: 0.639583,loss:1.662003\n",
      "[epoch:1,batch:539]:acc: 0.640972,loss:1.655004\n",
      "[epoch:1,batch:569]:acc: 0.641831,loss:1.650681\n",
      "[epoch:1,batch:599]:acc: 0.642031,loss:1.662984\n",
      "[epoch:1,batch:599]: val_loss:1.206844,val_acc:0.722626,val_total:4539\n",
      "[epoch:1,batch:629]:acc: 0.642262,loss:1.669948\n",
      "[epoch:1,batch:659]:acc: 0.641335,loss:1.681028\n",
      "[epoch:1,batch:689]:acc: 0.642844,loss:1.673754\n",
      "[epoch:1,batch:719]:acc: 0.644401,loss:1.669380\n",
      "[epoch:1,batch:749]:acc: 0.644458,loss:1.679086\n",
      "[epoch:1,batch:779]:acc: 0.644231,loss:1.689216\n",
      "[epoch:1,batch:809]:acc: 0.644136,loss:1.691163\n",
      "[epoch:1,batch:839]:acc: 0.644606,loss:1.684388\n",
      "[epoch:1,batch:869]:acc: 0.644899,loss:1.682198\n",
      "[epoch:1,batch:899]:acc: 0.646007,loss:1.681953\n",
      "[epoch:1,batch:899]: val_loss:1.465170,val_acc:0.714034,val_total:4539\n",
      "[epoch:1,batch:929]:acc: 0.646741,loss:1.682074\n",
      "[epoch:1,batch:959]:acc: 0.646940,loss:1.688849\n",
      "[epoch:1,batch:989]:acc: 0.647633,loss:1.689943\n",
      "[epoch:1] :acc: 0.647571,loss:1.690324,lr:0.001000,patience:0\n",
      "[epoch:1]: val_loss:1.588834,val_acc:0.673056,\n",
      "Epoch 2/59\n",
      "----------\n",
      "[epoch:2,batch:29]:acc: 0.593750,loss:2.215937\n",
      "[epoch:2,batch:59]:acc: 0.635938,loss:1.847309\n",
      "[epoch:2,batch:89]:acc: 0.651042,loss:1.796240\n",
      "[epoch:2,batch:119]:acc: 0.660937,loss:1.708222\n",
      "[epoch:2,batch:149]:acc: 0.661458,loss:1.665945\n",
      "[epoch:2,batch:179]:acc: 0.663889,loss:1.630244\n",
      "[epoch:2,batch:209]:acc: 0.664137,loss:1.628299\n",
      "[epoch:2,batch:239]:acc: 0.663542,loss:1.628834\n",
      "[epoch:2,batch:269]:acc: 0.669213,loss:1.591769\n",
      "[epoch:2,batch:299]:acc: 0.671979,loss:1.575812\n",
      "[epoch:2,batch:299]: val_loss:1.190670,val_acc:0.749725,val_total:4539\n",
      "[epoch:2,batch:329]:acc: 0.672443,loss:1.563187\n",
      "[epoch:2,batch:359]:acc: 0.671181,loss:1.562538\n",
      "[epoch:2,batch:389]:acc: 0.673317,loss:1.564231\n",
      "[epoch:2,batch:419]:acc: 0.673363,loss:1.568348\n",
      "[epoch:2,batch:449]:acc: 0.673194,loss:1.571838\n",
      "[epoch:2,batch:479]:acc: 0.672786,loss:1.573173\n",
      "[epoch:2,batch:509]:acc: 0.673591,loss:1.584937\n",
      "[epoch:2,batch:539]:acc: 0.673785,loss:1.586809\n",
      "[epoch:2,batch:569]:acc: 0.673355,loss:1.593235\n",
      "[epoch:2,batch:599]:acc: 0.674479,loss:1.594968\n",
      "[epoch:2,batch:599]: val_loss:1.339125,val_acc:0.719982,val_total:4539\n",
      "[epoch:2,batch:629]:acc: 0.674355,loss:1.595930\n",
      "[epoch:2,batch:659]:acc: 0.672869,loss:1.609000\n",
      "[epoch:2,batch:689]:acc: 0.673641,loss:1.600746\n",
      "[epoch:2,batch:719]:acc: 0.673003,loss:1.605730\n",
      "[epoch:2,batch:749]:acc: 0.673958,loss:1.607804\n",
      "[epoch:2,batch:779]:acc: 0.675200,loss:1.595895\n",
      "[epoch:2,batch:809]:acc: 0.675231,loss:1.597464\n",
      "[epoch:2,batch:839]:acc: 0.675521,loss:1.603588\n",
      "[epoch:2,batch:869]:acc: 0.675251,loss:1.605773\n",
      "[epoch:2,batch:899]:acc: 0.674965,loss:1.605293\n",
      "[epoch:2,batch:899]: val_loss:1.176534,val_acc:0.736065,val_total:4539\n",
      "[epoch:2,batch:929]:acc: 0.674597,loss:1.610917\n",
      "[epoch:2,batch:959]:acc: 0.674837,loss:1.610970\n",
      "[epoch:2,batch:989]:acc: 0.675568,loss:1.607352\n",
      "[epoch:2] :acc: 0.675474,loss:1.607621,lr:0.001000,patience:1\n",
      "[epoch:2]: val_loss:1.364052,val_acc:0.692223,\n",
      "Epoch 3/59\n",
      "----------\n",
      "set lr=:0.001000,momentum=0.900000\n",
      "loss has increased lr divide 10 lr now is :0.000100\n",
      "[epoch:3,batch:29]:acc: 0.736458,loss:0.973920\n",
      "[epoch:3,batch:59]:acc: 0.749479,loss:0.898690\n",
      "[epoch:3,batch:89]:acc: 0.750694,loss:0.880075\n",
      "[epoch:3,batch:119]:acc: 0.745573,loss:0.896600\n",
      "[epoch:3,batch:149]:acc: 0.742708,loss:0.901716\n",
      "[epoch:3,batch:179]:acc: 0.741319,loss:0.896828\n",
      "[epoch:3,batch:209]:acc: 0.740179,loss:0.883942\n",
      "[epoch:3,batch:239]:acc: 0.737760,loss:0.872556\n",
      "[epoch:3,batch:269]:acc: 0.734954,loss:0.870053\n",
      "[epoch:3,batch:299]:acc: 0.734375,loss:0.862526\n",
      "[epoch:3,batch:299]: val_loss:0.759200,val_acc:0.743336,val_total:4539\n",
      "[epoch:3,batch:329]:acc: 0.734091,loss:0.856456\n",
      "[epoch:3,batch:359]:acc: 0.737500,loss:0.845978\n",
      "[epoch:3,batch:389]:acc: 0.739904,loss:0.833807\n",
      "[epoch:3,batch:419]:acc: 0.742188,loss:0.826175\n",
      "[epoch:3,batch:449]:acc: 0.742639,loss:0.823570\n",
      "[epoch:3,batch:479]:acc: 0.742383,loss:0.819280\n",
      "[epoch:3,batch:509]:acc: 0.743934,loss:0.812901\n",
      "[epoch:3,batch:539]:acc: 0.745023,loss:0.808730\n",
      "[epoch:3,batch:569]:acc: 0.744298,loss:0.810155\n",
      "[epoch:3,batch:599]:acc: 0.744375,loss:0.810995\n",
      "[epoch:3,batch:599]: val_loss:0.740296,val_acc:0.758537,val_total:4539\n",
      "[epoch:3,batch:629]:acc: 0.744742,loss:0.808294\n",
      "[epoch:3,batch:659]:acc: 0.744792,loss:0.806968\n",
      "[epoch:3,batch:689]:acc: 0.745018,loss:0.804882\n",
      "[epoch:3,batch:719]:acc: 0.744835,loss:0.803974\n",
      "[epoch:3,batch:749]:acc: 0.745500,loss:0.800091\n",
      "[epoch:3,batch:779]:acc: 0.746354,loss:0.799908\n",
      "[epoch:3,batch:809]:acc: 0.746721,loss:0.798032\n",
      "[epoch:3,batch:839]:acc: 0.747842,loss:0.795641\n",
      "[epoch:3,batch:869]:acc: 0.747737,loss:0.796394\n",
      "[epoch:3,batch:899]:acc: 0.748160,loss:0.793818\n",
      "[epoch:3,batch:899]: val_loss:0.718004,val_acc:0.754351,val_total:4539\n",
      "[epoch:3,batch:929]:acc: 0.748387,loss:0.790229\n",
      "[epoch:3,batch:959]:acc: 0.749089,loss:0.787403\n",
      "[epoch:3,batch:989]:acc: 0.749590,loss:0.785432\n",
      "[epoch:3] :acc: 0.749724,loss:0.784692,lr:0.000100,patience:0\n",
      "[epoch:3]: val_loss:0.734241,val_acc:0.758317,\n",
      "save new model loss,now loss is  0.7342405319213867\n",
      "Epoch 4/59\n",
      "----------\n",
      "[epoch:4,batch:29]:acc: 0.750000,loss:0.816706\n",
      "[epoch:4,batch:59]:acc: 0.759896,loss:0.773623\n",
      "[epoch:4,batch:89]:acc: 0.750000,loss:0.781413\n",
      "[epoch:4,batch:119]:acc: 0.751823,loss:0.759357\n",
      "[epoch:4,batch:149]:acc: 0.751667,loss:0.760814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:4,batch:179]:acc: 0.751736,loss:0.767133\n",
      "[epoch:4,batch:209]:acc: 0.748810,loss:0.769497\n",
      "[epoch:4,batch:239]:acc: 0.748828,loss:0.766935\n",
      "[epoch:4,batch:269]:acc: 0.750926,loss:0.752116\n",
      "[epoch:4,batch:299]:acc: 0.752604,loss:0.741542\n",
      "[epoch:4,batch:299]: val_loss:0.706182,val_acc:0.762723,val_total:4539\n",
      "[epoch:4,batch:329]:acc: 0.751326,loss:0.739805\n",
      "[epoch:4,batch:359]:acc: 0.752604,loss:0.735142\n",
      "[epoch:4,batch:389]:acc: 0.753205,loss:0.736788\n",
      "[epoch:4,batch:419]:acc: 0.752753,loss:0.736266\n",
      "[epoch:4,batch:449]:acc: 0.752153,loss:0.736209\n",
      "[epoch:4,batch:479]:acc: 0.753060,loss:0.728949\n",
      "[epoch:4,batch:509]:acc: 0.752880,loss:0.729822\n",
      "[epoch:4,batch:539]:acc: 0.752141,loss:0.732412\n",
      "[epoch:4,batch:569]:acc: 0.752632,loss:0.731930\n",
      "[epoch:4,batch:599]:acc: 0.752552,loss:0.732217\n",
      "[epoch:4,batch:599]: val_loss:0.692234,val_acc:0.771095,val_total:4539\n",
      "[epoch:4,batch:629]:acc: 0.753423,loss:0.729741\n",
      "[epoch:4,batch:659]:acc: 0.754498,loss:0.729474\n",
      "[epoch:4,batch:689]:acc: 0.754710,loss:0.727302\n",
      "[epoch:4,batch:719]:acc: 0.755035,loss:0.726040\n",
      "[epoch:4,batch:749]:acc: 0.756417,loss:0.722427\n",
      "[epoch:4,batch:779]:acc: 0.756611,loss:0.722343\n",
      "[epoch:4,batch:809]:acc: 0.757215,loss:0.721899\n",
      "[epoch:4,batch:839]:acc: 0.757440,loss:0.723279\n",
      "[epoch:4,batch:869]:acc: 0.757256,loss:0.722947\n",
      "[epoch:4,batch:899]:acc: 0.758021,loss:0.720091\n",
      "[epoch:4,batch:899]: val_loss:0.646783,val_acc:0.777925,val_total:4539\n",
      "[epoch:4,batch:929]:acc: 0.758199,loss:0.718684\n",
      "[epoch:4,batch:959]:acc: 0.758171,loss:0.719642\n",
      "[epoch:4,batch:989]:acc: 0.757891,loss:0.720622\n",
      "[epoch:4] :acc: 0.757859,loss:0.720281,lr:0.000100,patience:0\n",
      "[epoch:4]: val_loss:0.674738,val_acc:0.769553,\n",
      "save new model loss,now loss is  0.6747382283210754\n",
      "Epoch 5/59\n",
      "----------\n",
      "[epoch:5,batch:29]:acc: 0.773958,loss:0.730752\n",
      "[epoch:5,batch:59]:acc: 0.763542,loss:0.741610\n",
      "[epoch:5,batch:89]:acc: 0.763889,loss:0.738127\n",
      "[epoch:5,batch:119]:acc: 0.766406,loss:0.722673\n",
      "[epoch:5,batch:149]:acc: 0.768542,loss:0.708109\n",
      "[epoch:5,batch:179]:acc: 0.769792,loss:0.702112\n",
      "[epoch:5,batch:209]:acc: 0.766667,loss:0.704003\n",
      "[epoch:5,batch:239]:acc: 0.766927,loss:0.708196\n",
      "[epoch:5,batch:269]:acc: 0.767593,loss:0.703333\n",
      "[epoch:5,batch:299]:acc: 0.767396,loss:0.698490\n",
      "[epoch:5,batch:299]: val_loss:0.640160,val_acc:0.784975,val_total:4539\n",
      "[epoch:5,batch:329]:acc: 0.767424,loss:0.698339\n",
      "[epoch:5,batch:359]:acc: 0.766927,loss:0.697586\n",
      "[epoch:5,batch:389]:acc: 0.766667,loss:0.698300\n",
      "[epoch:5,batch:419]:acc: 0.766443,loss:0.699239\n",
      "[epoch:5,batch:449]:acc: 0.766250,loss:0.699651\n",
      "[epoch:5,batch:479]:acc: 0.765690,loss:0.698852\n",
      "[epoch:5,batch:509]:acc: 0.765319,loss:0.700673\n",
      "[epoch:5,batch:539]:acc: 0.766377,loss:0.697669\n",
      "[epoch:5,batch:569]:acc: 0.766776,loss:0.696726\n",
      "[epoch:5,batch:599]:acc: 0.766667,loss:0.694495\n",
      "[epoch:5,batch:599]: val_loss:0.660269,val_acc:0.775061,val_total:4539\n",
      "[epoch:5,batch:629]:acc: 0.765327,loss:0.696790\n",
      "[epoch:5,batch:659]:acc: 0.765625,loss:0.695096\n",
      "[epoch:5,batch:689]:acc: 0.765806,loss:0.694500\n",
      "[epoch:5,batch:719]:acc: 0.766536,loss:0.691098\n",
      "[epoch:5,batch:749]:acc: 0.766500,loss:0.690951\n",
      "[epoch:5,batch:779]:acc: 0.766386,loss:0.690425\n",
      "[epoch:5,batch:809]:acc: 0.766204,loss:0.691493\n",
      "[epoch:5,batch:839]:acc: 0.765699,loss:0.692303\n",
      "[epoch:5,batch:869]:acc: 0.765338,loss:0.692918\n",
      "[epoch:5,batch:899]:acc: 0.766250,loss:0.692738\n",
      "[epoch:5,batch:899]: val_loss:0.694104,val_acc:0.769332,val_total:4539\n",
      "[epoch:5,batch:929]:acc: 0.766599,loss:0.691676\n",
      "[epoch:5,batch:959]:acc: 0.766016,loss:0.693843\n",
      "[epoch:5,batch:989]:acc: 0.766067,loss:0.694046\n",
      "[epoch:5] :acc: 0.766088,loss:0.694187,lr:0.000100,patience:0\n",
      "[epoch:5]: val_loss:0.627004,val_acc:0.781450,\n",
      "save new model loss,now loss is  0.6270038485527039\n",
      "Epoch 6/59\n",
      "----------\n",
      "[epoch:6,batch:29]:acc: 0.760417,loss:0.739631\n",
      "[epoch:6,batch:59]:acc: 0.748958,loss:0.722822\n",
      "[epoch:6,batch:89]:acc: 0.751042,loss:0.722327\n",
      "[epoch:6,batch:119]:acc: 0.749219,loss:0.717525\n",
      "[epoch:6,batch:149]:acc: 0.755000,loss:0.706295\n",
      "[epoch:6,batch:179]:acc: 0.754687,loss:0.708751\n",
      "[epoch:6,batch:209]:acc: 0.757738,loss:0.704931\n",
      "[epoch:6,batch:239]:acc: 0.757292,loss:0.706801\n",
      "[epoch:6,batch:269]:acc: 0.757176,loss:0.703542\n",
      "[epoch:6,batch:299]:acc: 0.757917,loss:0.703906\n",
      "[epoch:6,batch:299]: val_loss:0.624626,val_acc:0.789381,val_total:4539\n",
      "[epoch:6,batch:329]:acc: 0.761080,loss:0.695494\n",
      "[epoch:6,batch:359]:acc: 0.761458,loss:0.691067\n",
      "[epoch:6,batch:389]:acc: 0.762260,loss:0.685454\n",
      "[epoch:6,batch:419]:acc: 0.763914,loss:0.682333\n",
      "[epoch:6,batch:449]:acc: 0.763333,loss:0.679964\n",
      "[epoch:6,batch:479]:acc: 0.764193,loss:0.679195\n",
      "[epoch:6,batch:509]:acc: 0.764032,loss:0.677540\n",
      "[epoch:6,batch:539]:acc: 0.765336,loss:0.673812\n",
      "[epoch:6,batch:569]:acc: 0.765844,loss:0.672871\n",
      "[epoch:6,batch:599]:acc: 0.766250,loss:0.670256\n",
      "[epoch:6,batch:599]: val_loss:0.682292,val_acc:0.774400,val_total:4539\n",
      "[epoch:6,batch:629]:acc: 0.767014,loss:0.669160\n",
      "[epoch:6,batch:659]:acc: 0.767282,loss:0.667929\n",
      "[epoch:6,batch:689]:acc: 0.767527,loss:0.665588\n",
      "[epoch:6,batch:719]:acc: 0.769010,loss:0.663290\n",
      "[epoch:6,batch:749]:acc: 0.770375,loss:0.659685\n",
      "[epoch:6,batch:779]:acc: 0.770232,loss:0.659019\n",
      "[epoch:6,batch:809]:acc: 0.770640,loss:0.659567\n",
      "[epoch:6,batch:839]:acc: 0.770610,loss:0.661514\n",
      "[epoch:6,batch:869]:acc: 0.770366,loss:0.663513\n",
      "[epoch:6,batch:899]:acc: 0.769583,loss:0.665515\n",
      "[epoch:6,batch:899]: val_loss:0.633256,val_acc:0.778586,val_total:4539\n",
      "[epoch:6,batch:929]:acc: 0.768884,loss:0.665603\n",
      "[epoch:6,batch:959]:acc: 0.769108,loss:0.665561\n",
      "[epoch:6,batch:989]:acc: 0.768971,loss:0.666846\n",
      "[epoch:6] :acc: 0.769020,loss:0.666633,lr:0.000100,patience:0\n",
      "[epoch:6]: val_loss:0.633885,val_acc:0.769773,\n",
      "Epoch 7/59\n",
      "----------\n",
      "[epoch:7,batch:29]:acc: 0.763542,loss:0.660589\n",
      "[epoch:7,batch:59]:acc: 0.761458,loss:0.666875\n",
      "[epoch:7,batch:89]:acc: 0.760069,loss:0.678491\n",
      "[epoch:7,batch:119]:acc: 0.766927,loss:0.675628\n",
      "[epoch:7,batch:149]:acc: 0.764583,loss:0.683128\n",
      "[epoch:7,batch:179]:acc: 0.769444,loss:0.672936\n",
      "[epoch:7,batch:209]:acc: 0.771577,loss:0.662539\n",
      "[epoch:7,batch:239]:acc: 0.773698,loss:0.652787\n",
      "[epoch:7,batch:269]:acc: 0.773611,loss:0.651445\n",
      "[epoch:7,batch:299]:acc: 0.771563,loss:0.658925\n",
      "[epoch:7,batch:299]: val_loss:0.623297,val_acc:0.784975,val_total:4539\n",
      "[epoch:7,batch:329]:acc: 0.770833,loss:0.661881\n",
      "[epoch:7,batch:359]:acc: 0.771701,loss:0.659741\n",
      "[epoch:7,batch:389]:acc: 0.772756,loss:0.658389\n",
      "[epoch:7,batch:419]:acc: 0.772470,loss:0.658582\n",
      "[epoch:7,batch:449]:acc: 0.772361,loss:0.660068\n",
      "[epoch:7,batch:479]:acc: 0.772331,loss:0.657396\n",
      "[epoch:7,batch:509]:acc: 0.772243,loss:0.654601\n",
      "[epoch:7,batch:539]:acc: 0.771470,loss:0.656408\n",
      "[epoch:7,batch:569]:acc: 0.771327,loss:0.656642\n",
      "[epoch:7,batch:599]:acc: 0.771042,loss:0.656990\n",
      "[epoch:7,batch:599]: val_loss:0.617260,val_acc:0.790262,val_total:4539\n",
      "[epoch:7,batch:629]:acc: 0.772917,loss:0.653671\n",
      "[epoch:7,batch:659]:acc: 0.773343,loss:0.654027\n",
      "[epoch:7,batch:689]:acc: 0.774457,loss:0.649754\n",
      "[epoch:7,batch:719]:acc: 0.774306,loss:0.649770\n",
      "[epoch:7,batch:749]:acc: 0.774958,loss:0.647858\n",
      "[epoch:7,batch:779]:acc: 0.775080,loss:0.646786\n",
      "[epoch:7,batch:809]:acc: 0.775270,loss:0.646328\n",
      "[epoch:7,batch:839]:acc: 0.774516,loss:0.648909\n",
      "[epoch:7,batch:869]:acc: 0.774318,loss:0.649277\n",
      "[epoch:7,batch:899]:acc: 0.774583,loss:0.649738\n",
      "[epoch:7,batch:899]: val_loss:0.606009,val_acc:0.781450,val_total:4539\n",
      "[epoch:7,batch:929]:acc: 0.774429,loss:0.648377\n",
      "[epoch:7,batch:959]:acc: 0.774284,loss:0.649637\n",
      "[epoch:7,batch:989]:acc: 0.774148,loss:0.648348\n",
      "[epoch:7] :acc: 0.774064,loss:0.649173,lr:0.000100,patience:1\n",
      "[epoch:7]: val_loss:0.608214,val_acc:0.787398,\n",
      "save new model loss,now loss is  0.6082144975662231\n",
      "Epoch 8/59\n",
      "----------\n",
      "[epoch:8,batch:29]:acc: 0.780208,loss:0.623640\n",
      "[epoch:8,batch:59]:acc: 0.785417,loss:0.629525\n",
      "[epoch:8,batch:89]:acc: 0.782986,loss:0.635431\n",
      "[epoch:8,batch:119]:acc: 0.779427,loss:0.644445\n",
      "[epoch:8,batch:149]:acc: 0.780208,loss:0.639974\n",
      "[epoch:8,batch:179]:acc: 0.782118,loss:0.635985\n",
      "[epoch:8,batch:209]:acc: 0.783631,loss:0.632731\n",
      "[epoch:8,batch:239]:acc: 0.786068,loss:0.627503\n",
      "[epoch:8,batch:269]:acc: 0.785880,loss:0.625557\n",
      "[epoch:8,batch:299]:acc: 0.786563,loss:0.622730\n",
      "[epoch:8,batch:299]: val_loss:0.601957,val_acc:0.788500,val_total:4539\n",
      "[epoch:8,batch:329]:acc: 0.784280,loss:0.623686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:8,batch:359]:acc: 0.782899,loss:0.628745\n",
      "[epoch:8,batch:389]:acc: 0.779968,loss:0.631779\n",
      "[epoch:8,batch:419]:acc: 0.780432,loss:0.631499\n",
      "[epoch:8,batch:449]:acc: 0.779931,loss:0.629298\n",
      "[epoch:8,batch:479]:acc: 0.779818,loss:0.627263\n",
      "[epoch:8,batch:509]:acc: 0.780331,loss:0.629673\n",
      "[epoch:8,batch:539]:acc: 0.778935,loss:0.631314\n",
      "[epoch:8,batch:569]:acc: 0.778783,loss:0.631803\n",
      "[epoch:8,batch:599]:acc: 0.779635,loss:0.629587\n",
      "[epoch:8,batch:599]: val_loss:0.600566,val_acc:0.788500,val_total:4539\n",
      "[epoch:8,batch:629]:acc: 0.780060,loss:0.625765\n",
      "[epoch:8,batch:659]:acc: 0.780161,loss:0.627323\n",
      "[epoch:8,batch:689]:acc: 0.780344,loss:0.627738\n",
      "[epoch:8,batch:719]:acc: 0.779861,loss:0.630321\n",
      "[epoch:8,batch:749]:acc: 0.779167,loss:0.630839\n",
      "[epoch:8,batch:779]:acc: 0.778245,loss:0.631288\n",
      "[epoch:8,batch:809]:acc: 0.777431,loss:0.631725\n",
      "[epoch:8,batch:839]:acc: 0.778088,loss:0.630356\n",
      "[epoch:8,batch:869]:acc: 0.777227,loss:0.633833\n",
      "[epoch:8,batch:899]:acc: 0.776632,loss:0.634301\n",
      "[epoch:8,batch:899]: val_loss:0.632508,val_acc:0.783873,val_total:4539\n",
      "[epoch:8,batch:929]:acc: 0.776714,loss:0.634931\n",
      "[epoch:8,batch:959]:acc: 0.777083,loss:0.633174\n",
      "[epoch:8,batch:989]:acc: 0.776989,loss:0.634451\n",
      "[epoch:8] :acc: 0.776997,loss:0.634231,lr:0.000100,patience:0\n",
      "[epoch:8]: val_loss:0.608527,val_acc:0.791143,\n",
      "Epoch 9/59\n",
      "----------\n",
      "[epoch:9,batch:29]:acc: 0.770833,loss:0.622069\n",
      "[epoch:9,batch:59]:acc: 0.772396,loss:0.659237\n",
      "[epoch:9,batch:89]:acc: 0.774653,loss:0.651110\n",
      "[epoch:9,batch:119]:acc: 0.775000,loss:0.648533\n",
      "[epoch:9,batch:149]:acc: 0.781250,loss:0.631567\n",
      "[epoch:9,batch:179]:acc: 0.781944,loss:0.628472\n",
      "[epoch:9,batch:209]:acc: 0.784970,loss:0.634469\n",
      "[epoch:9,batch:239]:acc: 0.784505,loss:0.634762\n",
      "[epoch:9,batch:269]:acc: 0.785301,loss:0.629515\n",
      "[epoch:9,batch:299]:acc: 0.784479,loss:0.627585\n",
      "[epoch:9,batch:299]: val_loss:0.590453,val_acc:0.798414,val_total:4539\n",
      "[epoch:9,batch:329]:acc: 0.785133,loss:0.625989\n",
      "[epoch:9,batch:359]:acc: 0.785851,loss:0.624322\n",
      "[epoch:9,batch:389]:acc: 0.786298,loss:0.621551\n",
      "[epoch:9,batch:419]:acc: 0.785640,loss:0.623377\n",
      "[epoch:9,batch:449]:acc: 0.785208,loss:0.624763\n",
      "[epoch:9,batch:479]:acc: 0.785807,loss:0.624525\n",
      "[epoch:9,batch:509]:acc: 0.786213,loss:0.624145\n",
      "[epoch:9,batch:539]:acc: 0.786690,loss:0.625319\n",
      "[epoch:9,batch:569]:acc: 0.786294,loss:0.625080\n",
      "[epoch:9,batch:599]:acc: 0.785625,loss:0.625594\n",
      "[epoch:9,batch:599]: val_loss:0.603947,val_acc:0.780789,val_total:4539\n",
      "[epoch:9,batch:629]:acc: 0.785714,loss:0.624224\n",
      "[epoch:9,batch:659]:acc: 0.785890,loss:0.625636\n",
      "[epoch:9,batch:689]:acc: 0.786141,loss:0.622617\n",
      "[epoch:9,batch:719]:acc: 0.786198,loss:0.623766\n",
      "[epoch:9,batch:749]:acc: 0.785333,loss:0.624893\n",
      "[epoch:9,batch:779]:acc: 0.784455,loss:0.626097\n",
      "[epoch:9,batch:809]:acc: 0.784336,loss:0.624375\n",
      "[epoch:9,batch:839]:acc: 0.783966,loss:0.625089\n",
      "[epoch:9,batch:869]:acc: 0.783764,loss:0.625276\n",
      "[epoch:9,batch:899]:acc: 0.783958,loss:0.625035\n",
      "[epoch:9,batch:899]: val_loss:0.608340,val_acc:0.784314,val_total:4539\n",
      "[epoch:9,batch:929]:acc: 0.784207,loss:0.623962\n",
      "[epoch:9,batch:959]:acc: 0.784180,loss:0.622093\n",
      "[epoch:9,batch:989]:acc: 0.783902,loss:0.621913\n",
      "[epoch:9] :acc: 0.783933,loss:0.621857,lr:0.000100,patience:1\n",
      "[epoch:9]: val_loss:0.613245,val_acc:0.782992,\n",
      "Epoch 10/59\n",
      "----------\n",
      "[epoch:10,batch:29]:acc: 0.793750,loss:0.578813\n",
      "[epoch:10,batch:59]:acc: 0.793750,loss:0.591473\n",
      "[epoch:10,batch:89]:acc: 0.787847,loss:0.604605\n",
      "[epoch:10,batch:119]:acc: 0.784375,loss:0.611847\n",
      "[epoch:10,batch:149]:acc: 0.781042,loss:0.609797\n",
      "[epoch:10,batch:179]:acc: 0.781076,loss:0.618916\n",
      "[epoch:10,batch:209]:acc: 0.777232,loss:0.622300\n",
      "[epoch:10,batch:239]:acc: 0.780078,loss:0.619604\n",
      "[epoch:10,batch:269]:acc: 0.779051,loss:0.620685\n",
      "[epoch:10,batch:299]:acc: 0.780312,loss:0.620572\n",
      "[epoch:10,batch:299]: val_loss:0.605077,val_acc:0.782111,val_total:4539\n",
      "[epoch:10,batch:329]:acc: 0.780114,loss:0.618526\n",
      "[epoch:10,batch:359]:acc: 0.779774,loss:0.616992\n",
      "[epoch:10,batch:389]:acc: 0.779487,loss:0.614438\n",
      "[epoch:10,batch:419]:acc: 0.780134,loss:0.614876\n",
      "[epoch:10,batch:449]:acc: 0.781319,loss:0.614067\n",
      "[epoch:10,batch:479]:acc: 0.782943,loss:0.611264\n",
      "[epoch:10,batch:509]:acc: 0.782537,loss:0.612723\n",
      "[epoch:10,batch:539]:acc: 0.781887,loss:0.613972\n",
      "[epoch:10,batch:569]:acc: 0.780921,loss:0.614001\n",
      "[epoch:10,batch:599]:acc: 0.781146,loss:0.613478\n",
      "[epoch:10,batch:599]: val_loss:0.601837,val_acc:0.784534,val_total:4539\n",
      "[epoch:10,batch:629]:acc: 0.781052,loss:0.611062\n",
      "[epoch:10,batch:659]:acc: 0.780777,loss:0.612124\n",
      "[epoch:10,batch:689]:acc: 0.780344,loss:0.612913\n",
      "[epoch:10,batch:719]:acc: 0.779427,loss:0.614271\n",
      "[epoch:10,batch:749]:acc: 0.779500,loss:0.613967\n",
      "[epoch:10,batch:779]:acc: 0.779367,loss:0.617310\n",
      "[epoch:10,batch:809]:acc: 0.778935,loss:0.618261\n",
      "[epoch:10,batch:839]:acc: 0.779353,loss:0.619149\n",
      "[epoch:10,batch:869]:acc: 0.780136,loss:0.617629\n",
      "[epoch:10,batch:899]:acc: 0.780590,loss:0.617057\n",
      "[epoch:10,batch:899]: val_loss:0.598419,val_acc:0.791143,val_total:4539\n",
      "[epoch:10,batch:929]:acc: 0.780343,loss:0.617463\n",
      "[epoch:10,batch:959]:acc: 0.780762,loss:0.617731\n",
      "[epoch:10,batch:989]:acc: 0.780808,loss:0.618635\n",
      "[epoch:10] :acc: 0.780812,loss:0.619634,lr:0.000100,patience:0\n",
      "[epoch:10]: val_loss:0.583013,val_acc:0.799295,\n",
      "save new model loss,now loss is  0.5830132961273193\n",
      "Epoch 11/10\n",
      "----------\n",
      "[epoch:11,batch:29]:acc: 0.768750,loss:0.657483\n",
      "[epoch:11,batch:59]:acc: 0.771875,loss:0.631485\n",
      "[epoch:11,batch:89]:acc: 0.775694,loss:0.633008\n",
      "[epoch:11,batch:119]:acc: 0.783854,loss:0.614370\n",
      "[epoch:11,batch:149]:acc: 0.785417,loss:0.614944\n",
      "[epoch:11,batch:179]:acc: 0.782292,loss:0.624869\n",
      "[epoch:11,batch:209]:acc: 0.782738,loss:0.621807\n",
      "[epoch:11,batch:239]:acc: 0.781380,loss:0.623876\n",
      "[epoch:11,batch:269]:acc: 0.783449,loss:0.614439\n",
      "[epoch:11,batch:299]:acc: 0.783125,loss:0.613338\n",
      "[epoch:11,batch:299]: val_loss:0.602455,val_acc:0.785636,val_total:4539\n",
      "[epoch:11,batch:329]:acc: 0.782576,loss:0.613181\n",
      "[epoch:11,batch:359]:acc: 0.783594,loss:0.607336\n",
      "[epoch:11,batch:389]:acc: 0.783814,loss:0.610543\n",
      "[epoch:11,batch:419]:acc: 0.783408,loss:0.610642\n",
      "[epoch:11,batch:449]:acc: 0.782083,loss:0.613039\n",
      "[epoch:11,batch:479]:acc: 0.781706,loss:0.614507\n",
      "[epoch:11,batch:509]:acc: 0.780453,loss:0.617700\n",
      "[epoch:11,batch:539]:acc: 0.778762,loss:0.621086\n",
      "[epoch:11,batch:569]:acc: 0.779879,loss:0.619484\n",
      "[epoch:11,batch:599]:acc: 0.780312,loss:0.617768\n",
      "[epoch:11,batch:599]: val_loss:0.599209,val_acc:0.789381,val_total:4539\n",
      "[epoch:11,batch:629]:acc: 0.781151,loss:0.614920\n",
      "[epoch:11,batch:659]:acc: 0.781723,loss:0.613300\n",
      "[epoch:11,batch:689]:acc: 0.782020,loss:0.612027\n",
      "[epoch:11,batch:719]:acc: 0.782031,loss:0.612462\n",
      "[epoch:11,batch:749]:acc: 0.781750,loss:0.612694\n",
      "[epoch:11,batch:779]:acc: 0.781130,loss:0.612593\n",
      "[epoch:11,batch:809]:acc: 0.781096,loss:0.612395\n",
      "[epoch:11,batch:839]:acc: 0.781473,loss:0.612539\n",
      "[epoch:11,batch:869]:acc: 0.782328,loss:0.611344\n",
      "[epoch:11,batch:899]:acc: 0.783090,loss:0.607635\n",
      "[epoch:11,batch:899]: val_loss:0.568196,val_acc:0.798634,val_total:4539\n",
      "[epoch:11,batch:929]:acc: 0.783098,loss:0.607637\n",
      "[epoch:11,batch:959]:acc: 0.783496,loss:0.606707\n",
      "[epoch:11,batch:989]:acc: 0.784091,loss:0.604164\n",
      "[epoch:11] :acc: 0.784091,loss:0.604700,lr:0.000100,patience:0\n",
      "[epoch:11]: val_loss:0.595420,val_acc:0.798854,\n",
      "Epoch 12/10\n",
      "----------\n",
      "[epoch:12,batch:29]:acc: 0.795833,loss:0.638758\n",
      "[epoch:12,batch:59]:acc: 0.796354,loss:0.607296\n",
      "[epoch:12,batch:89]:acc: 0.793056,loss:0.605470\n",
      "[epoch:12,batch:119]:acc: 0.792969,loss:0.605816\n",
      "[epoch:12,batch:149]:acc: 0.790833,loss:0.606639\n",
      "[epoch:12,batch:179]:acc: 0.791319,loss:0.601050\n",
      "[epoch:12,batch:209]:acc: 0.788095,loss:0.607342\n",
      "[epoch:12,batch:239]:acc: 0.788802,loss:0.605254\n",
      "[epoch:12,batch:269]:acc: 0.787847,loss:0.600838\n",
      "[epoch:12,batch:299]:acc: 0.787813,loss:0.597519\n",
      "[epoch:12,batch:299]: val_loss:0.581336,val_acc:0.798414,val_total:4539\n",
      "[epoch:12,batch:329]:acc: 0.787311,loss:0.596360\n",
      "[epoch:12,batch:359]:acc: 0.788368,loss:0.594868\n",
      "[epoch:12,batch:389]:acc: 0.788061,loss:0.596969\n",
      "[epoch:12,batch:419]:acc: 0.788542,loss:0.595447\n",
      "[epoch:12,batch:449]:acc: 0.788750,loss:0.593615\n",
      "[epoch:12,batch:479]:acc: 0.788737,loss:0.596175\n",
      "[epoch:12,batch:509]:acc: 0.788787,loss:0.596831\n",
      "[epoch:12,batch:539]:acc: 0.789120,loss:0.597398\n",
      "[epoch:12,batch:569]:acc: 0.789254,loss:0.595581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:12,batch:599]:acc: 0.789740,loss:0.596409\n",
      "[epoch:12,batch:599]: val_loss:0.596278,val_acc:0.790482,val_total:4539\n",
      "[epoch:12,batch:629]:acc: 0.787996,loss:0.597779\n",
      "[epoch:12,batch:659]:acc: 0.786553,loss:0.600856\n",
      "[epoch:12,batch:689]:acc: 0.785915,loss:0.602097\n",
      "[epoch:12,batch:719]:acc: 0.785503,loss:0.602707\n",
      "[epoch:12,batch:749]:acc: 0.785500,loss:0.603308\n",
      "[epoch:12,batch:779]:acc: 0.784896,loss:0.604549\n",
      "[epoch:12,batch:809]:acc: 0.786227,loss:0.600973\n",
      "[epoch:12,batch:839]:acc: 0.786719,loss:0.599804\n",
      "[epoch:12,batch:869]:acc: 0.786997,loss:0.598854\n",
      "[epoch:12,batch:899]:acc: 0.787188,loss:0.597438\n",
      "[epoch:12,batch:899]: val_loss:0.571981,val_acc:0.799736,val_total:4539\n",
      "[epoch:12,batch:929]:acc: 0.787366,loss:0.598226\n",
      "[epoch:12,batch:959]:acc: 0.787533,loss:0.599237\n",
      "[epoch:12,batch:989]:acc: 0.787563,loss:0.598577\n",
      "[epoch:12] :acc: 0.787527,loss:0.598044,lr:0.000100,patience:1\n",
      "[epoch:12]: val_loss:0.581055,val_acc:0.786076,\n",
      "save new model loss,now loss is  0.5810545086860657\n",
      "Epoch 13/10\n",
      "----------\n",
      "[epoch:13,batch:29]:acc: 0.785417,loss:0.618957\n",
      "[epoch:13,batch:59]:acc: 0.800000,loss:0.580931\n",
      "[epoch:13,batch:89]:acc: 0.795486,loss:0.590625\n",
      "[epoch:13,batch:119]:acc: 0.796354,loss:0.587743\n",
      "[epoch:13,batch:149]:acc: 0.797083,loss:0.592246\n",
      "[epoch:13,batch:179]:acc: 0.797743,loss:0.584461\n",
      "[epoch:13,batch:209]:acc: 0.794494,loss:0.589806\n",
      "[epoch:13,batch:239]:acc: 0.794922,loss:0.585710\n",
      "[epoch:13,batch:269]:acc: 0.791667,loss:0.593446\n",
      "[epoch:13,batch:299]:acc: 0.792396,loss:0.591473\n",
      "[epoch:13,batch:299]: val_loss:0.591761,val_acc:0.788940,val_total:4539\n",
      "[epoch:13,batch:329]:acc: 0.793277,loss:0.588821\n",
      "[epoch:13,batch:359]:acc: 0.792188,loss:0.593295\n",
      "[epoch:13,batch:389]:acc: 0.791907,loss:0.592714\n",
      "[epoch:13,batch:419]:acc: 0.791071,loss:0.595999\n",
      "[epoch:13,batch:449]:acc: 0.790903,loss:0.593211\n",
      "[epoch:13,batch:479]:acc: 0.791211,loss:0.590553\n",
      "[epoch:13,batch:509]:acc: 0.792770,loss:0.586012\n",
      "[epoch:13,batch:539]:acc: 0.792824,loss:0.586015\n",
      "[epoch:13,batch:569]:acc: 0.792160,loss:0.587889\n",
      "[epoch:13,batch:599]:acc: 0.791562,loss:0.589172\n",
      "[epoch:13,batch:599]: val_loss:0.582769,val_acc:0.789822,val_total:4539\n",
      "[epoch:13,batch:629]:acc: 0.790774,loss:0.591430\n",
      "[epoch:13,batch:659]:acc: 0.791051,loss:0.588986\n",
      "[epoch:13,batch:689]:acc: 0.791757,loss:0.587702\n",
      "[epoch:13,batch:719]:acc: 0.791536,loss:0.587864\n",
      "[epoch:13,batch:749]:acc: 0.790333,loss:0.590288\n",
      "[epoch:13,batch:779]:acc: 0.788942,loss:0.592903\n",
      "[epoch:13,batch:809]:acc: 0.788387,loss:0.592093\n",
      "[epoch:13,batch:839]:acc: 0.788356,loss:0.591356\n",
      "[epoch:13,batch:869]:acc: 0.788003,loss:0.589183\n",
      "[epoch:13,batch:899]:acc: 0.788507,loss:0.587251\n",
      "[epoch:13,batch:899]: val_loss:0.569186,val_acc:0.786076,val_total:4539\n",
      "[epoch:13,batch:929]:acc: 0.789415,loss:0.586046\n",
      "[epoch:13,batch:959]:acc: 0.788965,loss:0.587985\n",
      "[epoch:13,batch:989]:acc: 0.789678,loss:0.587252\n",
      "[epoch:13] :acc: 0.789703,loss:0.587388,lr:0.000100,patience:0\n",
      "[epoch:13]: val_loss:0.583880,val_acc:0.779687,\n",
      "Epoch 14/10\n",
      "----------\n",
      "[epoch:14,batch:29]:acc: 0.770833,loss:0.690369\n",
      "[epoch:14,batch:59]:acc: 0.786979,loss:0.632903\n",
      "[epoch:14,batch:89]:acc: 0.787847,loss:0.620521\n",
      "[epoch:14,batch:119]:acc: 0.788542,loss:0.620641\n",
      "[epoch:14,batch:149]:acc: 0.789167,loss:0.615937\n",
      "[epoch:14,batch:179]:acc: 0.792361,loss:0.597076\n",
      "[epoch:14,batch:209]:acc: 0.790327,loss:0.595471\n",
      "[epoch:14,batch:239]:acc: 0.790234,loss:0.594601\n",
      "[epoch:14,batch:269]:acc: 0.791319,loss:0.595889\n",
      "[epoch:14,batch:299]:acc: 0.792188,loss:0.591892\n",
      "[epoch:14,batch:299]: val_loss:0.572183,val_acc:0.798854,val_total:4539\n",
      "[epoch:14,batch:329]:acc: 0.791572,loss:0.591816\n",
      "[epoch:14,batch:359]:acc: 0.790104,loss:0.593994\n",
      "[epoch:14,batch:389]:acc: 0.788862,loss:0.594393\n",
      "[epoch:14,batch:419]:acc: 0.789435,loss:0.592210\n",
      "[epoch:14,batch:449]:acc: 0.790625,loss:0.589335\n",
      "[epoch:14,batch:479]:acc: 0.791341,loss:0.586737\n",
      "[epoch:14,batch:509]:acc: 0.791789,loss:0.582899\n",
      "[epoch:14,batch:539]:acc: 0.792650,loss:0.580735\n",
      "[epoch:14,batch:569]:acc: 0.792763,loss:0.581893\n",
      "[epoch:14,batch:599]:acc: 0.791719,loss:0.583041\n",
      "[epoch:14,batch:599]: val_loss:0.580767,val_acc:0.795770,val_total:4539\n",
      "[epoch:14,batch:629]:acc: 0.790774,loss:0.587348\n",
      "[epoch:14,batch:659]:acc: 0.791383,loss:0.586805\n",
      "[epoch:14,batch:689]:acc: 0.791395,loss:0.588176\n",
      "[epoch:14,batch:719]:acc: 0.792188,loss:0.586373\n",
      "[epoch:14,batch:749]:acc: 0.792625,loss:0.584188\n",
      "[epoch:14,batch:779]:acc: 0.792788,loss:0.583149\n",
      "[epoch:14,batch:809]:acc: 0.792207,loss:0.584360\n",
      "[epoch:14,batch:839]:acc: 0.791778,loss:0.584356\n",
      "[epoch:14,batch:869]:acc: 0.791739,loss:0.583965\n",
      "[epoch:14,batch:899]:acc: 0.791042,loss:0.583890\n",
      "[epoch:14,batch:899]: val_loss:0.580964,val_acc:0.795770,val_total:4539\n",
      "[epoch:14,batch:929]:acc: 0.791196,loss:0.584018\n",
      "[epoch:14,batch:959]:acc: 0.791211,loss:0.584450\n",
      "[epoch:14,batch:989]:acc: 0.791635,loss:0.583468\n",
      "[epoch:14] :acc: 0.791563,loss:0.584178,lr:0.000100,patience:1\n",
      "[epoch:14]: val_loss:0.562474,val_acc:0.798414,\n",
      "save new model loss,now loss is  0.5624740719795227\n",
      "Epoch 15/10\n",
      "----------\n",
      "[epoch:15,batch:29]:acc: 0.784375,loss:0.581413\n",
      "[epoch:15,batch:59]:acc: 0.795312,loss:0.578757\n",
      "[epoch:15,batch:89]:acc: 0.800347,loss:0.571358\n",
      "[epoch:15,batch:119]:acc: 0.802344,loss:0.571183\n",
      "[epoch:15,batch:149]:acc: 0.799792,loss:0.564103\n",
      "[epoch:15,batch:179]:acc: 0.796007,loss:0.568909\n",
      "[epoch:15,batch:209]:acc: 0.796577,loss:0.569834\n",
      "[epoch:15,batch:239]:acc: 0.796875,loss:0.564732\n",
      "[epoch:15,batch:269]:acc: 0.795486,loss:0.565273\n",
      "[epoch:15,batch:299]:acc: 0.795833,loss:0.565690\n",
      "[epoch:15,batch:299]: val_loss:0.567426,val_acc:0.801278,val_total:4539\n",
      "[epoch:15,batch:329]:acc: 0.795265,loss:0.566718\n",
      "[epoch:15,batch:359]:acc: 0.793750,loss:0.572232\n",
      "[epoch:15,batch:389]:acc: 0.793189,loss:0.570473\n",
      "[epoch:15,batch:419]:acc: 0.792411,loss:0.574956\n",
      "[epoch:15,batch:449]:acc: 0.793958,loss:0.574586\n",
      "[epoch:15,batch:479]:acc: 0.793490,loss:0.574670\n",
      "[epoch:15,batch:509]:acc: 0.794363,loss:0.572538\n",
      "[epoch:15,batch:539]:acc: 0.794271,loss:0.571928\n",
      "[epoch:15,batch:569]:acc: 0.794134,loss:0.574773\n",
      "[epoch:15,batch:599]:acc: 0.794427,loss:0.574682\n",
      "[epoch:15,batch:599]: val_loss:0.575535,val_acc:0.795329,val_total:4539\n",
      "[epoch:15,batch:629]:acc: 0.794345,loss:0.574989\n",
      "[epoch:15,batch:659]:acc: 0.793608,loss:0.575227\n",
      "[epoch:15,batch:689]:acc: 0.794429,loss:0.573767\n",
      "[epoch:15,batch:719]:acc: 0.793620,loss:0.573193\n",
      "[epoch:15,batch:749]:acc: 0.793750,loss:0.571894\n",
      "[epoch:15,batch:779]:acc: 0.793750,loss:0.572267\n",
      "[epoch:15,batch:809]:acc: 0.794059,loss:0.572013\n",
      "[epoch:15,batch:839]:acc: 0.794048,loss:0.573249\n",
      "[epoch:15,batch:869]:acc: 0.794289,loss:0.572767\n",
      "[epoch:15,batch:899]:acc: 0.794792,loss:0.571220\n",
      "[epoch:15,batch:899]: val_loss:0.559015,val_acc:0.803481,val_total:4539\n",
      "[epoch:15,batch:929]:acc: 0.794590,loss:0.571707\n",
      "[epoch:15,batch:959]:acc: 0.794336,loss:0.571384\n",
      "[epoch:15,batch:989]:acc: 0.793939,loss:0.573606\n",
      "[epoch:15] :acc: 0.793864,loss:0.573775,lr:0.000100,patience:0\n",
      "[epoch:15]: val_loss:0.582706,val_acc:0.799515,\n",
      "Epoch 16/10\n",
      "----------\n",
      "[epoch:16,batch:29]:acc: 0.770833,loss:0.705460\n",
      "[epoch:16,batch:59]:acc: 0.781771,loss:0.642906\n",
      "[epoch:16,batch:89]:acc: 0.789931,loss:0.605803\n",
      "[epoch:16,batch:119]:acc: 0.791667,loss:0.600333\n",
      "[epoch:16,batch:149]:acc: 0.798542,loss:0.581586\n",
      "[epoch:16,batch:179]:acc: 0.799826,loss:0.575902\n",
      "[epoch:16,batch:209]:acc: 0.798810,loss:0.574748\n",
      "[epoch:16,batch:239]:acc: 0.797005,loss:0.580170\n",
      "[epoch:16,batch:269]:acc: 0.797569,loss:0.575721\n",
      "[epoch:16,batch:299]:acc: 0.798021,loss:0.571471\n",
      "[epoch:16,batch:299]: val_loss:0.567972,val_acc:0.797092,val_total:4539\n",
      "[epoch:16,batch:329]:acc: 0.800095,loss:0.564945\n",
      "[epoch:16,batch:359]:acc: 0.799132,loss:0.570717\n",
      "[epoch:16,batch:389]:acc: 0.799679,loss:0.569205\n",
      "[epoch:16,batch:419]:acc: 0.800595,loss:0.565081\n",
      "[epoch:16,batch:449]:acc: 0.800208,loss:0.565661\n",
      "[epoch:16,batch:479]:acc: 0.799609,loss:0.565500\n",
      "[epoch:16,batch:509]:acc: 0.799387,loss:0.565219\n",
      "[epoch:16,batch:539]:acc: 0.798785,loss:0.567344\n",
      "[epoch:16,batch:569]:acc: 0.798300,loss:0.570218\n",
      "[epoch:16,batch:599]:acc: 0.798958,loss:0.570727\n",
      "[epoch:16,batch:599]: val_loss:0.590377,val_acc:0.801057,val_total:4539\n",
      "[epoch:16,batch:629]:acc: 0.798363,loss:0.571084\n",
      "[epoch:16,batch:659]:acc: 0.796686,loss:0.574026\n",
      "[epoch:16,batch:689]:acc: 0.795562,loss:0.573226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:16,batch:719]:acc: 0.795399,loss:0.572921\n",
      "[epoch:16,batch:749]:acc: 0.795125,loss:0.573486\n",
      "[epoch:16,batch:779]:acc: 0.794872,loss:0.574640\n",
      "[epoch:16,batch:809]:acc: 0.795062,loss:0.574205\n",
      "[epoch:16,batch:839]:acc: 0.795722,loss:0.573456\n",
      "[epoch:16,batch:869]:acc: 0.795582,loss:0.574631\n",
      "[epoch:16,batch:899]:acc: 0.795451,loss:0.574498\n",
      "[epoch:16,batch:899]: val_loss:0.585921,val_acc:0.801718,val_total:4539\n",
      "[epoch:16,batch:929]:acc: 0.795598,loss:0.574216\n",
      "[epoch:16,batch:959]:acc: 0.795280,loss:0.575008\n",
      "[epoch:16,batch:989]:acc: 0.795234,loss:0.575304\n",
      "[epoch:16] :acc: 0.795252,loss:0.575194,lr:0.000100,patience:1\n",
      "[epoch:16]: val_loss:0.562471,val_acc:0.803922,\n",
      "save new model loss,now loss is  0.5624714493751526\n",
      "save new model acc,now acc is  tensor(0.8039, device='cuda:0')\n",
      "Epoch 17/10\n",
      "----------\n",
      "[epoch:17,batch:29]:acc: 0.787500,loss:0.664852\n",
      "[epoch:17,batch:59]:acc: 0.787500,loss:0.625431\n",
      "[epoch:17,batch:89]:acc: 0.788889,loss:0.611409\n",
      "[epoch:17,batch:119]:acc: 0.783854,loss:0.609425\n",
      "[epoch:17,batch:149]:acc: 0.788958,loss:0.596883\n",
      "[epoch:17,batch:179]:acc: 0.790972,loss:0.589049\n",
      "[epoch:17,batch:209]:acc: 0.789435,loss:0.593649\n",
      "[epoch:17,batch:239]:acc: 0.792188,loss:0.582827\n",
      "[epoch:17,batch:269]:acc: 0.791435,loss:0.583509\n",
      "[epoch:17,batch:299]:acc: 0.789375,loss:0.584298\n",
      "[epoch:17,batch:299]: val_loss:0.562444,val_acc:0.789381,val_total:4539\n",
      "[epoch:17,batch:329]:acc: 0.790530,loss:0.582586\n",
      "[epoch:17,batch:359]:acc: 0.790799,loss:0.582527\n",
      "[epoch:17,batch:389]:acc: 0.791426,loss:0.580383\n",
      "[epoch:17,batch:419]:acc: 0.790923,loss:0.577714\n",
      "[epoch:17,batch:449]:acc: 0.790903,loss:0.576044\n",
      "[epoch:17,batch:479]:acc: 0.790820,loss:0.577904\n",
      "[epoch:17,batch:509]:acc: 0.790257,loss:0.579246\n",
      "[epoch:17,batch:539]:acc: 0.789641,loss:0.580411\n",
      "[epoch:17,batch:569]:acc: 0.790570,loss:0.576614\n",
      "[epoch:17,batch:599]:acc: 0.790417,loss:0.575059\n",
      "[epoch:17,batch:599]: val_loss:0.552482,val_acc:0.796651,val_total:4539\n",
      "[epoch:17,batch:629]:acc: 0.790724,loss:0.574462\n",
      "[epoch:17,batch:659]:acc: 0.790625,loss:0.574985\n",
      "[epoch:17,batch:689]:acc: 0.790942,loss:0.574093\n",
      "[epoch:17,batch:719]:acc: 0.790755,loss:0.575959\n",
      "[epoch:17,batch:749]:acc: 0.790417,loss:0.576655\n",
      "[epoch:17,batch:779]:acc: 0.790665,loss:0.577279\n",
      "[epoch:17,batch:809]:acc: 0.791744,loss:0.576273\n",
      "[epoch:17,batch:839]:acc: 0.792262,loss:0.575668\n",
      "[epoch:17,batch:869]:acc: 0.792457,loss:0.574775\n",
      "[epoch:17,batch:899]:acc: 0.792639,loss:0.574655\n",
      "[epoch:17,batch:899]: val_loss:0.560692,val_acc:0.794448,val_total:4539\n",
      "[epoch:17,batch:929]:acc: 0.792641,loss:0.574940\n",
      "[epoch:17,batch:959]:acc: 0.791992,loss:0.575637\n",
      "[epoch:17,batch:989]:acc: 0.791604,loss:0.576015\n",
      "[epoch:17] :acc: 0.791657,loss:0.576020,lr:0.000100,patience:0\n",
      "[epoch:17]: val_loss:0.578045,val_acc:0.788059,\n",
      "Epoch 18/10\n",
      "----------\n",
      "[epoch:18,batch:29]:acc: 0.794792,loss:0.612010\n",
      "[epoch:18,batch:59]:acc: 0.811458,loss:0.557434\n",
      "[epoch:18,batch:89]:acc: 0.800694,loss:0.572609\n",
      "[epoch:18,batch:119]:acc: 0.802865,loss:0.567957\n",
      "[epoch:18,batch:149]:acc: 0.799167,loss:0.566653\n",
      "[epoch:18,batch:179]:acc: 0.800347,loss:0.570094\n",
      "[epoch:18,batch:209]:acc: 0.800744,loss:0.565170\n",
      "[epoch:18,batch:239]:acc: 0.799089,loss:0.572117\n",
      "[epoch:18,batch:269]:acc: 0.798727,loss:0.565624\n",
      "[epoch:18,batch:299]:acc: 0.800104,loss:0.561939\n",
      "[epoch:18,batch:299]: val_loss:0.571988,val_acc:0.792025,val_total:4539\n",
      "[epoch:18,batch:329]:acc: 0.799432,loss:0.565052\n",
      "[epoch:18,batch:359]:acc: 0.798090,loss:0.569286\n",
      "[epoch:18,batch:389]:acc: 0.797356,loss:0.571076\n",
      "[epoch:18,batch:419]:acc: 0.796280,loss:0.571337\n",
      "[epoch:18,batch:449]:acc: 0.794931,loss:0.572473\n",
      "[epoch:18,batch:479]:acc: 0.794792,loss:0.571845\n",
      "[epoch:18,batch:509]:acc: 0.793873,loss:0.574742\n",
      "[epoch:18,batch:539]:acc: 0.794387,loss:0.572732\n",
      "[epoch:18,batch:569]:acc: 0.794737,loss:0.570891\n",
      "[epoch:18,batch:599]:acc: 0.795000,loss:0.570409\n",
      "[epoch:18,batch:599]: val_loss:0.562252,val_acc:0.802159,val_total:4539\n",
      "[epoch:18,batch:629]:acc: 0.795833,loss:0.569225\n",
      "[epoch:18,batch:659]:acc: 0.794271,loss:0.571088\n",
      "[epoch:18,batch:689]:acc: 0.794158,loss:0.572231\n",
      "[epoch:18,batch:719]:acc: 0.794488,loss:0.569979\n",
      "[epoch:18,batch:749]:acc: 0.795042,loss:0.568420\n",
      "[epoch:18,batch:779]:acc: 0.795593,loss:0.566849\n",
      "[epoch:18,batch:809]:acc: 0.796142,loss:0.565152\n",
      "[epoch:18,batch:839]:acc: 0.795908,loss:0.566230\n",
      "[epoch:18,batch:869]:acc: 0.796264,loss:0.564902\n",
      "[epoch:18,batch:899]:acc: 0.796007,loss:0.565415\n",
      "[epoch:18,batch:899]: val_loss:0.560413,val_acc:0.797973,val_total:4539\n",
      "[epoch:18,batch:929]:acc: 0.796673,loss:0.563670\n",
      "[epoch:18,batch:959]:acc: 0.797526,loss:0.562097\n",
      "[epoch:18,batch:989]:acc: 0.797759,loss:0.561615\n",
      "[epoch:18] :acc: 0.797648,loss:0.561749,lr:0.000100,patience:1\n",
      "[epoch:18]: val_loss:0.534669,val_acc:0.802820,\n",
      "save new model loss,now loss is  0.5346693992614746\n",
      "Epoch 19/10\n",
      "----------\n",
      "[epoch:19,batch:29]:acc: 0.790625,loss:0.614182\n",
      "[epoch:19,batch:59]:acc: 0.796354,loss:0.577506\n",
      "[epoch:19,batch:89]:acc: 0.788889,loss:0.581717\n",
      "[epoch:19,batch:119]:acc: 0.793750,loss:0.568692\n",
      "[epoch:19,batch:149]:acc: 0.802292,loss:0.555471\n",
      "[epoch:19,batch:179]:acc: 0.799653,loss:0.558186\n",
      "[epoch:19,batch:209]:acc: 0.799851,loss:0.556300\n",
      "[epoch:19,batch:239]:acc: 0.800391,loss:0.556711\n",
      "[epoch:19,batch:269]:acc: 0.800926,loss:0.556527\n",
      "[epoch:19,batch:299]:acc: 0.800937,loss:0.557561\n",
      "[epoch:19,batch:299]: val_loss:0.573116,val_acc:0.794007,val_total:4539\n",
      "[epoch:19,batch:329]:acc: 0.800947,loss:0.557727\n",
      "[epoch:19,batch:359]:acc: 0.800608,loss:0.557606\n",
      "[epoch:19,batch:389]:acc: 0.800881,loss:0.556161\n",
      "[epoch:19,batch:419]:acc: 0.800223,loss:0.556671\n",
      "[epoch:19,batch:449]:acc: 0.799653,loss:0.557994\n",
      "[epoch:19,batch:479]:acc: 0.800065,loss:0.559216\n",
      "[epoch:19,batch:509]:acc: 0.799265,loss:0.562526\n",
      "[epoch:19,batch:539]:acc: 0.799248,loss:0.561972\n",
      "[epoch:19,batch:569]:acc: 0.799890,loss:0.560871\n",
      "[epoch:19,batch:599]:acc: 0.798958,loss:0.563365\n",
      "[epoch:19,batch:599]: val_loss:0.558894,val_acc:0.800176,val_total:4539\n",
      "[epoch:19,batch:629]:acc: 0.799554,loss:0.561983\n",
      "[epoch:19,batch:659]:acc: 0.799574,loss:0.561664\n",
      "[epoch:19,batch:689]:acc: 0.800317,loss:0.561636\n",
      "[epoch:19,batch:719]:acc: 0.800651,loss:0.560342\n",
      "[epoch:19,batch:749]:acc: 0.800417,loss:0.558629\n",
      "[epoch:19,batch:779]:acc: 0.800641,loss:0.557079\n",
      "[epoch:19,batch:809]:acc: 0.801350,loss:0.555487\n",
      "[epoch:19,batch:839]:acc: 0.801786,loss:0.555419\n",
      "[epoch:19,batch:869]:acc: 0.800862,loss:0.557443\n",
      "[epoch:19,batch:899]:acc: 0.800486,loss:0.558810\n",
      "[epoch:19,batch:899]: val_loss:0.549602,val_acc:0.796872,val_total:4539\n",
      "[epoch:19,batch:929]:acc: 0.800269,loss:0.559550\n",
      "[epoch:19,batch:959]:acc: 0.799837,loss:0.560602\n",
      "[epoch:19,batch:989]:acc: 0.799621,loss:0.560579\n",
      "[epoch:19] :acc: 0.799634,loss:0.560482,lr:0.000100,patience:0\n",
      "[epoch:19]: val_loss:0.583514,val_acc:0.796431,\n",
      "Epoch 20/10\n",
      "----------\n",
      "[epoch:20,batch:29]:acc: 0.809375,loss:0.596401\n",
      "[epoch:20,batch:59]:acc: 0.796354,loss:0.607982\n",
      "[epoch:20,batch:89]:acc: 0.799306,loss:0.595161\n",
      "[epoch:20,batch:119]:acc: 0.796875,loss:0.590779\n",
      "[epoch:20,batch:149]:acc: 0.800833,loss:0.580392\n",
      "[epoch:20,batch:179]:acc: 0.802431,loss:0.570072\n",
      "[epoch:20,batch:209]:acc: 0.800744,loss:0.572827\n",
      "[epoch:20,batch:239]:acc: 0.802604,loss:0.565908\n",
      "[epoch:20,batch:269]:acc: 0.801389,loss:0.562968\n",
      "[epoch:20,batch:299]:acc: 0.799063,loss:0.566991\n",
      "[epoch:20,batch:299]: val_loss:0.574622,val_acc:0.788500,val_total:4539\n",
      "[epoch:20,batch:329]:acc: 0.798580,loss:0.565258\n",
      "[epoch:20,batch:359]:acc: 0.797743,loss:0.565909\n",
      "[epoch:20,batch:389]:acc: 0.798077,loss:0.566046\n",
      "[epoch:20,batch:419]:acc: 0.797247,loss:0.566638\n",
      "[epoch:20,batch:449]:acc: 0.797431,loss:0.564444\n",
      "[epoch:20,batch:479]:acc: 0.797201,loss:0.565126\n",
      "[epoch:20,batch:509]:acc: 0.796998,loss:0.563282\n",
      "[epoch:20,batch:539]:acc: 0.798264,loss:0.559143\n",
      "[epoch:20,batch:569]:acc: 0.798629,loss:0.558890\n",
      "[epoch:20,batch:599]:acc: 0.797292,loss:0.559614\n",
      "[epoch:20,batch:599]: val_loss:0.544061,val_acc:0.810751,val_total:4539\n",
      "[epoch:20,batch:629]:acc: 0.797768,loss:0.559368\n",
      "[epoch:20,batch:659]:acc: 0.797633,loss:0.559390\n",
      "[epoch:20,batch:689]:acc: 0.797283,loss:0.562182\n",
      "[epoch:20,batch:719]:acc: 0.797569,loss:0.560441\n",
      "[epoch:20,batch:749]:acc: 0.797708,loss:0.559067\n",
      "[epoch:20,batch:779]:acc: 0.797997,loss:0.560087\n",
      "[epoch:20,batch:809]:acc: 0.797685,loss:0.558738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:20,batch:839]:acc: 0.798289,loss:0.558229\n",
      "[epoch:20,batch:869]:acc: 0.799282,loss:0.556129\n",
      "[epoch:20,batch:899]:acc: 0.798854,loss:0.556826\n",
      "[epoch:20,batch:899]: val_loss:0.575936,val_acc:0.796211,val_total:4539\n",
      "[epoch:20,batch:929]:acc: 0.798454,loss:0.557393\n",
      "[epoch:20,batch:959]:acc: 0.798730,loss:0.557555\n",
      "[epoch:20,batch:989]:acc: 0.799590,loss:0.555330\n",
      "[epoch:20] :acc: 0.799666,loss:0.555335,lr:0.000100,patience:1\n",
      "[epoch:20]: val_loss:0.550452,val_acc:0.795990,\n",
      "Epoch 21/10\n",
      "----------\n",
      "[epoch:21,batch:29]:acc: 0.777083,loss:0.571010\n",
      "[epoch:21,batch:59]:acc: 0.786458,loss:0.586618\n",
      "[epoch:21,batch:89]:acc: 0.796181,loss:0.575477\n",
      "[epoch:21,batch:119]:acc: 0.797396,loss:0.560399\n",
      "[epoch:21,batch:149]:acc: 0.792917,loss:0.568566\n",
      "[epoch:21,batch:179]:acc: 0.794965,loss:0.566484\n",
      "[epoch:21,batch:209]:acc: 0.796726,loss:0.564349\n",
      "[epoch:21,batch:239]:acc: 0.799089,loss:0.556598\n",
      "[epoch:21,batch:269]:acc: 0.800810,loss:0.551257\n",
      "[epoch:21,batch:299]:acc: 0.800417,loss:0.551633\n",
      "[epoch:21,batch:299]: val_loss:0.550073,val_acc:0.808548,val_total:4539\n",
      "[epoch:21,batch:329]:acc: 0.799053,loss:0.554069\n",
      "[epoch:21,batch:359]:acc: 0.800260,loss:0.552310\n",
      "[epoch:21,batch:389]:acc: 0.799920,loss:0.549994\n",
      "[epoch:21,batch:419]:acc: 0.799182,loss:0.551180\n",
      "[epoch:21,batch:449]:acc: 0.798750,loss:0.552688\n",
      "[epoch:21,batch:479]:acc: 0.799674,loss:0.549538\n",
      "[epoch:21,batch:509]:acc: 0.800919,loss:0.547364\n",
      "[epoch:21,batch:539]:acc: 0.799942,loss:0.548915\n",
      "[epoch:21,batch:569]:acc: 0.799068,loss:0.549593\n",
      "[epoch:21,batch:599]:acc: 0.799531,loss:0.549745\n",
      "[epoch:21,batch:599]: val_loss:0.560932,val_acc:0.800617,val_total:4539\n",
      "[epoch:21,batch:629]:acc: 0.798512,loss:0.552164\n",
      "[epoch:21,batch:659]:acc: 0.797538,loss:0.551204\n",
      "[epoch:21,batch:689]:acc: 0.797509,loss:0.550852\n",
      "[epoch:21,batch:719]:acc: 0.797917,loss:0.548882\n",
      "[epoch:21,batch:749]:acc: 0.797917,loss:0.547412\n",
      "[epoch:21,batch:779]:acc: 0.798197,loss:0.548679\n",
      "[epoch:21,batch:809]:acc: 0.797724,loss:0.550258\n",
      "[epoch:21,batch:839]:acc: 0.797321,loss:0.551086\n",
      "[epoch:21,batch:869]:acc: 0.797450,loss:0.550005\n",
      "[epoch:21,batch:899]:acc: 0.797535,loss:0.549989\n",
      "[epoch:21,batch:899]: val_loss:0.539401,val_acc:0.811633,val_total:4539\n",
      "[epoch:21,batch:929]:acc: 0.797681,loss:0.550549\n",
      "[epoch:21,batch:959]:acc: 0.798177,loss:0.550559\n",
      "[epoch:21,batch:989]:acc: 0.798706,loss:0.550508\n",
      "[epoch:21] :acc: 0.798751,loss:0.550172,lr:0.000100,patience:0\n",
      "[epoch:21]: val_loss:0.563386,val_acc:0.808548,\n",
      "save new model acc,now acc is  tensor(0.8085, device='cuda:0')\n",
      "Epoch 22/21\n",
      "----------\n",
      "[epoch:22,batch:29]:acc: 0.785417,loss:0.600872\n",
      "[epoch:22,batch:59]:acc: 0.792708,loss:0.584542\n",
      "[epoch:22,batch:89]:acc: 0.797917,loss:0.571785\n",
      "[epoch:22,batch:119]:acc: 0.799219,loss:0.567597\n",
      "[epoch:22,batch:149]:acc: 0.797292,loss:0.566132\n",
      "[epoch:22,batch:179]:acc: 0.798611,loss:0.563171\n",
      "[epoch:22,batch:209]:acc: 0.803274,loss:0.548009\n",
      "[epoch:22,batch:239]:acc: 0.804297,loss:0.547566\n",
      "[epoch:22,batch:269]:acc: 0.805671,loss:0.550519\n",
      "[epoch:22,batch:299]:acc: 0.807708,loss:0.547736\n",
      "[epoch:22,batch:299]: val_loss:0.565629,val_acc:0.807006,val_total:4539\n",
      "[epoch:22,batch:329]:acc: 0.807860,loss:0.544969\n",
      "[epoch:22,batch:359]:acc: 0.807726,loss:0.544111\n",
      "[epoch:22,batch:389]:acc: 0.807452,loss:0.545176\n",
      "[epoch:22,batch:419]:acc: 0.806994,loss:0.545663\n",
      "[epoch:22,batch:449]:acc: 0.807708,loss:0.541207\n",
      "[epoch:22,batch:479]:acc: 0.808268,loss:0.539732\n",
      "[epoch:22,batch:509]:acc: 0.809252,loss:0.538801\n",
      "[epoch:22,batch:539]:acc: 0.809317,loss:0.538190\n",
      "[epoch:22,batch:569]:acc: 0.808662,loss:0.539919\n",
      "[epoch:22,batch:599]:acc: 0.808906,loss:0.541366\n",
      "[epoch:22,batch:599]: val_loss:0.564577,val_acc:0.799295,val_total:4539\n",
      "[epoch:22,batch:629]:acc: 0.808185,loss:0.541654\n",
      "[epoch:22,batch:659]:acc: 0.807339,loss:0.543267\n",
      "[epoch:22,batch:689]:acc: 0.806884,loss:0.544545\n",
      "[epoch:22,batch:719]:acc: 0.806337,loss:0.543948\n",
      "[epoch:22,batch:749]:acc: 0.805750,loss:0.545633\n",
      "[epoch:22,batch:779]:acc: 0.805369,loss:0.545779\n",
      "[epoch:22,batch:809]:acc: 0.805671,loss:0.544147\n",
      "[epoch:22,batch:839]:acc: 0.805357,loss:0.543993\n",
      "[epoch:22,batch:869]:acc: 0.805172,loss:0.543342\n",
      "[epoch:22,batch:899]:acc: 0.805243,loss:0.543424\n",
      "[epoch:22,batch:899]: val_loss:0.549284,val_acc:0.802379,val_total:4539\n",
      "[epoch:22,batch:929]:acc: 0.804772,loss:0.544322\n",
      "[epoch:22,batch:959]:acc: 0.804622,loss:0.544526\n",
      "[epoch:22,batch:989]:acc: 0.804072,loss:0.545826\n",
      "[epoch:22] :acc: 0.804048,loss:0.546887,lr:0.000100,patience:1\n",
      "[epoch:22]: val_loss:0.553648,val_acc:0.807447,\n",
      "Epoch 23/21\n",
      "----------\n",
      "[epoch:23,batch:29]:acc: 0.790625,loss:0.592950\n",
      "[epoch:23,batch:59]:acc: 0.802604,loss:0.555609\n",
      "[epoch:23,batch:89]:acc: 0.802431,loss:0.551703\n",
      "[epoch:23,batch:119]:acc: 0.805729,loss:0.546730\n",
      "[epoch:23,batch:149]:acc: 0.804375,loss:0.547637\n",
      "[epoch:23,batch:179]:acc: 0.803299,loss:0.550447\n",
      "[epoch:23,batch:209]:acc: 0.804167,loss:0.555366\n",
      "[epoch:23,batch:239]:acc: 0.803646,loss:0.551035\n",
      "[epoch:23,batch:269]:acc: 0.801968,loss:0.549810\n",
      "[epoch:23,batch:299]:acc: 0.803333,loss:0.547072\n",
      "[epoch:23,batch:299]: val_loss:0.538484,val_acc:0.811853,val_total:4539\n",
      "[epoch:23,batch:329]:acc: 0.805208,loss:0.548139\n",
      "[epoch:23,batch:359]:acc: 0.805469,loss:0.549119\n",
      "[epoch:23,batch:389]:acc: 0.805849,loss:0.548899\n",
      "[epoch:23,batch:419]:acc: 0.805878,loss:0.547606\n",
      "[epoch:23,batch:449]:acc: 0.804306,loss:0.550019\n",
      "[epoch:23,batch:479]:acc: 0.803971,loss:0.549580\n",
      "[epoch:23,batch:509]:acc: 0.802512,loss:0.553435\n",
      "[epoch:23,batch:539]:acc: 0.801505,loss:0.552868\n",
      "[epoch:23,batch:569]:acc: 0.800877,loss:0.552082\n",
      "[epoch:23,batch:599]:acc: 0.801510,loss:0.552427\n",
      "[epoch:23,batch:599]: val_loss:0.557895,val_acc:0.801939,val_total:4539\n",
      "[epoch:23,batch:629]:acc: 0.802530,loss:0.549827\n",
      "[epoch:23,batch:659]:acc: 0.802746,loss:0.550387\n",
      "[epoch:23,batch:689]:acc: 0.801993,loss:0.550742\n",
      "[epoch:23,batch:719]:acc: 0.801128,loss:0.549219\n",
      "[epoch:23,batch:749]:acc: 0.800250,loss:0.550985\n",
      "[epoch:23,batch:779]:acc: 0.800361,loss:0.549948\n",
      "[epoch:23,batch:809]:acc: 0.801119,loss:0.547819\n",
      "[epoch:23,batch:839]:acc: 0.801265,loss:0.548081\n",
      "[epoch:23,batch:869]:acc: 0.801868,loss:0.546344\n",
      "[epoch:23,batch:899]:acc: 0.802049,loss:0.545474\n",
      "[epoch:23,batch:899]: val_loss:0.544080,val_acc:0.812734,val_total:4539\n",
      "[epoch:23,batch:929]:acc: 0.802419,loss:0.544851\n",
      "[epoch:23,batch:959]:acc: 0.802995,loss:0.543809\n",
      "[epoch:23,batch:989]:acc: 0.802146,loss:0.545578\n",
      "[epoch:23] :acc: 0.802220,loss:0.545829,lr:0.000100,patience:0\n",
      "[epoch:23]: val_loss:0.542271,val_acc:0.815378,\n",
      "save new model acc,now acc is  tensor(0.8154, device='cuda:0')\n",
      "Epoch 24/23\n",
      "----------\n",
      "[epoch:24,batch:29]:acc: 0.785417,loss:0.558068\n",
      "[epoch:24,batch:59]:acc: 0.794792,loss:0.544196\n",
      "[epoch:24,batch:89]:acc: 0.790278,loss:0.564614\n",
      "[epoch:24,batch:119]:acc: 0.794010,loss:0.561774\n",
      "[epoch:24,batch:149]:acc: 0.791042,loss:0.574412\n",
      "[epoch:24,batch:179]:acc: 0.796181,loss:0.568849\n",
      "[epoch:24,batch:209]:acc: 0.798661,loss:0.561496\n",
      "[epoch:24,batch:239]:acc: 0.800651,loss:0.553754\n",
      "[epoch:24,batch:269]:acc: 0.800810,loss:0.551151\n",
      "[epoch:24,batch:299]:acc: 0.801146,loss:0.548163\n",
      "[epoch:24,batch:299]: val_loss:0.571342,val_acc:0.791804,val_total:4539\n",
      "[epoch:24,batch:329]:acc: 0.802936,loss:0.541596\n",
      "[epoch:24,batch:359]:acc: 0.803038,loss:0.539231\n",
      "[epoch:24,batch:389]:acc: 0.804487,loss:0.538146\n",
      "[epoch:24,batch:419]:acc: 0.803720,loss:0.540135\n",
      "[epoch:24,batch:449]:acc: 0.804167,loss:0.541336\n",
      "[epoch:24,batch:479]:acc: 0.805208,loss:0.538462\n",
      "[epoch:24,batch:509]:acc: 0.804289,loss:0.539598\n",
      "[epoch:24,batch:539]:acc: 0.804803,loss:0.537410\n",
      "[epoch:24,batch:569]:acc: 0.803289,loss:0.537926\n",
      "[epoch:24,batch:599]:acc: 0.803542,loss:0.538572\n",
      "[epoch:24,batch:599]: val_loss:0.558273,val_acc:0.808989,val_total:4539\n",
      "[epoch:24,batch:629]:acc: 0.803472,loss:0.540728\n",
      "[epoch:24,batch:659]:acc: 0.802746,loss:0.544244\n",
      "[epoch:24,batch:689]:acc: 0.803578,loss:0.541477\n",
      "[epoch:24,batch:719]:acc: 0.802908,loss:0.543845\n",
      "[epoch:24,batch:749]:acc: 0.801917,loss:0.545969\n",
      "[epoch:24,batch:779]:acc: 0.801122,loss:0.547250\n",
      "[epoch:24,batch:809]:acc: 0.801620,loss:0.546727\n",
      "[epoch:24,batch:839]:acc: 0.801935,loss:0.546488\n",
      "[epoch:24,batch:869]:acc: 0.802011,loss:0.545822\n",
      "[epoch:24,batch:899]:acc: 0.802257,loss:0.544741\n",
      "[epoch:24,batch:899]: val_loss:0.555899,val_acc:0.799736,val_total:4539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:24,batch:929]:acc: 0.802957,loss:0.543002\n",
      "[epoch:24,batch:959]:acc: 0.803516,loss:0.542002\n",
      "[epoch:24,batch:989]:acc: 0.803693,loss:0.542536\n",
      "[epoch:24] :acc: 0.803670,loss:0.542014,lr:0.000100,patience:1\n",
      "[epoch:24]: val_loss:0.569030,val_acc:0.794668,\n",
      "Epoch 25/23\n",
      "----------\n",
      "[epoch:25,batch:29]:acc: 0.793750,loss:0.614750\n",
      "[epoch:25,batch:59]:acc: 0.798958,loss:0.594801\n",
      "[epoch:25,batch:89]:acc: 0.804861,loss:0.581527\n",
      "[epoch:25,batch:119]:acc: 0.799219,loss:0.584651\n",
      "[epoch:25,batch:149]:acc: 0.801667,loss:0.574247\n",
      "[epoch:25,batch:179]:acc: 0.801215,loss:0.571550\n",
      "[epoch:25,batch:209]:acc: 0.800446,loss:0.564450\n",
      "[epoch:25,batch:239]:acc: 0.798307,loss:0.566672\n",
      "[epoch:25,batch:269]:acc: 0.800926,loss:0.559400\n",
      "[epoch:25,batch:299]:acc: 0.801146,loss:0.559351\n",
      "[epoch:25,batch:299]: val_loss:0.548601,val_acc:0.804803,val_total:4539\n",
      "[epoch:25,batch:329]:acc: 0.801705,loss:0.556038\n",
      "[epoch:25,batch:359]:acc: 0.799306,loss:0.558198\n",
      "[epoch:25,batch:389]:acc: 0.800160,loss:0.558677\n",
      "[epoch:25,batch:419]:acc: 0.799702,loss:0.558481\n",
      "[epoch:25,batch:449]:acc: 0.800139,loss:0.554351\n",
      "[epoch:25,batch:479]:acc: 0.799805,loss:0.552912\n",
      "[epoch:25,batch:509]:acc: 0.800797,loss:0.552285\n",
      "[epoch:25,batch:539]:acc: 0.801852,loss:0.548992\n",
      "[epoch:25,batch:569]:acc: 0.802193,loss:0.547268\n",
      "[epoch:25,batch:599]:acc: 0.802917,loss:0.545610\n",
      "[epoch:25,batch:599]: val_loss:0.536305,val_acc:0.809870,val_total:4539\n",
      "[epoch:25,batch:629]:acc: 0.803671,loss:0.544798\n",
      "[epoch:25,batch:659]:acc: 0.804640,loss:0.543912\n",
      "[epoch:25,batch:689]:acc: 0.804167,loss:0.543450\n",
      "[epoch:25,batch:719]:acc: 0.803993,loss:0.543440\n",
      "[epoch:25,batch:749]:acc: 0.804375,loss:0.541884\n",
      "[epoch:25,batch:779]:acc: 0.803926,loss:0.541791\n",
      "[epoch:25,batch:809]:acc: 0.803974,loss:0.542158\n",
      "[epoch:25,batch:839]:acc: 0.803720,loss:0.541955\n",
      "[epoch:25,batch:869]:acc: 0.804418,loss:0.541846\n",
      "[epoch:25,batch:899]:acc: 0.804896,loss:0.539155\n",
      "[epoch:25,batch:899]: val_loss:0.527555,val_acc:0.806125,val_total:4539\n",
      "[epoch:25,batch:929]:acc: 0.804637,loss:0.540285\n",
      "[epoch:25,batch:959]:acc: 0.804427,loss:0.539217\n",
      "[epoch:25,batch:989]:acc: 0.804388,loss:0.539720\n",
      "[epoch:25] :acc: 0.804521,loss:0.539370,lr:0.000100,patience:0\n",
      "[epoch:25]: val_loss:0.572717,val_acc:0.795329,\n",
      "Epoch 26/25\n",
      "----------\n",
      "[epoch:26,batch:29]:acc: 0.796875,loss:0.570022\n",
      "[epoch:26,batch:59]:acc: 0.810937,loss:0.544245\n",
      "[epoch:26,batch:89]:acc: 0.802778,loss:0.544232\n",
      "[epoch:26,batch:119]:acc: 0.805469,loss:0.545664\n",
      "[epoch:26,batch:149]:acc: 0.809583,loss:0.528410\n",
      "[epoch:26,batch:179]:acc: 0.808507,loss:0.532387\n",
      "[epoch:26,batch:209]:acc: 0.808333,loss:0.533020\n",
      "[epoch:26,batch:239]:acc: 0.809635,loss:0.522875\n",
      "[epoch:26,batch:269]:acc: 0.809259,loss:0.528930\n",
      "[epoch:26,batch:299]:acc: 0.808958,loss:0.531468\n",
      "[epoch:26,batch:299]: val_loss:0.570929,val_acc:0.797092,val_total:4539\n",
      "[epoch:26,batch:329]:acc: 0.808049,loss:0.529230\n",
      "[epoch:26,batch:359]:acc: 0.807899,loss:0.528758\n",
      "[epoch:26,batch:389]:acc: 0.807612,loss:0.525715\n",
      "[epoch:26,batch:419]:acc: 0.807292,loss:0.525754\n",
      "[epoch:26,batch:449]:acc: 0.808264,loss:0.521766\n",
      "[epoch:26,batch:479]:acc: 0.807292,loss:0.524208\n",
      "[epoch:26,batch:509]:acc: 0.805944,loss:0.526436\n",
      "[epoch:26,batch:539]:acc: 0.804514,loss:0.528568\n",
      "[epoch:26,batch:569]:acc: 0.804989,loss:0.528667\n",
      "[epoch:26,batch:599]:acc: 0.805312,loss:0.528565\n",
      "[epoch:26,batch:599]: val_loss:0.533160,val_acc:0.809209,val_total:4539\n",
      "[epoch:26,batch:629]:acc: 0.804960,loss:0.530159\n",
      "[epoch:26,batch:659]:acc: 0.804877,loss:0.530553\n",
      "[epoch:26,batch:689]:acc: 0.804348,loss:0.530451\n",
      "[epoch:26,batch:719]:acc: 0.804427,loss:0.531102\n",
      "[epoch:26,batch:749]:acc: 0.805250,loss:0.531577\n",
      "[epoch:26,batch:779]:acc: 0.805569,loss:0.532638\n",
      "[epoch:26,batch:809]:acc: 0.805285,loss:0.532872\n",
      "[epoch:26,batch:839]:acc: 0.805432,loss:0.533079\n",
      "[epoch:26,batch:869]:acc: 0.804777,loss:0.535944\n",
      "[epoch:26,batch:899]:acc: 0.804792,loss:0.536027\n",
      "[epoch:26,batch:899]: val_loss:0.548072,val_acc:0.807447,val_total:4539\n",
      "[epoch:26,batch:929]:acc: 0.804402,loss:0.536555\n",
      "[epoch:26,batch:959]:acc: 0.804297,loss:0.535307\n",
      "[epoch:26,batch:989]:acc: 0.803883,loss:0.537021\n",
      "[epoch:26] :acc: 0.803891,loss:0.536724,lr:0.000100,patience:1\n",
      "[epoch:26]: val_loss:0.542675,val_acc:0.802379,\n",
      "Epoch 27/25\n",
      "----------\n",
      "[epoch:27,batch:29]:acc: 0.781250,loss:0.579277\n",
      "[epoch:27,batch:59]:acc: 0.792708,loss:0.560346\n",
      "[epoch:27,batch:89]:acc: 0.802083,loss:0.554183\n",
      "[epoch:27,batch:119]:acc: 0.797135,loss:0.558456\n",
      "[epoch:27,batch:149]:acc: 0.799167,loss:0.547080\n",
      "[epoch:27,batch:179]:acc: 0.803299,loss:0.538631\n",
      "[epoch:27,batch:209]:acc: 0.805060,loss:0.534146\n",
      "[epoch:27,batch:239]:acc: 0.803516,loss:0.538552\n",
      "[epoch:27,batch:269]:acc: 0.804167,loss:0.539285\n",
      "[epoch:27,batch:299]:acc: 0.805312,loss:0.537867\n",
      "[epoch:27,batch:299]: val_loss:0.538486,val_acc:0.808768,val_total:4539\n",
      "[epoch:27,batch:329]:acc: 0.805019,loss:0.536982\n",
      "[epoch:27,batch:359]:acc: 0.804774,loss:0.539477\n",
      "[epoch:27,batch:389]:acc: 0.804647,loss:0.538924\n",
      "[epoch:27,batch:419]:acc: 0.805580,loss:0.536308\n",
      "[epoch:27,batch:449]:acc: 0.806389,loss:0.533984\n",
      "[epoch:27,batch:479]:acc: 0.805664,loss:0.535018\n",
      "[epoch:27,batch:509]:acc: 0.804963,loss:0.536867\n",
      "[epoch:27,batch:539]:acc: 0.805498,loss:0.534200\n",
      "[epoch:27,batch:569]:acc: 0.807127,loss:0.533080\n",
      "[epoch:27,batch:599]:acc: 0.807552,loss:0.533591\n",
      "[epoch:27,batch:599]: val_loss:0.588755,val_acc:0.795990,val_total:4539\n",
      "[epoch:27,batch:629]:acc: 0.807093,loss:0.534502\n",
      "[epoch:27,batch:659]:acc: 0.807481,loss:0.534850\n",
      "[epoch:27,batch:689]:acc: 0.808514,loss:0.536024\n",
      "[epoch:27,batch:719]:acc: 0.808116,loss:0.536472\n",
      "[epoch:27,batch:749]:acc: 0.808792,loss:0.534376\n",
      "[epoch:27,batch:779]:acc: 0.808574,loss:0.534010\n",
      "[epoch:27,batch:809]:acc: 0.808333,loss:0.533689\n",
      "[epoch:27,batch:839]:acc: 0.808259,loss:0.533149\n",
      "[epoch:27,batch:869]:acc: 0.807902,loss:0.534517\n",
      "[epoch:27,batch:899]:acc: 0.807431,loss:0.534733\n",
      "[epoch:27,batch:899]: val_loss:0.549909,val_acc:0.800837,val_total:4539\n",
      "[epoch:27,batch:929]:acc: 0.807527,loss:0.534752\n",
      "[epoch:27,batch:959]:acc: 0.807324,loss:0.533945\n",
      "[epoch:27,batch:989]:acc: 0.807260,loss:0.534540\n",
      "[epoch:27] :acc: 0.807170,loss:0.534732,lr:0.000100,patience:0\n",
      "[epoch:27]: val_loss:0.565287,val_acc:0.803481,\n",
      "Epoch 28/27\n",
      "----------\n",
      "[epoch:28,batch:29]:acc: 0.796875,loss:0.584678\n",
      "[epoch:28,batch:59]:acc: 0.802604,loss:0.533767\n",
      "[epoch:28,batch:89]:acc: 0.806250,loss:0.540249\n",
      "[epoch:28,batch:119]:acc: 0.808854,loss:0.533051\n",
      "[epoch:28,batch:149]:acc: 0.806875,loss:0.538475\n",
      "[epoch:28,batch:179]:acc: 0.807813,loss:0.532653\n",
      "[epoch:28,batch:209]:acc: 0.807887,loss:0.525642\n",
      "[epoch:28,batch:239]:acc: 0.809115,loss:0.523171\n",
      "[epoch:28,batch:269]:acc: 0.808565,loss:0.519030\n",
      "[epoch:28,batch:299]:acc: 0.807500,loss:0.519149\n",
      "[epoch:28,batch:299]: val_loss:0.537394,val_acc:0.801057,val_total:4539\n",
      "[epoch:28,batch:329]:acc: 0.808807,loss:0.520314\n",
      "[epoch:28,batch:359]:acc: 0.809375,loss:0.521238\n",
      "[epoch:28,batch:389]:acc: 0.808574,loss:0.522600\n",
      "[epoch:28,batch:419]:acc: 0.808705,loss:0.523624\n",
      "[epoch:28,batch:449]:acc: 0.806597,loss:0.529042\n",
      "[epoch:28,batch:479]:acc: 0.805990,loss:0.529057\n",
      "[epoch:28,batch:509]:acc: 0.806495,loss:0.528587\n",
      "[epoch:28,batch:539]:acc: 0.806366,loss:0.527136\n",
      "[epoch:28,batch:569]:acc: 0.806250,loss:0.528333\n",
      "[epoch:28,batch:599]:acc: 0.805990,loss:0.528631\n",
      "[epoch:28,batch:599]: val_loss:0.533341,val_acc:0.807447,val_total:4539\n",
      "[epoch:28,batch:629]:acc: 0.806052,loss:0.529586\n",
      "[epoch:28,batch:659]:acc: 0.805824,loss:0.529389\n",
      "[epoch:28,batch:689]:acc: 0.806658,loss:0.527697\n",
      "[epoch:28,batch:719]:acc: 0.806684,loss:0.527444\n",
      "[epoch:28,batch:749]:acc: 0.806958,loss:0.528288\n",
      "[epoch:28,batch:779]:acc: 0.806691,loss:0.529014\n",
      "[epoch:28,batch:809]:acc: 0.806057,loss:0.532135\n",
      "[epoch:28,batch:839]:acc: 0.805990,loss:0.531466\n",
      "[epoch:28,batch:869]:acc: 0.805927,loss:0.530597\n",
      "[epoch:28,batch:899]:acc: 0.805243,loss:0.532300\n",
      "[epoch:28,batch:899]: val_loss:0.534211,val_acc:0.805023,val_total:4539\n",
      "[epoch:28,batch:929]:acc: 0.805712,loss:0.532985\n",
      "[epoch:28,batch:959]:acc: 0.805436,loss:0.533375\n",
      "[epoch:28,batch:989]:acc: 0.804703,loss:0.533754\n",
      "[epoch:28] :acc: 0.804805,loss:0.533571,lr:0.000100,patience:1\n",
      "[epoch:28]: val_loss:0.565328,val_acc:0.802820,\n",
      "Epoch 29/27\n",
      "----------\n",
      "[epoch:29,batch:29]:acc: 0.793750,loss:0.591086\n",
      "[epoch:29,batch:59]:acc: 0.790104,loss:0.574788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:29,batch:89]:acc: 0.796181,loss:0.559799\n",
      "[epoch:29,batch:119]:acc: 0.797135,loss:0.562102\n",
      "[epoch:29,batch:149]:acc: 0.798542,loss:0.556262\n",
      "[epoch:29,batch:179]:acc: 0.800347,loss:0.560659\n",
      "[epoch:29,batch:209]:acc: 0.802083,loss:0.560515\n",
      "[epoch:29,batch:239]:acc: 0.804036,loss:0.554997\n",
      "[epoch:29,batch:269]:acc: 0.805208,loss:0.546472\n",
      "[epoch:29,batch:299]:acc: 0.805000,loss:0.546850\n",
      "[epoch:29,batch:299]: val_loss:0.568876,val_acc:0.803701,val_total:4539\n",
      "[epoch:29,batch:329]:acc: 0.806345,loss:0.541743\n",
      "[epoch:29,batch:359]:acc: 0.806684,loss:0.541539\n",
      "[epoch:29,batch:389]:acc: 0.806330,loss:0.541743\n",
      "[epoch:29,batch:419]:acc: 0.804613,loss:0.541106\n",
      "[epoch:29,batch:449]:acc: 0.804028,loss:0.542154\n",
      "[epoch:29,batch:479]:acc: 0.803451,loss:0.541925\n",
      "[epoch:29,batch:509]:acc: 0.803309,loss:0.540195\n",
      "[epoch:29,batch:539]:acc: 0.804514,loss:0.537719\n",
      "[epoch:29,batch:569]:acc: 0.804715,loss:0.537605\n",
      "[epoch:29,batch:599]:acc: 0.806146,loss:0.534927\n",
      "[epoch:29,batch:599]: val_loss:0.524981,val_acc:0.808548,val_total:4539\n",
      "[epoch:29,batch:629]:acc: 0.805754,loss:0.534857\n",
      "[epoch:29,batch:659]:acc: 0.804830,loss:0.534878\n",
      "[epoch:29,batch:689]:acc: 0.805344,loss:0.533530\n",
      "[epoch:29,batch:719]:acc: 0.805686,loss:0.531300\n",
      "[epoch:29,batch:749]:acc: 0.805708,loss:0.530506\n",
      "[epoch:29,batch:779]:acc: 0.805849,loss:0.531055\n",
      "[epoch:29,batch:809]:acc: 0.805324,loss:0.531957\n",
      "[epoch:29,batch:839]:acc: 0.805729,loss:0.531462\n",
      "[epoch:29,batch:869]:acc: 0.805172,loss:0.531768\n",
      "[epoch:29,batch:899]:acc: 0.805278,loss:0.531225\n",
      "[epoch:29,batch:899]: val_loss:0.548308,val_acc:0.803922,val_total:4539\n",
      "[epoch:29,batch:929]:acc: 0.805376,loss:0.531876\n",
      "[epoch:29,batch:959]:acc: 0.805241,loss:0.532628\n",
      "[epoch:29,batch:989]:acc: 0.805934,loss:0.531426\n",
      "[epoch:29] :acc: 0.805877,loss:0.532285,lr:0.000100,patience:0\n",
      "[epoch:29]: val_loss:0.532583,val_acc:0.809429,\n",
      "save new model loss,now loss is  0.5325829386711121\n",
      "Epoch 30/29\n",
      "----------\n",
      "[epoch:30,batch:29]:acc: 0.801042,loss:0.565075\n",
      "[epoch:30,batch:59]:acc: 0.803125,loss:0.541928\n",
      "[epoch:30,batch:89]:acc: 0.804861,loss:0.533823\n",
      "[epoch:30,batch:119]:acc: 0.814063,loss:0.516640\n",
      "[epoch:30,batch:149]:acc: 0.811042,loss:0.523143\n",
      "[epoch:30,batch:179]:acc: 0.805382,loss:0.530855\n",
      "[epoch:30,batch:209]:acc: 0.803720,loss:0.531059\n",
      "[epoch:30,batch:239]:acc: 0.807161,loss:0.525241\n",
      "[epoch:30,batch:269]:acc: 0.806944,loss:0.523638\n",
      "[epoch:30,batch:299]:acc: 0.806875,loss:0.523512\n",
      "[epoch:30,batch:299]: val_loss:0.517415,val_acc:0.809870,val_total:4539\n",
      "[epoch:30,batch:329]:acc: 0.805871,loss:0.526553\n",
      "[epoch:30,batch:359]:acc: 0.803646,loss:0.533465\n",
      "[epoch:30,batch:389]:acc: 0.805048,loss:0.530572\n",
      "[epoch:30,batch:419]:acc: 0.805804,loss:0.530010\n",
      "[epoch:30,batch:449]:acc: 0.806944,loss:0.531102\n",
      "[epoch:30,batch:479]:acc: 0.806901,loss:0.530930\n",
      "[epoch:30,batch:509]:acc: 0.806618,loss:0.530360\n",
      "[epoch:30,batch:539]:acc: 0.806192,loss:0.530247\n",
      "[epoch:30,batch:569]:acc: 0.806908,loss:0.528678\n",
      "[epoch:30,batch:599]:acc: 0.806510,loss:0.528709\n",
      "[epoch:30,batch:599]: val_loss:0.534456,val_acc:0.807887,val_total:4539\n",
      "[epoch:30,batch:629]:acc: 0.806895,loss:0.527861\n",
      "[epoch:30,batch:659]:acc: 0.806581,loss:0.527131\n",
      "[epoch:30,batch:689]:acc: 0.807563,loss:0.525456\n",
      "[epoch:30,batch:719]:acc: 0.807552,loss:0.525277\n",
      "[epoch:30,batch:749]:acc: 0.806708,loss:0.525886\n",
      "[epoch:30,batch:779]:acc: 0.807171,loss:0.526546\n",
      "[epoch:30,batch:809]:acc: 0.806404,loss:0.528696\n",
      "[epoch:30,batch:839]:acc: 0.806473,loss:0.527089\n",
      "[epoch:30,batch:869]:acc: 0.806968,loss:0.526071\n",
      "[epoch:30,batch:899]:acc: 0.806736,loss:0.528603\n",
      "[epoch:30,batch:899]: val_loss:0.557147,val_acc:0.804362,val_total:4539\n",
      "[epoch:30,batch:929]:acc: 0.806183,loss:0.530595\n",
      "[epoch:30,batch:959]:acc: 0.805664,loss:0.530585\n",
      "[epoch:30,batch:989]:acc: 0.805903,loss:0.529658\n",
      "[epoch:30] :acc: 0.805972,loss:0.530049,lr:0.000100,patience:0\n",
      "[epoch:30]: val_loss:0.536714,val_acc:0.804362,\n",
      "Epoch 31/29\n",
      "----------\n",
      "[epoch:31,batch:29]:acc: 0.808333,loss:0.566370\n",
      "[epoch:31,batch:59]:acc: 0.804167,loss:0.553003\n",
      "[epoch:31,batch:89]:acc: 0.803472,loss:0.533807\n",
      "[epoch:31,batch:119]:acc: 0.804688,loss:0.529970\n",
      "[epoch:31,batch:149]:acc: 0.808542,loss:0.525025\n",
      "[epoch:31,batch:179]:acc: 0.809549,loss:0.517587\n",
      "[epoch:31,batch:209]:acc: 0.813095,loss:0.509113\n",
      "[epoch:31,batch:239]:acc: 0.815495,loss:0.508096\n",
      "[epoch:31,batch:269]:acc: 0.812384,loss:0.514564\n",
      "[epoch:31,batch:299]:acc: 0.809271,loss:0.522416\n",
      "[epoch:31,batch:299]: val_loss:0.546017,val_acc:0.802159,val_total:4539\n",
      "[epoch:31,batch:329]:acc: 0.807292,loss:0.523830\n",
      "[epoch:31,batch:359]:acc: 0.806597,loss:0.523333\n",
      "[epoch:31,batch:389]:acc: 0.806571,loss:0.523025\n",
      "[epoch:31,batch:419]:acc: 0.805804,loss:0.525021\n",
      "[epoch:31,batch:449]:acc: 0.806806,loss:0.522590\n",
      "[epoch:31,batch:479]:acc: 0.807096,loss:0.522229\n",
      "[epoch:31,batch:509]:acc: 0.808211,loss:0.518400\n",
      "[epoch:31,batch:539]:acc: 0.809144,loss:0.518970\n",
      "[epoch:31,batch:569]:acc: 0.808936,loss:0.519817\n",
      "[epoch:31,batch:599]:acc: 0.808125,loss:0.522884\n",
      "[epoch:31,batch:599]: val_loss:0.543958,val_acc:0.806125,val_total:4539\n",
      "[epoch:31,batch:629]:acc: 0.808333,loss:0.520426\n",
      "[epoch:31,batch:659]:acc: 0.808144,loss:0.520626\n",
      "[epoch:31,batch:689]:acc: 0.807563,loss:0.522414\n",
      "[epoch:31,batch:719]:acc: 0.807552,loss:0.521864\n",
      "[epoch:31,batch:749]:acc: 0.807292,loss:0.521551\n",
      "[epoch:31,batch:779]:acc: 0.806571,loss:0.521949\n",
      "[epoch:31,batch:809]:acc: 0.806597,loss:0.523088\n",
      "[epoch:31,batch:839]:acc: 0.806957,loss:0.522750\n",
      "[epoch:31,batch:869]:acc: 0.806466,loss:0.522569\n",
      "[epoch:31,batch:899]:acc: 0.806597,loss:0.522798\n",
      "[epoch:31,batch:899]: val_loss:0.528754,val_acc:0.815158,val_total:4539\n",
      "[epoch:31,batch:929]:acc: 0.807191,loss:0.520552\n",
      "[epoch:31,batch:959]:acc: 0.806999,loss:0.521245\n",
      "[epoch:31,batch:989]:acc: 0.806913,loss:0.522889\n",
      "[epoch:31] :acc: 0.806854,loss:0.524450,lr:0.000100,patience:1\n",
      "[epoch:31]: val_loss:0.546724,val_acc:0.803701,\n",
      "Epoch 32/29\n",
      "----------\n",
      "[epoch:32,batch:29]:acc: 0.802083,loss:0.575144\n",
      "[epoch:32,batch:59]:acc: 0.792188,loss:0.576500\n",
      "[epoch:32,batch:89]:acc: 0.802083,loss:0.553252\n",
      "[epoch:32,batch:119]:acc: 0.799740,loss:0.553553\n",
      "[epoch:32,batch:149]:acc: 0.804167,loss:0.543541\n",
      "[epoch:32,batch:179]:acc: 0.806597,loss:0.539185\n",
      "[epoch:32,batch:209]:acc: 0.809375,loss:0.528894\n",
      "[epoch:32,batch:239]:acc: 0.812630,loss:0.526639\n",
      "[epoch:32,batch:269]:acc: 0.811806,loss:0.524544\n",
      "[epoch:32,batch:299]:acc: 0.809688,loss:0.529334\n",
      "[epoch:32,batch:299]: val_loss:0.564416,val_acc:0.801498,val_total:4539\n",
      "[epoch:32,batch:329]:acc: 0.808617,loss:0.531483\n",
      "[epoch:32,batch:359]:acc: 0.806858,loss:0.534232\n",
      "[epoch:32,batch:389]:acc: 0.806170,loss:0.532696\n",
      "[epoch:32,batch:419]:acc: 0.805952,loss:0.531959\n",
      "[epoch:32,batch:449]:acc: 0.805278,loss:0.534780\n",
      "[epoch:32,batch:479]:acc: 0.806380,loss:0.534732\n",
      "[epoch:32,batch:509]:acc: 0.806495,loss:0.535886\n",
      "[epoch:32,batch:539]:acc: 0.806481,loss:0.532732\n",
      "[epoch:32,batch:569]:acc: 0.807456,loss:0.528836\n",
      "[epoch:32,batch:599]:acc: 0.807292,loss:0.527695\n",
      "[epoch:32,batch:599]: val_loss:0.538764,val_acc:0.817581,val_total:4539\n",
      "[epoch:32,batch:629]:acc: 0.807788,loss:0.526451\n",
      "[epoch:32,batch:659]:acc: 0.808665,loss:0.524305\n",
      "[epoch:32,batch:689]:acc: 0.808062,loss:0.526559\n",
      "[epoch:32,batch:719]:acc: 0.807813,loss:0.526179\n",
      "[epoch:32,batch:749]:acc: 0.807583,loss:0.528464\n",
      "[epoch:32,batch:779]:acc: 0.807893,loss:0.528267\n",
      "[epoch:32,batch:809]:acc: 0.808179,loss:0.526186\n",
      "[epoch:32,batch:839]:acc: 0.808482,loss:0.525859\n",
      "[epoch:32,batch:869]:acc: 0.808082,loss:0.526201\n",
      "[epoch:32,batch:899]:acc: 0.808889,loss:0.523607\n",
      "[epoch:32,batch:899]: val_loss:0.526622,val_acc:0.811853,val_total:4539\n",
      "[epoch:32,batch:929]:acc: 0.809341,loss:0.524759\n",
      "[epoch:32,batch:959]:acc: 0.809570,loss:0.524358\n",
      "[epoch:32,batch:989]:acc: 0.809501,loss:0.523609\n",
      "[epoch:32] :acc: 0.809440,loss:0.523409,lr:0.000100,patience:0\n",
      "[epoch:32]: val_loss:0.545685,val_acc:0.806565,\n",
      "Epoch 33/32\n",
      "----------\n",
      "[epoch:33,batch:29]:acc: 0.808333,loss:0.556170\n",
      "[epoch:33,batch:59]:acc: 0.815625,loss:0.531688\n",
      "[epoch:33,batch:89]:acc: 0.806250,loss:0.530829\n",
      "[epoch:33,batch:119]:acc: 0.810417,loss:0.521700\n",
      "[epoch:33,batch:149]:acc: 0.810417,loss:0.520430\n",
      "[epoch:33,batch:179]:acc: 0.805382,loss:0.528291\n",
      "[epoch:33,batch:209]:acc: 0.805060,loss:0.533201\n",
      "[epoch:33,batch:239]:acc: 0.805990,loss:0.531641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:33,batch:269]:acc: 0.806481,loss:0.529821\n",
      "[epoch:33,batch:299]:acc: 0.806250,loss:0.527884\n",
      "[epoch:33,batch:299]: val_loss:0.538163,val_acc:0.801718,val_total:4539\n",
      "[epoch:33,batch:329]:acc: 0.807292,loss:0.523504\n",
      "[epoch:33,batch:359]:acc: 0.807639,loss:0.520757\n",
      "[epoch:33,batch:389]:acc: 0.808333,loss:0.519833\n",
      "[epoch:33,batch:419]:acc: 0.806845,loss:0.523958\n",
      "[epoch:33,batch:449]:acc: 0.806944,loss:0.523887\n",
      "[epoch:33,batch:479]:acc: 0.807878,loss:0.521528\n",
      "[epoch:33,batch:509]:acc: 0.809130,loss:0.517219\n",
      "[epoch:33,batch:539]:acc: 0.808044,loss:0.520394\n",
      "[epoch:33,batch:569]:acc: 0.807182,loss:0.521475\n",
      "[epoch:33,batch:599]:acc: 0.807969,loss:0.520340\n",
      "[epoch:33,batch:599]: val_loss:0.521775,val_acc:0.808548,val_total:4539\n",
      "[epoch:33,batch:629]:acc: 0.808433,loss:0.518832\n",
      "[epoch:33,batch:659]:acc: 0.808333,loss:0.519956\n",
      "[epoch:33,batch:689]:acc: 0.808469,loss:0.519240\n",
      "[epoch:33,batch:719]:acc: 0.807595,loss:0.520474\n",
      "[epoch:33,batch:749]:acc: 0.808417,loss:0.520226\n",
      "[epoch:33,batch:779]:acc: 0.808534,loss:0.521194\n",
      "[epoch:33,batch:809]:acc: 0.808333,loss:0.522468\n",
      "[epoch:33,batch:839]:acc: 0.808482,loss:0.522161\n",
      "[epoch:33,batch:869]:acc: 0.808549,loss:0.521055\n",
      "[epoch:33,batch:899]:acc: 0.809132,loss:0.519576\n",
      "[epoch:33,batch:899]: val_loss:0.526304,val_acc:0.813395,val_total:4539\n",
      "[epoch:33,batch:929]:acc: 0.809442,loss:0.518890\n",
      "[epoch:33,batch:959]:acc: 0.808496,loss:0.519908\n",
      "[epoch:33,batch:989]:acc: 0.807544,loss:0.521615\n",
      "[epoch:33] :acc: 0.807611,loss:0.521298,lr:0.000100,patience:1\n",
      "[epoch:33]: val_loss:0.550395,val_acc:0.808989,\n",
      "Epoch 34/32\n",
      "----------\n",
      "[epoch:34,batch:29]:acc: 0.796875,loss:0.562332\n",
      "[epoch:34,batch:59]:acc: 0.811458,loss:0.500837\n",
      "[epoch:34,batch:89]:acc: 0.802778,loss:0.511317\n",
      "[epoch:34,batch:119]:acc: 0.809375,loss:0.505698\n",
      "[epoch:34,batch:149]:acc: 0.808958,loss:0.509248\n",
      "[epoch:34,batch:179]:acc: 0.811458,loss:0.500676\n",
      "[epoch:34,batch:209]:acc: 0.810565,loss:0.504505\n",
      "[epoch:34,batch:239]:acc: 0.807422,loss:0.509332\n",
      "[epoch:34,batch:269]:acc: 0.806481,loss:0.510610\n",
      "[epoch:34,batch:299]:acc: 0.805521,loss:0.510718\n",
      "[epoch:34,batch:299]: val_loss:0.531607,val_acc:0.807006,val_total:4539\n",
      "[epoch:34,batch:329]:acc: 0.805492,loss:0.514344\n",
      "[epoch:34,batch:359]:acc: 0.806163,loss:0.513808\n",
      "[epoch:34,batch:389]:acc: 0.807372,loss:0.510667\n",
      "[epoch:34,batch:419]:acc: 0.808110,loss:0.509549\n",
      "[epoch:34,batch:449]:acc: 0.807917,loss:0.508319\n",
      "[epoch:34,batch:479]:acc: 0.807682,loss:0.510497\n",
      "[epoch:34,batch:509]:acc: 0.807843,loss:0.511806\n",
      "[epoch:34,batch:539]:acc: 0.808218,loss:0.512222\n",
      "[epoch:34,batch:569]:acc: 0.808114,loss:0.512804\n",
      "[epoch:34,batch:599]:acc: 0.808802,loss:0.511443\n",
      "[epoch:34,batch:599]: val_loss:0.538215,val_acc:0.801498,val_total:4539\n",
      "[epoch:34,batch:629]:acc: 0.809524,loss:0.511600\n",
      "[epoch:34,batch:659]:acc: 0.810322,loss:0.510687\n",
      "[epoch:34,batch:689]:acc: 0.810100,loss:0.511953\n",
      "[epoch:34,batch:719]:acc: 0.810330,loss:0.511956\n",
      "[epoch:34,batch:749]:acc: 0.810500,loss:0.513376\n",
      "[epoch:34,batch:779]:acc: 0.810937,loss:0.515018\n",
      "[epoch:34,batch:809]:acc: 0.811343,loss:0.513621\n",
      "[epoch:34,batch:839]:acc: 0.811198,loss:0.514316\n",
      "[epoch:34,batch:869]:acc: 0.810955,loss:0.515930\n",
      "[epoch:34,batch:899]:acc: 0.810799,loss:0.517107\n",
      "[epoch:34,batch:899]: val_loss:0.547776,val_acc:0.795990,val_total:4539\n",
      "[epoch:34,batch:929]:acc: 0.810484,loss:0.517522\n",
      "[epoch:34,batch:959]:acc: 0.810059,loss:0.516912\n",
      "[epoch:34,batch:989]:acc: 0.810069,loss:0.517545\n",
      "[epoch:34] :acc: 0.809818,loss:0.519930,lr:0.000100,patience:0\n",
      "[epoch:34]: val_loss:0.535650,val_acc:0.812073,\n",
      "Epoch 35/34\n",
      "----------\n",
      "[epoch:35,batch:29]:acc: 0.786458,loss:0.614565\n",
      "[epoch:35,batch:59]:acc: 0.794792,loss:0.571059\n",
      "[epoch:35,batch:89]:acc: 0.795486,loss:0.556213\n",
      "[epoch:35,batch:119]:acc: 0.803385,loss:0.533237\n",
      "[epoch:35,batch:149]:acc: 0.801042,loss:0.536862\n",
      "[epoch:35,batch:179]:acc: 0.803125,loss:0.531828\n",
      "[epoch:35,batch:209]:acc: 0.806845,loss:0.533484\n",
      "[epoch:35,batch:239]:acc: 0.807422,loss:0.527207\n",
      "[epoch:35,batch:269]:acc: 0.807986,loss:0.526037\n",
      "[epoch:35,batch:299]:acc: 0.806875,loss:0.528711\n",
      "[epoch:35,batch:299]: val_loss:0.543287,val_acc:0.804582,val_total:4539\n",
      "[epoch:35,batch:329]:acc: 0.807955,loss:0.529955\n",
      "[epoch:35,batch:359]:acc: 0.807205,loss:0.531057\n",
      "[epoch:35,batch:389]:acc: 0.807292,loss:0.528361\n",
      "[epoch:35,batch:419]:acc: 0.808333,loss:0.525681\n",
      "[epoch:35,batch:449]:acc: 0.809306,loss:0.522356\n",
      "[epoch:35,batch:479]:acc: 0.810091,loss:0.519447\n",
      "[epoch:35,batch:509]:acc: 0.808946,loss:0.522218\n",
      "[epoch:35,batch:539]:acc: 0.809259,loss:0.520768\n",
      "[epoch:35,batch:569]:acc: 0.809868,loss:0.518624\n",
      "[epoch:35,batch:599]:acc: 0.809896,loss:0.519647\n",
      "[epoch:35,batch:599]: val_loss:0.534196,val_acc:0.808328,val_total:4539\n",
      "[epoch:35,batch:629]:acc: 0.809722,loss:0.517833\n",
      "[epoch:35,batch:659]:acc: 0.809375,loss:0.519308\n",
      "[epoch:35,batch:689]:acc: 0.810054,loss:0.518991\n",
      "[epoch:35,batch:719]:acc: 0.810156,loss:0.517261\n",
      "[epoch:35,batch:749]:acc: 0.809333,loss:0.519334\n",
      "[epoch:35,batch:779]:acc: 0.809415,loss:0.518603\n",
      "[epoch:35,batch:809]:acc: 0.809298,loss:0.519144\n",
      "[epoch:35,batch:839]:acc: 0.809226,loss:0.518921\n",
      "[epoch:35,batch:869]:acc: 0.809698,loss:0.516662\n",
      "[epoch:35,batch:899]:acc: 0.810069,loss:0.517294\n",
      "[epoch:35,batch:899]: val_loss:0.536726,val_acc:0.803261,val_total:4539\n",
      "[epoch:35,batch:929]:acc: 0.810081,loss:0.516768\n",
      "[epoch:35,batch:959]:acc: 0.810156,loss:0.517508\n",
      "[epoch:35,batch:989]:acc: 0.810511,loss:0.516933\n",
      "[epoch:35] :acc: 0.810512,loss:0.516849,lr:0.000100,patience:1\n",
      "[epoch:35]: val_loss:0.530799,val_acc:0.816479,\n",
      "save new model loss,now loss is  0.5307989716529846\n",
      "save new model acc,now acc is  tensor(0.8165, device='cuda:0')\n",
      "Epoch 36/34\n",
      "----------\n",
      "[epoch:36,batch:29]:acc: 0.802083,loss:0.567348\n",
      "[epoch:36,batch:59]:acc: 0.807292,loss:0.528575\n",
      "[epoch:36,batch:89]:acc: 0.808333,loss:0.511151\n",
      "[epoch:36,batch:119]:acc: 0.802344,loss:0.526376\n",
      "[epoch:36,batch:149]:acc: 0.804583,loss:0.530969\n",
      "[epoch:36,batch:179]:acc: 0.806771,loss:0.528844\n",
      "[epoch:36,batch:209]:acc: 0.809226,loss:0.523515\n",
      "[epoch:36,batch:239]:acc: 0.812891,loss:0.510051\n",
      "[epoch:36,batch:269]:acc: 0.813889,loss:0.514039\n",
      "[epoch:36,batch:299]:acc: 0.814896,loss:0.511741\n",
      "[epoch:36,batch:299]: val_loss:0.532870,val_acc:0.807006,val_total:4539\n",
      "[epoch:36,batch:329]:acc: 0.812879,loss:0.516598\n",
      "[epoch:36,batch:359]:acc: 0.810330,loss:0.518880\n",
      "[epoch:36,batch:389]:acc: 0.809936,loss:0.518822\n",
      "[epoch:36,batch:419]:acc: 0.809896,loss:0.519419\n",
      "[epoch:36,batch:449]:acc: 0.810625,loss:0.519873\n",
      "[epoch:36,batch:479]:acc: 0.809375,loss:0.522058\n",
      "[epoch:36,batch:509]:acc: 0.807843,loss:0.526015\n",
      "[epoch:36,batch:539]:acc: 0.807176,loss:0.527924\n",
      "[epoch:36,batch:569]:acc: 0.806031,loss:0.529555\n",
      "[epoch:36,batch:599]:acc: 0.805885,loss:0.526913\n",
      "[epoch:36,batch:599]: val_loss:0.547757,val_acc:0.803922,val_total:4539\n",
      "[epoch:36,batch:629]:acc: 0.806200,loss:0.526851\n",
      "[epoch:36,batch:659]:acc: 0.807576,loss:0.523634\n",
      "[epoch:36,batch:689]:acc: 0.807111,loss:0.523131\n",
      "[epoch:36,batch:719]:acc: 0.807161,loss:0.522436\n",
      "[epoch:36,batch:749]:acc: 0.807417,loss:0.520792\n",
      "[epoch:36,batch:779]:acc: 0.807212,loss:0.522569\n",
      "[epoch:36,batch:809]:acc: 0.807986,loss:0.520489\n",
      "[epoch:36,batch:839]:acc: 0.808557,loss:0.519684\n",
      "[epoch:36,batch:869]:acc: 0.808226,loss:0.520276\n",
      "[epoch:36,batch:899]:acc: 0.808333,loss:0.519811\n",
      "[epoch:36,batch:899]: val_loss:0.541517,val_acc:0.808768,val_total:4539\n",
      "[epoch:36,batch:929]:acc: 0.808501,loss:0.521246\n",
      "[epoch:36,batch:959]:acc: 0.808724,loss:0.520262\n",
      "[epoch:36,batch:989]:acc: 0.808176,loss:0.520940\n",
      "[epoch:36] :acc: 0.808116,loss:0.521530,lr:0.000100,patience:0\n",
      "[epoch:36]: val_loss:0.562599,val_acc:0.804582,\n",
      "Epoch 37/34\n",
      "----------\n",
      "[epoch:37,batch:29]:acc: 0.767708,loss:0.603827\n",
      "[epoch:37,batch:59]:acc: 0.783854,loss:0.558218\n",
      "[epoch:37,batch:89]:acc: 0.792014,loss:0.549083\n",
      "[epoch:37,batch:119]:acc: 0.798177,loss:0.541329\n",
      "[epoch:37,batch:149]:acc: 0.802708,loss:0.531164\n",
      "[epoch:37,batch:179]:acc: 0.805729,loss:0.524490\n",
      "[epoch:37,batch:209]:acc: 0.808036,loss:0.524110\n",
      "[epoch:37,batch:239]:acc: 0.808594,loss:0.516491\n",
      "[epoch:37,batch:269]:acc: 0.808796,loss:0.513682\n",
      "[epoch:37,batch:299]:acc: 0.809271,loss:0.511778\n",
      "[epoch:37,batch:299]: val_loss:0.540666,val_acc:0.808328,val_total:4539\n",
      "[epoch:37,batch:329]:acc: 0.808617,loss:0.518489\n",
      "[epoch:37,batch:359]:acc: 0.808160,loss:0.517461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:37,batch:389]:acc: 0.808734,loss:0.515159\n",
      "[epoch:37,batch:419]:acc: 0.808780,loss:0.515282\n",
      "[epoch:37,batch:449]:acc: 0.808542,loss:0.516171\n",
      "[epoch:37,batch:479]:acc: 0.809961,loss:0.510741\n",
      "[epoch:37,batch:509]:acc: 0.808762,loss:0.512614\n",
      "[epoch:37,batch:539]:acc: 0.810185,loss:0.510095\n",
      "[epoch:37,batch:569]:acc: 0.809156,loss:0.511016\n",
      "[epoch:37,batch:599]:acc: 0.809115,loss:0.509730\n",
      "[epoch:37,batch:599]: val_loss:0.511766,val_acc:0.810531,val_total:4539\n",
      "[epoch:37,batch:629]:acc: 0.810417,loss:0.508895\n",
      "[epoch:37,batch:659]:acc: 0.811032,loss:0.509530\n",
      "[epoch:37,batch:689]:acc: 0.810417,loss:0.510582\n",
      "[epoch:37,batch:719]:acc: 0.809722,loss:0.510681\n",
      "[epoch:37,batch:749]:acc: 0.809333,loss:0.513195\n",
      "[epoch:37,batch:779]:acc: 0.808814,loss:0.512993\n",
      "[epoch:37,batch:809]:acc: 0.808333,loss:0.512987\n",
      "[epoch:37,batch:839]:acc: 0.807850,loss:0.514620\n",
      "[epoch:37,batch:869]:acc: 0.808836,loss:0.513996\n",
      "[epoch:37,batch:899]:acc: 0.808715,loss:0.514369\n",
      "[epoch:37,batch:899]: val_loss:0.575130,val_acc:0.802600,val_total:4539\n",
      "[epoch:37,batch:929]:acc: 0.809409,loss:0.512971\n",
      "[epoch:37,batch:959]:acc: 0.809408,loss:0.512748\n",
      "[epoch:37,batch:989]:acc: 0.809533,loss:0.513628\n",
      "[epoch:37] :acc: 0.809566,loss:0.513490,lr:0.000100,patience:1\n",
      "[epoch:37]: val_loss:0.531038,val_acc:0.810972,\n",
      "Epoch 38/34\n",
      "----------\n",
      "[epoch:38,batch:29]:acc: 0.792708,loss:0.566531\n",
      "[epoch:38,batch:59]:acc: 0.798438,loss:0.553492\n",
      "[epoch:38,batch:89]:acc: 0.801389,loss:0.545288\n",
      "[epoch:38,batch:119]:acc: 0.809375,loss:0.525185\n",
      "[epoch:38,batch:149]:acc: 0.815417,loss:0.516866\n",
      "[epoch:38,batch:179]:acc: 0.815799,loss:0.514553\n",
      "[epoch:38,batch:209]:acc: 0.819345,loss:0.505624\n",
      "[epoch:38,batch:239]:acc: 0.817708,loss:0.503233\n",
      "[epoch:38,batch:269]:acc: 0.817245,loss:0.502439\n",
      "[epoch:38,batch:299]:acc: 0.818438,loss:0.497908\n",
      "[epoch:38,batch:299]: val_loss:0.542490,val_acc:0.808989,val_total:4539\n",
      "[epoch:38,batch:329]:acc: 0.818561,loss:0.494972\n",
      "[epoch:38,batch:359]:acc: 0.818576,loss:0.495609\n",
      "[epoch:38,batch:389]:acc: 0.818750,loss:0.495127\n",
      "[epoch:38,batch:419]:acc: 0.816964,loss:0.497127\n",
      "[epoch:38,batch:449]:acc: 0.816875,loss:0.497613\n",
      "[epoch:38,batch:479]:acc: 0.817057,loss:0.495629\n",
      "[epoch:38,batch:509]:acc: 0.815625,loss:0.500853\n",
      "[epoch:38,batch:539]:acc: 0.814236,loss:0.504875\n",
      "[epoch:38,batch:569]:acc: 0.814364,loss:0.504278\n",
      "[epoch:38,batch:599]:acc: 0.814323,loss:0.505369\n",
      "[epoch:38,batch:599]: val_loss:0.532803,val_acc:0.808328,val_total:4539\n",
      "[epoch:38,batch:629]:acc: 0.813492,loss:0.506516\n",
      "[epoch:38,batch:659]:acc: 0.812595,loss:0.511152\n",
      "[epoch:38,batch:689]:acc: 0.812998,loss:0.511679\n",
      "[epoch:38,batch:719]:acc: 0.813802,loss:0.510695\n",
      "[epoch:38,batch:749]:acc: 0.813333,loss:0.509927\n",
      "[epoch:38,batch:779]:acc: 0.813381,loss:0.509707\n",
      "[epoch:38,batch:809]:acc: 0.813079,loss:0.509717\n",
      "[epoch:38,batch:839]:acc: 0.813393,loss:0.509977\n",
      "[epoch:38,batch:869]:acc: 0.813182,loss:0.509456\n",
      "[epoch:38,batch:899]:acc: 0.812500,loss:0.510230\n",
      "[epoch:38,batch:899]: val_loss:0.521101,val_acc:0.801278,val_total:4539\n",
      "[epoch:38,batch:929]:acc: 0.812466,loss:0.510802\n",
      "[epoch:38,batch:959]:acc: 0.812240,loss:0.511925\n",
      "[epoch:38,batch:989]:acc: 0.812058,loss:0.512626\n",
      "[epoch:38] :acc: 0.812151,loss:0.512165,lr:0.000100,patience:0\n",
      "[epoch:38]: val_loss:0.546316,val_acc:0.810090,\n",
      "Epoch 39/38\n",
      "----------\n",
      "[epoch:39,batch:29]:acc: 0.787500,loss:0.522332\n",
      "[epoch:39,batch:59]:acc: 0.796875,loss:0.517393\n",
      "[epoch:39,batch:89]:acc: 0.800000,loss:0.502731\n",
      "[epoch:39,batch:119]:acc: 0.807813,loss:0.494854\n",
      "[epoch:39,batch:149]:acc: 0.810000,loss:0.497618\n",
      "[epoch:39,batch:179]:acc: 0.814063,loss:0.492281\n",
      "[epoch:39,batch:209]:acc: 0.818304,loss:0.484196\n",
      "[epoch:39,batch:239]:acc: 0.815104,loss:0.488763\n",
      "[epoch:39,batch:269]:acc: 0.815046,loss:0.491264\n",
      "[epoch:39,batch:299]:acc: 0.814792,loss:0.491833\n",
      "[epoch:39,batch:299]: val_loss:0.537784,val_acc:0.811853,val_total:4539\n",
      "[epoch:39,batch:329]:acc: 0.814583,loss:0.490514\n",
      "[epoch:39,batch:359]:acc: 0.812760,loss:0.496926\n",
      "[epoch:39,batch:389]:acc: 0.812981,loss:0.495833\n",
      "[epoch:39,batch:419]:acc: 0.812054,loss:0.498263\n",
      "[epoch:39,batch:449]:acc: 0.813194,loss:0.499833\n",
      "[epoch:39,batch:479]:acc: 0.813932,loss:0.500889\n",
      "[epoch:39,batch:509]:acc: 0.814706,loss:0.497968\n",
      "[epoch:39,batch:539]:acc: 0.814352,loss:0.500333\n",
      "[epoch:39,batch:569]:acc: 0.813377,loss:0.499649\n",
      "[epoch:39,batch:599]:acc: 0.812917,loss:0.500762\n",
      "[epoch:39,batch:599]: val_loss:0.556850,val_acc:0.797092,val_total:4539\n",
      "[epoch:39,batch:629]:acc: 0.813542,loss:0.499709\n",
      "[epoch:39,batch:659]:acc: 0.813210,loss:0.500647\n",
      "[epoch:39,batch:689]:acc: 0.813225,loss:0.501191\n",
      "[epoch:39,batch:719]:acc: 0.811589,loss:0.504496\n",
      "[epoch:39,batch:749]:acc: 0.811250,loss:0.504601\n",
      "[epoch:39,batch:779]:acc: 0.811178,loss:0.505017\n",
      "[epoch:39,batch:809]:acc: 0.810880,loss:0.504501\n",
      "[epoch:39,batch:839]:acc: 0.810342,loss:0.507224\n",
      "[epoch:39,batch:869]:acc: 0.811135,loss:0.507368\n",
      "[epoch:39,batch:899]:acc: 0.810833,loss:0.508117\n",
      "[epoch:39,batch:899]: val_loss:0.538073,val_acc:0.805243,val_total:4539\n",
      "[epoch:39,batch:929]:acc: 0.811593,loss:0.506890\n",
      "[epoch:39,batch:959]:acc: 0.811296,loss:0.507551\n",
      "[epoch:39,batch:989]:acc: 0.811774,loss:0.506031\n",
      "[epoch:39] :acc: 0.811804,loss:0.505785,lr:0.000100,patience:1\n",
      "[epoch:39]: val_loss:0.532407,val_acc:0.812514,\n",
      "Epoch 40/38\n",
      "----------\n",
      "[epoch:40,batch:29]:acc: 0.791667,loss:0.553714\n",
      "[epoch:40,batch:59]:acc: 0.802604,loss:0.534963\n",
      "[epoch:40,batch:89]:acc: 0.801389,loss:0.519692\n",
      "[epoch:40,batch:119]:acc: 0.803906,loss:0.508843\n",
      "[epoch:40,batch:149]:acc: 0.802292,loss:0.509070\n",
      "[epoch:40,batch:179]:acc: 0.804688,loss:0.499102\n",
      "[epoch:40,batch:209]:acc: 0.805804,loss:0.496545\n",
      "[epoch:40,batch:239]:acc: 0.804557,loss:0.504323\n",
      "[epoch:40,batch:269]:acc: 0.806134,loss:0.501123\n",
      "[epoch:40,batch:299]:acc: 0.804896,loss:0.504075\n",
      "[epoch:40,batch:299]: val_loss:0.542645,val_acc:0.801057,val_total:4539\n",
      "[epoch:40,batch:329]:acc: 0.805966,loss:0.504946\n",
      "[epoch:40,batch:359]:acc: 0.806858,loss:0.506690\n",
      "[epoch:40,batch:389]:acc: 0.805609,loss:0.509031\n",
      "[epoch:40,batch:419]:acc: 0.806548,loss:0.507648\n",
      "[epoch:40,batch:449]:acc: 0.806181,loss:0.507396\n",
      "[epoch:40,batch:479]:acc: 0.805599,loss:0.507272\n",
      "[epoch:40,batch:509]:acc: 0.804841,loss:0.510057\n",
      "[epoch:40,batch:539]:acc: 0.805787,loss:0.509437\n",
      "[epoch:40,batch:569]:acc: 0.806634,loss:0.507803\n",
      "[epoch:40,batch:599]:acc: 0.807969,loss:0.504985\n",
      "[epoch:40,batch:599]: val_loss:0.543824,val_acc:0.804362,val_total:4539\n",
      "[epoch:40,batch:629]:acc: 0.808383,loss:0.504300\n",
      "[epoch:40,batch:659]:acc: 0.809422,loss:0.502164\n",
      "[epoch:40,batch:689]:acc: 0.809692,loss:0.502248\n",
      "[epoch:40,batch:719]:acc: 0.808854,loss:0.503235\n",
      "[epoch:40,batch:749]:acc: 0.808625,loss:0.505456\n",
      "[epoch:40,batch:779]:acc: 0.809095,loss:0.503374\n",
      "[epoch:40,batch:809]:acc: 0.810262,loss:0.501158\n",
      "[epoch:40,batch:839]:acc: 0.810268,loss:0.500270\n",
      "[epoch:40,batch:869]:acc: 0.810381,loss:0.499697\n",
      "[epoch:40,batch:899]:acc: 0.810382,loss:0.498982\n",
      "[epoch:40,batch:899]: val_loss:0.542581,val_acc:0.808328,val_total:4539\n",
      "[epoch:40,batch:929]:acc: 0.810786,loss:0.499459\n",
      "[epoch:40,batch:959]:acc: 0.810937,loss:0.499328\n",
      "[epoch:40,batch:989]:acc: 0.810638,loss:0.500088\n",
      "[epoch:40] :acc: 0.810543,loss:0.500328,lr:0.000100,patience:0\n",
      "[epoch:40]: val_loss:0.549691,val_acc:0.797973,\n",
      "Epoch 41/40\n",
      "----------\n",
      "[epoch:41,batch:29]:acc: 0.808333,loss:0.502646\n",
      "[epoch:41,batch:59]:acc: 0.821354,loss:0.475262\n",
      "[epoch:41,batch:89]:acc: 0.818750,loss:0.493631\n",
      "[epoch:41,batch:119]:acc: 0.819271,loss:0.492432\n",
      "[epoch:41,batch:149]:acc: 0.817083,loss:0.502934\n",
      "[epoch:41,batch:179]:acc: 0.814931,loss:0.504257\n",
      "[epoch:41,batch:209]:acc: 0.818452,loss:0.492746\n",
      "[epoch:41,batch:239]:acc: 0.816146,loss:0.496347\n",
      "[epoch:41,batch:269]:acc: 0.815394,loss:0.494617\n",
      "[epoch:41,batch:299]:acc: 0.815625,loss:0.496670\n",
      "[epoch:41,batch:299]: val_loss:0.560458,val_acc:0.800837,val_total:4539\n",
      "[epoch:41,batch:329]:acc: 0.815625,loss:0.494978\n",
      "[epoch:41,batch:359]:acc: 0.816927,loss:0.490808\n",
      "[epoch:41,batch:389]:acc: 0.816106,loss:0.491528\n",
      "[epoch:41,batch:419]:acc: 0.816592,loss:0.494293\n",
      "[epoch:41,batch:449]:acc: 0.816736,loss:0.494022\n",
      "[epoch:41,batch:479]:acc: 0.816211,loss:0.494970\n",
      "[epoch:41,batch:509]:acc: 0.816728,loss:0.493782\n",
      "[epoch:41,batch:539]:acc: 0.815509,loss:0.495366\n",
      "[epoch:41,batch:569]:acc: 0.815351,loss:0.495679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:41,batch:599]:acc: 0.815156,loss:0.497835\n",
      "[epoch:41,batch:599]: val_loss:0.554506,val_acc:0.793567,val_total:4539\n",
      "[epoch:41,batch:629]:acc: 0.813194,loss:0.501797\n",
      "[epoch:41,batch:659]:acc: 0.813116,loss:0.502458\n",
      "[epoch:41,batch:689]:acc: 0.813225,loss:0.502714\n",
      "[epoch:41,batch:719]:acc: 0.813889,loss:0.502992\n",
      "[epoch:41,batch:749]:acc: 0.812792,loss:0.504062\n",
      "[epoch:41,batch:779]:acc: 0.813021,loss:0.504487\n",
      "[epoch:41,batch:809]:acc: 0.811998,loss:0.505664\n",
      "[epoch:41,batch:839]:acc: 0.811570,loss:0.507029\n",
      "[epoch:41,batch:869]:acc: 0.811243,loss:0.506567\n",
      "[epoch:41,batch:899]:acc: 0.811215,loss:0.506618\n",
      "[epoch:41,batch:899]: val_loss:0.523980,val_acc:0.813615,val_total:4539\n",
      "[epoch:41,batch:929]:acc: 0.811727,loss:0.505513\n",
      "[epoch:41,batch:959]:acc: 0.811751,loss:0.506762\n",
      "[epoch:41,batch:989]:acc: 0.811458,loss:0.509204\n",
      "[epoch:41] :acc: 0.811331,loss:0.510289,lr:0.000100,patience:1\n",
      "[epoch:41]: val_loss:0.573762,val_acc:0.801939,\n",
      "Epoch 42/40\n",
      "----------\n",
      "[epoch:42,batch:29]:acc: 0.803125,loss:0.528682\n",
      "[epoch:42,batch:59]:acc: 0.817187,loss:0.508524\n",
      "[epoch:42,batch:89]:acc: 0.815278,loss:0.502900\n",
      "[epoch:42,batch:119]:acc: 0.820312,loss:0.491386\n",
      "[epoch:42,batch:149]:acc: 0.812083,loss:0.511947\n",
      "[epoch:42,batch:179]:acc: 0.813368,loss:0.507980\n",
      "[epoch:42,batch:209]:acc: 0.813095,loss:0.505003\n",
      "[epoch:42,batch:239]:acc: 0.813151,loss:0.507824\n",
      "[epoch:42,batch:269]:acc: 0.811921,loss:0.508607\n",
      "[epoch:42,batch:299]:acc: 0.812813,loss:0.506689\n",
      "[epoch:42,batch:299]: val_loss:0.534348,val_acc:0.818903,val_total:4539\n",
      "[epoch:42,batch:329]:acc: 0.811742,loss:0.508599\n",
      "[epoch:42,batch:359]:acc: 0.812847,loss:0.504447\n",
      "[epoch:42,batch:389]:acc: 0.811458,loss:0.509618\n",
      "[epoch:42,batch:419]:acc: 0.813542,loss:0.506120\n",
      "[epoch:42,batch:449]:acc: 0.815139,loss:0.501088\n",
      "[epoch:42,batch:479]:acc: 0.814128,loss:0.505286\n",
      "[epoch:42,batch:509]:acc: 0.814277,loss:0.502008\n",
      "[epoch:42,batch:539]:acc: 0.814988,loss:0.501106\n",
      "[epoch:42,batch:569]:acc: 0.814035,loss:0.502299\n",
      "[epoch:42,batch:599]:acc: 0.813229,loss:0.504302\n",
      "[epoch:42,batch:599]: val_loss:0.588444,val_acc:0.805904,val_total:4539\n",
      "[epoch:42,batch:629]:acc: 0.812599,loss:0.504330\n",
      "[epoch:42,batch:659]:acc: 0.812358,loss:0.504704\n",
      "[epoch:42,batch:689]:acc: 0.812228,loss:0.504534\n",
      "[epoch:42,batch:719]:acc: 0.811719,loss:0.504222\n",
      "[epoch:42,batch:749]:acc: 0.811625,loss:0.503098\n",
      "[epoch:42,batch:779]:acc: 0.812139,loss:0.501472\n",
      "[epoch:42,batch:809]:acc: 0.812539,loss:0.500078\n",
      "[epoch:42,batch:839]:acc: 0.812835,loss:0.498739\n",
      "[epoch:42,batch:869]:acc: 0.812500,loss:0.499061\n",
      "[epoch:42,batch:899]:acc: 0.813090,loss:0.497489\n",
      "[epoch:42,batch:899]: val_loss:0.555983,val_acc:0.812514,val_total:4539\n",
      "[epoch:42,batch:929]:acc: 0.812634,loss:0.498201\n",
      "[epoch:42,batch:959]:acc: 0.812760,loss:0.498495\n",
      "[epoch:42,batch:989]:acc: 0.813068,loss:0.497474\n",
      "[epoch:42] :acc: 0.813034,loss:0.497079,lr:0.000100,patience:0\n",
      "[epoch:42]: val_loss:0.561810,val_acc:0.798854,\n",
      "Epoch 43/42\n",
      "----------\n",
      "[epoch:43,batch:29]:acc: 0.822917,loss:0.488790\n",
      "[epoch:43,batch:59]:acc: 0.820312,loss:0.471665\n",
      "[epoch:43,batch:89]:acc: 0.817361,loss:0.486146\n",
      "[epoch:43,batch:119]:acc: 0.820573,loss:0.483291\n",
      "[epoch:43,batch:149]:acc: 0.817083,loss:0.491504\n",
      "[epoch:43,batch:179]:acc: 0.819097,loss:0.485826\n",
      "[epoch:43,batch:209]:acc: 0.814286,loss:0.499110\n",
      "[epoch:43,batch:239]:acc: 0.813151,loss:0.505753\n",
      "[epoch:43,batch:269]:acc: 0.810532,loss:0.510885\n",
      "[epoch:43,batch:299]:acc: 0.809688,loss:0.513046\n",
      "[epoch:43,batch:299]: val_loss:0.540203,val_acc:0.799956,val_total:4539\n",
      "[epoch:43,batch:329]:acc: 0.810511,loss:0.508459\n",
      "[epoch:43,batch:359]:acc: 0.811458,loss:0.505074\n",
      "[epoch:43,batch:389]:acc: 0.809856,loss:0.506127\n",
      "[epoch:43,batch:419]:acc: 0.809375,loss:0.505560\n",
      "[epoch:43,batch:449]:acc: 0.809167,loss:0.504508\n",
      "[epoch:43,batch:479]:acc: 0.809896,loss:0.503745\n",
      "[epoch:43,batch:509]:acc: 0.810846,loss:0.503334\n",
      "[epoch:43,batch:539]:acc: 0.810995,loss:0.504488\n",
      "[epoch:43,batch:569]:acc: 0.811404,loss:0.505674\n",
      "[epoch:43,batch:599]:acc: 0.810260,loss:0.506886\n",
      "[epoch:43,batch:599]: val_loss:0.526992,val_acc:0.812073,val_total:4539\n",
      "[epoch:43,batch:629]:acc: 0.811111,loss:0.505237\n",
      "[epoch:43,batch:659]:acc: 0.812169,loss:0.501702\n",
      "[epoch:43,batch:689]:acc: 0.812409,loss:0.502094\n",
      "[epoch:43,batch:719]:acc: 0.812326,loss:0.503175\n",
      "[epoch:43,batch:749]:acc: 0.813125,loss:0.501755\n",
      "[epoch:43,batch:779]:acc: 0.813421,loss:0.500819\n",
      "[epoch:43,batch:809]:acc: 0.814043,loss:0.500461\n",
      "[epoch:43,batch:839]:acc: 0.814360,loss:0.499677\n",
      "[epoch:43,batch:869]:acc: 0.813649,loss:0.502147\n",
      "[epoch:43,batch:899]:acc: 0.813299,loss:0.502432\n",
      "[epoch:43,batch:899]: val_loss:0.526427,val_acc:0.808107,val_total:4539\n",
      "[epoch:43,batch:929]:acc: 0.813273,loss:0.502097\n",
      "[epoch:43,batch:959]:acc: 0.812923,loss:0.502337\n",
      "[epoch:43,batch:989]:acc: 0.812847,loss:0.501739\n",
      "[epoch:43] :acc: 0.812813,loss:0.501805,lr:0.000100,patience:1\n",
      "[epoch:43]: val_loss:0.545602,val_acc:0.805243,\n",
      "Epoch 44/42\n",
      "----------\n",
      "[epoch:44,batch:29]:acc: 0.818750,loss:0.504523\n",
      "[epoch:44,batch:59]:acc: 0.824479,loss:0.513981\n",
      "[epoch:44,batch:89]:acc: 0.820486,loss:0.511282\n",
      "[epoch:44,batch:119]:acc: 0.819792,loss:0.512280\n",
      "[epoch:44,batch:149]:acc: 0.821458,loss:0.503609\n",
      "[epoch:44,batch:179]:acc: 0.819097,loss:0.508096\n",
      "[epoch:44,batch:209]:acc: 0.819196,loss:0.506110\n",
      "[epoch:44,batch:239]:acc: 0.820312,loss:0.505169\n",
      "[epoch:44,batch:269]:acc: 0.817593,loss:0.512516\n",
      "[epoch:44,batch:299]:acc: 0.815833,loss:0.509522\n",
      "[epoch:44,batch:299]: val_loss:0.532818,val_acc:0.817361,val_total:4539\n",
      "[epoch:44,batch:329]:acc: 0.816951,loss:0.509155\n",
      "[epoch:44,batch:359]:acc: 0.817274,loss:0.504744\n",
      "[epoch:44,batch:389]:acc: 0.815385,loss:0.504996\n",
      "[epoch:44,batch:419]:acc: 0.815774,loss:0.503987\n",
      "[epoch:44,batch:449]:acc: 0.815347,loss:0.505969\n",
      "[epoch:44,batch:479]:acc: 0.816341,loss:0.501959\n",
      "[epoch:44,batch:509]:acc: 0.815870,loss:0.502065\n",
      "[epoch:44,batch:539]:acc: 0.816088,loss:0.502005\n",
      "[epoch:44,batch:569]:acc: 0.813925,loss:0.507239\n",
      "[epoch:44,batch:599]:acc: 0.813698,loss:0.505546\n",
      "[epoch:44,batch:599]: val_loss:0.540593,val_acc:0.806565,val_total:4539\n",
      "[epoch:44,batch:629]:acc: 0.813244,loss:0.506396\n",
      "[epoch:44,batch:659]:acc: 0.812737,loss:0.505904\n",
      "[epoch:44,batch:689]:acc: 0.813134,loss:0.503391\n",
      "[epoch:44,batch:719]:acc: 0.813455,loss:0.503541\n",
      "[epoch:44,batch:749]:acc: 0.813792,loss:0.503643\n",
      "[epoch:44,batch:779]:acc: 0.814063,loss:0.502889\n",
      "[epoch:44,batch:809]:acc: 0.813927,loss:0.505191\n",
      "[epoch:44,batch:839]:acc: 0.814100,loss:0.504148\n",
      "[epoch:44,batch:869]:acc: 0.814152,loss:0.503371\n",
      "[epoch:44,batch:899]:acc: 0.813785,loss:0.503674\n",
      "[epoch:44,batch:899]: val_loss:0.547043,val_acc:0.818462,val_total:4539\n",
      "[epoch:44,batch:929]:acc: 0.813710,loss:0.504691\n",
      "[epoch:44,batch:959]:acc: 0.813477,loss:0.505720\n",
      "[epoch:44,batch:989]:acc: 0.812910,loss:0.506078\n",
      "[epoch:44] :acc: 0.812813,loss:0.506135,lr:0.000100,patience:0\n",
      "[epoch:44]: val_loss:0.532462,val_acc:0.807667,\n",
      "Epoch 45/44\n",
      "----------\n",
      "[epoch:45,batch:29]:acc: 0.793750,loss:0.562258\n",
      "[epoch:45,batch:59]:acc: 0.804167,loss:0.542745\n",
      "[epoch:45,batch:89]:acc: 0.809028,loss:0.518378\n",
      "[epoch:45,batch:119]:acc: 0.810677,loss:0.514258\n",
      "[epoch:45,batch:149]:acc: 0.809583,loss:0.514909\n",
      "[epoch:45,batch:179]:acc: 0.809201,loss:0.508502\n",
      "[epoch:45,batch:209]:acc: 0.806548,loss:0.514009\n",
      "[epoch:45,batch:239]:acc: 0.808594,loss:0.513608\n",
      "[epoch:45,batch:269]:acc: 0.806944,loss:0.514313\n",
      "[epoch:45,batch:299]:acc: 0.805625,loss:0.514710\n",
      "[epoch:45,batch:299]: val_loss:0.522053,val_acc:0.817581,val_total:4539\n",
      "[epoch:45,batch:329]:acc: 0.806345,loss:0.511545\n",
      "[epoch:45,batch:359]:acc: 0.807813,loss:0.510854\n",
      "[epoch:45,batch:389]:acc: 0.809135,loss:0.508822\n",
      "[epoch:45,batch:419]:acc: 0.808631,loss:0.509301\n",
      "[epoch:45,batch:449]:acc: 0.809861,loss:0.504730\n",
      "[epoch:45,batch:479]:acc: 0.810352,loss:0.504133\n",
      "[epoch:45,batch:509]:acc: 0.810172,loss:0.502842\n",
      "[epoch:45,batch:539]:acc: 0.811053,loss:0.501762\n",
      "[epoch:45,batch:569]:acc: 0.811623,loss:0.500302\n",
      "[epoch:45,batch:599]:acc: 0.812187,loss:0.498842\n",
      "[epoch:45,batch:599]: val_loss:0.516973,val_acc:0.811192,val_total:4539\n",
      "[epoch:45,batch:629]:acc: 0.811508,loss:0.500062\n",
      "[epoch:45,batch:659]:acc: 0.811269,loss:0.500402\n",
      "[epoch:45,batch:689]:acc: 0.811911,loss:0.497623\n",
      "[epoch:45,batch:719]:acc: 0.811415,loss:0.497726\n",
      "[epoch:45,batch:749]:acc: 0.811500,loss:0.498627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:45,batch:779]:acc: 0.811258,loss:0.498558\n",
      "[epoch:45,batch:809]:acc: 0.811150,loss:0.497835\n",
      "[epoch:45,batch:839]:acc: 0.812016,loss:0.497222\n",
      "[epoch:45,batch:869]:acc: 0.812141,loss:0.496398\n",
      "[epoch:45,batch:899]:acc: 0.812743,loss:0.496520\n",
      "[epoch:45,batch:899]: val_loss:0.526196,val_acc:0.807447,val_total:4539\n",
      "[epoch:45,batch:929]:acc: 0.812836,loss:0.496730\n",
      "[epoch:45,batch:959]:acc: 0.812760,loss:0.498616\n",
      "[epoch:45,batch:989]:acc: 0.812279,loss:0.500689\n",
      "[epoch:45] :acc: 0.812372,loss:0.500298,lr:0.000100,patience:1\n",
      "[epoch:45]: val_loss:0.527055,val_acc:0.808107,\n",
      "save new model loss,now loss is  0.5270546078681946\n",
      "Epoch 46/44\n",
      "----------\n",
      "[epoch:46,batch:29]:acc: 0.825000,loss:0.479798\n",
      "[epoch:46,batch:59]:acc: 0.828125,loss:0.491391\n",
      "[epoch:46,batch:89]:acc: 0.824306,loss:0.488637\n",
      "[epoch:46,batch:119]:acc: 0.825260,loss:0.483726\n",
      "[epoch:46,batch:149]:acc: 0.823125,loss:0.482113\n",
      "[epoch:46,batch:179]:acc: 0.817361,loss:0.499783\n",
      "[epoch:46,batch:209]:acc: 0.817857,loss:0.490664\n",
      "[epoch:46,batch:239]:acc: 0.817448,loss:0.495727\n",
      "[epoch:46,batch:269]:acc: 0.818519,loss:0.492471\n",
      "[epoch:46,batch:299]:acc: 0.817917,loss:0.493681\n",
      "[epoch:46,batch:299]: val_loss:0.541035,val_acc:0.808548,val_total:4539\n",
      "[epoch:46,batch:329]:acc: 0.818750,loss:0.490142\n",
      "[epoch:46,batch:359]:acc: 0.819097,loss:0.487338\n",
      "[epoch:46,batch:389]:acc: 0.818990,loss:0.487645\n",
      "[epoch:46,batch:419]:acc: 0.819940,loss:0.488419\n",
      "[epoch:46,batch:449]:acc: 0.819028,loss:0.487661\n",
      "[epoch:46,batch:479]:acc: 0.817448,loss:0.492277\n",
      "[epoch:46,batch:509]:acc: 0.816667,loss:0.494768\n",
      "[epoch:46,batch:539]:acc: 0.816898,loss:0.495376\n",
      "[epoch:46,batch:569]:acc: 0.816393,loss:0.497672\n",
      "[epoch:46,batch:599]:acc: 0.816823,loss:0.496578\n",
      "[epoch:46,batch:599]: val_loss:0.531719,val_acc:0.807887,val_total:4539\n",
      "[epoch:46,batch:629]:acc: 0.816220,loss:0.498973\n",
      "[epoch:46,batch:659]:acc: 0.816335,loss:0.499401\n",
      "[epoch:46,batch:689]:acc: 0.816123,loss:0.498614\n",
      "[epoch:46,batch:719]:acc: 0.815148,loss:0.498831\n",
      "[epoch:46,batch:749]:acc: 0.814625,loss:0.499660\n",
      "[epoch:46,batch:779]:acc: 0.815304,loss:0.500041\n",
      "[epoch:46,batch:809]:acc: 0.814892,loss:0.500730\n",
      "[epoch:46,batch:839]:acc: 0.815216,loss:0.498450\n",
      "[epoch:46,batch:869]:acc: 0.815409,loss:0.497866\n",
      "[epoch:46,batch:899]:acc: 0.815035,loss:0.499647\n",
      "[epoch:46,batch:899]: val_loss:0.538896,val_acc:0.805023,val_total:4539\n",
      "[epoch:46,batch:929]:acc: 0.814315,loss:0.499925\n",
      "[epoch:46,batch:959]:acc: 0.814714,loss:0.499096\n",
      "[epoch:46,batch:989]:acc: 0.814236,loss:0.500982\n",
      "[epoch:46] :acc: 0.814232,loss:0.501158,lr:0.000100,patience:0\n",
      "[epoch:46]: val_loss:0.536314,val_acc:0.803701,\n",
      "Epoch 47/44\n",
      "----------\n",
      "[epoch:47,batch:29]:acc: 0.819792,loss:0.513792\n",
      "[epoch:47,batch:59]:acc: 0.817708,loss:0.504596\n",
      "[epoch:47,batch:89]:acc: 0.813889,loss:0.512161\n",
      "[epoch:47,batch:119]:acc: 0.817448,loss:0.498750\n",
      "[epoch:47,batch:149]:acc: 0.816042,loss:0.494210\n",
      "[epoch:47,batch:179]:acc: 0.812326,loss:0.505143\n",
      "[epoch:47,batch:209]:acc: 0.813690,loss:0.504402\n",
      "[epoch:47,batch:239]:acc: 0.813932,loss:0.503465\n",
      "[epoch:47,batch:269]:acc: 0.815394,loss:0.498154\n",
      "[epoch:47,batch:299]:acc: 0.816667,loss:0.498628\n",
      "[epoch:47,batch:299]: val_loss:0.547203,val_acc:0.798193,val_total:4539\n",
      "[epoch:47,batch:329]:acc: 0.815909,loss:0.501200\n",
      "[epoch:47,batch:359]:acc: 0.815625,loss:0.499939\n",
      "[epoch:47,batch:389]:acc: 0.816747,loss:0.496349\n",
      "[epoch:47,batch:419]:acc: 0.815625,loss:0.496590\n",
      "[epoch:47,batch:449]:acc: 0.813264,loss:0.498485\n",
      "[epoch:47,batch:479]:acc: 0.812891,loss:0.499936\n",
      "[epoch:47,batch:509]:acc: 0.813480,loss:0.497737\n",
      "[epoch:47,batch:539]:acc: 0.813657,loss:0.497454\n",
      "[epoch:47,batch:569]:acc: 0.813542,loss:0.498632\n",
      "[epoch:47,batch:599]:acc: 0.814635,loss:0.497822\n",
      "[epoch:47,batch:599]: val_loss:0.534245,val_acc:0.804582,val_total:4539\n",
      "[epoch:47,batch:629]:acc: 0.814881,loss:0.497334\n",
      "[epoch:47,batch:659]:acc: 0.814678,loss:0.497937\n",
      "[epoch:47,batch:689]:acc: 0.814266,loss:0.497805\n",
      "[epoch:47,batch:719]:acc: 0.813672,loss:0.499876\n",
      "[epoch:47,batch:749]:acc: 0.814167,loss:0.500058\n",
      "[epoch:47,batch:779]:acc: 0.814784,loss:0.497792\n",
      "[epoch:47,batch:809]:acc: 0.814198,loss:0.499687\n",
      "[epoch:47,batch:839]:acc: 0.814100,loss:0.501869\n",
      "[epoch:47,batch:869]:acc: 0.813865,loss:0.501523\n",
      "[epoch:47,batch:899]:acc: 0.814097,loss:0.500325\n",
      "[epoch:47,batch:899]: val_loss:0.520519,val_acc:0.805904,val_total:4539\n",
      "[epoch:47,batch:929]:acc: 0.814247,loss:0.499815\n",
      "[epoch:47,batch:959]:acc: 0.814746,loss:0.498813\n",
      "[epoch:47,batch:989]:acc: 0.814646,loss:0.499270\n",
      "[epoch:47] :acc: 0.814737,loss:0.498936,lr:0.000100,patience:1\n",
      "[epoch:47]: val_loss:0.533145,val_acc:0.800837,\n",
      "Epoch 48/44\n",
      "----------\n",
      "[epoch:48,batch:29]:acc: 0.805208,loss:0.563463\n",
      "[epoch:48,batch:59]:acc: 0.806771,loss:0.543629\n",
      "[epoch:48,batch:89]:acc: 0.811111,loss:0.518662\n",
      "[epoch:48,batch:119]:acc: 0.811979,loss:0.514629\n",
      "[epoch:48,batch:149]:acc: 0.813125,loss:0.515241\n",
      "[epoch:48,batch:179]:acc: 0.814931,loss:0.508215\n",
      "[epoch:48,batch:209]:acc: 0.816369,loss:0.505671\n",
      "[epoch:48,batch:239]:acc: 0.816667,loss:0.499806\n",
      "[epoch:48,batch:269]:acc: 0.814120,loss:0.505853\n",
      "[epoch:48,batch:299]:acc: 0.812187,loss:0.506950\n",
      "[epoch:48,batch:299]: val_loss:0.538381,val_acc:0.794889,val_total:4539\n",
      "[epoch:48,batch:329]:acc: 0.814962,loss:0.497319\n",
      "[epoch:48,batch:359]:acc: 0.815538,loss:0.496057\n",
      "[epoch:48,batch:389]:acc: 0.816186,loss:0.494950\n",
      "[epoch:48,batch:419]:acc: 0.816667,loss:0.493881\n",
      "[epoch:48,batch:449]:acc: 0.816667,loss:0.493132\n",
      "[epoch:48,batch:479]:acc: 0.817318,loss:0.489909\n",
      "[epoch:48,batch:509]:acc: 0.816973,loss:0.490662\n",
      "[epoch:48,batch:539]:acc: 0.817650,loss:0.487905\n",
      "[epoch:48,batch:569]:acc: 0.816721,loss:0.489521\n",
      "[epoch:48,batch:599]:acc: 0.817240,loss:0.489556\n",
      "[epoch:48,batch:599]: val_loss:0.548845,val_acc:0.805023,val_total:4539\n",
      "[epoch:48,batch:629]:acc: 0.816667,loss:0.490926\n",
      "[epoch:48,batch:659]:acc: 0.816951,loss:0.489797\n",
      "[epoch:48,batch:689]:acc: 0.817210,loss:0.490345\n",
      "[epoch:48,batch:719]:acc: 0.817925,loss:0.490838\n",
      "[epoch:48,batch:749]:acc: 0.818250,loss:0.490062\n",
      "[epoch:48,batch:779]:acc: 0.817949,loss:0.490710\n",
      "[epoch:48,batch:809]:acc: 0.818287,loss:0.489116\n",
      "[epoch:48,batch:839]:acc: 0.817857,loss:0.490584\n",
      "[epoch:48,batch:869]:acc: 0.818032,loss:0.490792\n",
      "[epoch:48,batch:899]:acc: 0.817951,loss:0.491001\n",
      "[epoch:48,batch:899]: val_loss:0.552598,val_acc:0.794228,val_total:4539\n",
      "[epoch:48,batch:929]:acc: 0.817776,loss:0.491014\n",
      "[epoch:48,batch:959]:acc: 0.817415,loss:0.491738\n",
      "[epoch:48,batch:989]:acc: 0.817298,loss:0.491816\n",
      "[epoch:48] :acc: 0.817196,loss:0.491740,lr:0.000100,patience:0\n",
      "[epoch:48]: val_loss:0.539628,val_acc:0.804142,\n",
      "Epoch 49/48\n",
      "----------\n",
      "[epoch:49,batch:29]:acc: 0.820833,loss:0.499609\n",
      "[epoch:49,batch:59]:acc: 0.816667,loss:0.494682\n",
      "[epoch:49,batch:89]:acc: 0.816319,loss:0.497154\n",
      "[epoch:49,batch:119]:acc: 0.810677,loss:0.504427\n",
      "[epoch:49,batch:149]:acc: 0.813542,loss:0.503198\n",
      "[epoch:49,batch:179]:acc: 0.812674,loss:0.500737\n",
      "[epoch:49,batch:209]:acc: 0.813690,loss:0.500931\n",
      "[epoch:49,batch:239]:acc: 0.813281,loss:0.496937\n",
      "[epoch:49,batch:269]:acc: 0.814352,loss:0.495302\n",
      "[epoch:49,batch:299]:acc: 0.814271,loss:0.497648\n",
      "[epoch:49,batch:299]: val_loss:0.530305,val_acc:0.818022,val_total:4539\n",
      "[epoch:49,batch:329]:acc: 0.810890,loss:0.507882\n",
      "[epoch:49,batch:359]:acc: 0.811892,loss:0.508293\n",
      "[epoch:49,batch:389]:acc: 0.812901,loss:0.507225\n",
      "[epoch:49,batch:419]:acc: 0.812872,loss:0.506036\n",
      "[epoch:49,batch:449]:acc: 0.810486,loss:0.511825\n",
      "[epoch:49,batch:479]:acc: 0.812565,loss:0.508575\n",
      "[epoch:49,batch:509]:acc: 0.812684,loss:0.509685\n",
      "[epoch:49,batch:539]:acc: 0.812211,loss:0.509299\n",
      "[epoch:49,batch:569]:acc: 0.812829,loss:0.507341\n",
      "[epoch:49,batch:599]:acc: 0.813333,loss:0.507319\n",
      "[epoch:49,batch:599]: val_loss:0.542209,val_acc:0.810090,val_total:4539\n",
      "[epoch:49,batch:629]:acc: 0.813194,loss:0.507402\n",
      "[epoch:49,batch:659]:acc: 0.813636,loss:0.508168\n",
      "[epoch:49,batch:689]:acc: 0.814266,loss:0.505097\n",
      "[epoch:49,batch:719]:acc: 0.814844,loss:0.504366\n",
      "[epoch:49,batch:749]:acc: 0.815083,loss:0.504075\n",
      "[epoch:49,batch:779]:acc: 0.814423,loss:0.506328\n",
      "[epoch:49,batch:809]:acc: 0.813966,loss:0.506196\n",
      "[epoch:49,batch:839]:acc: 0.813542,loss:0.506404\n",
      "[epoch:49,batch:869]:acc: 0.813398,loss:0.505515\n",
      "[epoch:49,batch:899]:acc: 0.813368,loss:0.505808\n",
      "[epoch:49,batch:899]: val_loss:0.561298,val_acc:0.793787,val_total:4539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:49,batch:929]:acc: 0.814113,loss:0.504441\n",
      "[epoch:49,batch:959]:acc: 0.813867,loss:0.504070\n",
      "[epoch:49,batch:989]:acc: 0.814110,loss:0.503091\n",
      "[epoch:49] :acc: 0.814138,loss:0.503089,lr:0.000100,patience:1\n",
      "[epoch:49]: val_loss:0.541961,val_acc:0.802379,\n",
      "Epoch 50/48\n",
      "----------\n",
      "[epoch:50,batch:29]:acc: 0.808333,loss:0.521663\n",
      "[epoch:50,batch:59]:acc: 0.804167,loss:0.532574\n",
      "[epoch:50,batch:89]:acc: 0.812500,loss:0.502313\n",
      "[epoch:50,batch:119]:acc: 0.808594,loss:0.518660\n",
      "[epoch:50,batch:149]:acc: 0.809583,loss:0.509177\n",
      "[epoch:50,batch:179]:acc: 0.810069,loss:0.502335\n",
      "[epoch:50,batch:209]:acc: 0.815923,loss:0.491289\n",
      "[epoch:50,batch:239]:acc: 0.815625,loss:0.492033\n",
      "[epoch:50,batch:269]:acc: 0.817245,loss:0.491163\n",
      "[epoch:50,batch:299]:acc: 0.818229,loss:0.485668\n",
      "[epoch:50,batch:299]: val_loss:0.530020,val_acc:0.806565,val_total:4539\n",
      "[epoch:50,batch:329]:acc: 0.819792,loss:0.481528\n",
      "[epoch:50,batch:359]:acc: 0.818576,loss:0.483799\n",
      "[epoch:50,batch:389]:acc: 0.817548,loss:0.487223\n"
     ]
    }
   ],
   "source": [
    "train(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model... Done\n",
      "min_loss is :0.383656\n",
      "val_correct is 0.862084\n",
      "Epoch 72/89\n",
      "----------\n",
      "lr now is 0.010000\n",
      "now patience is 0 \n",
      "[epoch:72,batch:29]:acc: 0.782292,loss:0.769916\n",
      "[epoch:72,batch:59]:acc: 0.615104,loss:1.720353\n",
      "[epoch:72,batch:89]:acc: 0.569792,loss:1.830606\n",
      "[epoch:72,batch:119]:acc: 0.577344,loss:1.719513\n",
      "[epoch:72,batch:149]:acc: 0.592500,loss:1.576185\n",
      "[epoch:72,batch:179]:acc: 0.614583,loss:1.451779\n",
      "[epoch:72,batch:209]:acc: 0.633036,loss:1.345298\n",
      "[epoch:72,batch:239]:acc: 0.645833,loss:1.275229\n",
      "[epoch:72,batch:269]:acc: 0.656829,loss:1.209314\n",
      "[epoch:72,batch:299]:acc: 0.666458,loss:1.156987\n",
      "[epoch:72,batch:299]: val_loss:0.622181,val_acc:0.767350,val_total:4539\n",
      "[epoch:72,batch:329]:acc: 0.676231,loss:1.109793\n",
      "[epoch:72,batch:359]:acc: 0.681684,loss:1.075536\n",
      "[epoch:72,batch:389]:acc: 0.687821,loss:1.040372\n",
      "[epoch:72,batch:419]:acc: 0.695238,loss:1.004598\n",
      "[epoch:72,batch:449]:acc: 0.702917,loss:0.972748\n",
      "[epoch:72,batch:479]:acc: 0.706510,loss:0.952404\n",
      "[epoch:72,batch:509]:acc: 0.709620,loss:0.930932\n",
      "[epoch:72,batch:539]:acc: 0.713252,loss:0.913919\n",
      "[epoch:72,batch:569]:acc: 0.717325,loss:0.896768\n",
      "[epoch:72,batch:599]:acc: 0.720469,loss:0.879898\n",
      "[epoch:72,batch:599]: val_loss:0.557564,val_acc:0.797532,val_total:4539\n",
      "[epoch:72,batch:629]:acc: 0.724504,loss:0.861559\n",
      "[epoch:72,batch:659]:acc: 0.728314,loss:0.846682\n",
      "[epoch:72,batch:689]:acc: 0.730525,loss:0.834163\n",
      "[epoch:72,batch:719]:acc: 0.732726,loss:0.821816\n",
      "[epoch:72,batch:749]:acc: 0.735333,loss:0.810309\n",
      "[epoch:72,batch:779]:acc: 0.737420,loss:0.800177\n",
      "[epoch:72,batch:809]:acc: 0.739776,loss:0.788333\n",
      "[epoch:72,batch:839]:acc: 0.742039,loss:0.778045\n",
      "[epoch:72,batch:869]:acc: 0.744145,loss:0.768278\n",
      "[epoch:72,batch:899]:acc: 0.746458,loss:0.757871\n",
      "[epoch:72,batch:899]: val_loss:0.510215,val_acc:0.801498,val_total:4539\n",
      "[epoch:72,batch:929]:acc: 0.748085,loss:0.751290\n",
      "[epoch:72,batch:959]:acc: 0.749902,loss:0.743750\n",
      "[epoch:72,batch:989]:acc: 0.751515,loss:0.735968\n",
      "[epoch:72] :acc: 0.751616,loss:0.736040,lr:0.010000,patience:0\n",
      "[epoch:72]: val_loss:0.517958,val_acc:0.793126,\n",
      "Epoch 73/89\n",
      "----------\n",
      "lr now is 0.010000\n",
      "now patience is 1 \n",
      "[epoch:73,batch:29]:acc: 0.836458,loss:0.423087\n",
      "[epoch:73,batch:59]:acc: 0.828125,loss:0.448030\n",
      "[epoch:73,batch:89]:acc: 0.824306,loss:0.445054\n",
      "[epoch:73,batch:119]:acc: 0.821875,loss:0.446779\n",
      "[epoch:73,batch:149]:acc: 0.819792,loss:0.445920\n",
      "[epoch:73,batch:179]:acc: 0.818750,loss:0.446786\n",
      "[epoch:73,batch:209]:acc: 0.816518,loss:0.448346\n",
      "[epoch:73,batch:239]:acc: 0.815755,loss:0.452712\n",
      "[epoch:73,batch:269]:acc: 0.817014,loss:0.448512\n",
      "[epoch:73,batch:299]:acc: 0.815625,loss:0.452105\n",
      "[epoch:73,batch:299]: val_loss:0.450116,val_acc:0.813175,val_total:4539\n",
      "[epoch:73,batch:329]:acc: 0.815909,loss:0.452389\n",
      "[epoch:73,batch:359]:acc: 0.815799,loss:0.452189\n",
      "[epoch:73,batch:389]:acc: 0.816987,loss:0.451107\n",
      "[epoch:73,batch:419]:acc: 0.818006,loss:0.450466\n",
      "[epoch:73,batch:449]:acc: 0.819236,loss:0.447319\n",
      "[epoch:73,batch:479]:acc: 0.819206,loss:0.449481\n",
      "[epoch:73,batch:509]:acc: 0.818505,loss:0.451063\n",
      "[epoch:73,batch:539]:acc: 0.818924,loss:0.450187\n",
      "[epoch:73,batch:569]:acc: 0.817928,loss:0.452650\n",
      "[epoch:73,batch:599]:acc: 0.817552,loss:0.455730\n",
      "[epoch:73,batch:599]: val_loss:0.452041,val_acc:0.824631,val_total:4539\n",
      "[epoch:73,batch:629]:acc: 0.816915,loss:0.456929\n",
      "[epoch:73,batch:659]:acc: 0.817519,loss:0.455373\n",
      "[epoch:73,batch:689]:acc: 0.818750,loss:0.452475\n",
      "[epoch:73,batch:719]:acc: 0.819661,loss:0.451411\n",
      "[epoch:73,batch:749]:acc: 0.819500,loss:0.451253\n",
      "[epoch:73,batch:779]:acc: 0.819111,loss:0.452597\n",
      "[epoch:73,batch:809]:acc: 0.818403,loss:0.453338\n",
      "[epoch:73,batch:839]:acc: 0.818192,loss:0.452999\n",
      "[epoch:73,batch:869]:acc: 0.818032,loss:0.452351\n",
      "[epoch:73,batch:899]:acc: 0.819028,loss:0.450709\n",
      "[epoch:73,batch:899]: val_loss:0.472360,val_acc:0.815598,val_total:4539\n",
      "[epoch:73,batch:929]:acc: 0.819590,loss:0.450520\n",
      "[epoch:73,batch:959]:acc: 0.819368,loss:0.450509\n",
      "[epoch:73,batch:989]:acc: 0.819792,loss:0.449293\n",
      "[epoch:73] :acc: 0.819844,loss:0.450300,lr:0.010000,patience:1\n",
      "[epoch:73]: val_loss:0.449011,val_acc:0.822648,\n",
      "Epoch 74/89\n",
      "----------\n",
      "lr now is 0.001000\n",
      "now patience is 2 \n",
      "[epoch:74,batch:29]:acc: 0.846875,loss:0.368239\n",
      "[epoch:74,batch:59]:acc: 0.845833,loss:0.363147\n",
      "[epoch:74,batch:89]:acc: 0.851042,loss:0.354679\n",
      "[epoch:74,batch:119]:acc: 0.853646,loss:0.349710\n",
      "[epoch:74,batch:149]:acc: 0.856042,loss:0.340549\n",
      "[epoch:74,batch:179]:acc: 0.859375,loss:0.335346\n",
      "[epoch:74,batch:209]:acc: 0.860714,loss:0.333194\n",
      "[epoch:74,batch:239]:acc: 0.863411,loss:0.329689\n",
      "[epoch:74,batch:269]:acc: 0.864931,loss:0.328127\n",
      "[epoch:74,batch:299]:acc: 0.866458,loss:0.325472\n",
      "[epoch:74,batch:299]: val_loss:0.364033,val_acc:0.850628,val_total:4539\n",
      "[epoch:74,batch:329]:acc: 0.866761,loss:0.323418\n",
      "[epoch:74,batch:359]:acc: 0.865885,loss:0.322404\n",
      "[epoch:74,batch:389]:acc: 0.867468,loss:0.319616\n",
      "[epoch:74,batch:419]:acc: 0.867485,loss:0.318224\n",
      "[epoch:74,batch:449]:acc: 0.867708,loss:0.316724\n",
      "[epoch:74,batch:479]:acc: 0.868164,loss:0.315417\n",
      "[epoch:74,batch:509]:acc: 0.867279,loss:0.317028\n",
      "[epoch:74,batch:539]:acc: 0.866551,loss:0.317512\n",
      "[epoch:74,batch:569]:acc: 0.867050,loss:0.315837\n",
      "[epoch:74,batch:599]:acc: 0.867500,loss:0.315345\n",
      "[epoch:74,batch:599]: val_loss:0.360731,val_acc:0.848865,val_total:4539\n",
      "[epoch:74,batch:629]:acc: 0.867857,loss:0.315148\n",
      "[epoch:74,batch:659]:acc: 0.867992,loss:0.314503\n",
      "[epoch:74,batch:689]:acc: 0.868025,loss:0.314231\n",
      "[epoch:74,batch:719]:acc: 0.867882,loss:0.314303\n",
      "[epoch:74,batch:749]:acc: 0.867833,loss:0.314255\n",
      "[epoch:74,batch:779]:acc: 0.868269,loss:0.312633\n",
      "[epoch:74,batch:809]:acc: 0.868364,loss:0.311892\n",
      "[epoch:74,batch:839]:acc: 0.867634,loss:0.312959\n",
      "[epoch:74,batch:869]:acc: 0.867744,loss:0.312429\n",
      "[epoch:74,batch:899]:acc: 0.868264,loss:0.311488\n",
      "[epoch:74,batch:899]: val_loss:0.359271,val_acc:0.851289,val_total:4539\n",
      "[epoch:74,batch:929]:acc: 0.867843,loss:0.311725\n",
      "[epoch:74,batch:959]:acc: 0.868392,loss:0.310879\n",
      "[epoch:74,batch:989]:acc: 0.868182,loss:0.311609\n",
      "[epoch:74] :acc: 0.868115,loss:0.311638,lr:0.001000,patience:2\n",
      "[epoch:74]: val_loss:0.358938,val_acc:0.855915,\n",
      "save new model loss,now loss is  0.3589383661746979\n",
      "Epoch 75/89\n",
      "----------\n",
      "lr now is 0.001000\n",
      "now patience is 0 \n",
      "[epoch:75,batch:29]:acc: 0.881250,loss:0.280399\n",
      "[epoch:75,batch:59]:acc: 0.881771,loss:0.276978\n",
      "[epoch:75,batch:89]:acc: 0.875000,loss:0.287847\n",
      "[epoch:75,batch:119]:acc: 0.874740,loss:0.288070\n",
      "[epoch:75,batch:149]:acc: 0.874375,loss:0.288075\n",
      "[epoch:75,batch:179]:acc: 0.875868,loss:0.286336\n",
      "[epoch:75,batch:209]:acc: 0.875446,loss:0.290309\n",
      "[epoch:75,batch:239]:acc: 0.874609,loss:0.289163\n",
      "[epoch:75,batch:269]:acc: 0.875347,loss:0.288872\n",
      "[epoch:75,batch:299]:acc: 0.877708,loss:0.286248\n",
      "[epoch:75,batch:299]: val_loss:0.359900,val_acc:0.853492,val_total:4539\n",
      "[epoch:75,batch:329]:acc: 0.877936,loss:0.284985\n",
      "[epoch:75,batch:359]:acc: 0.878038,loss:0.285150\n",
      "[epoch:75,batch:389]:acc: 0.877003,loss:0.286725\n",
      "[epoch:75,batch:419]:acc: 0.877083,loss:0.286271\n",
      "[epoch:75,batch:449]:acc: 0.877431,loss:0.287110\n",
      "[epoch:75,batch:479]:acc: 0.876172,loss:0.288031\n",
      "[epoch:75,batch:509]:acc: 0.876471,loss:0.287280\n",
      "[epoch:75,batch:539]:acc: 0.876389,loss:0.287778\n",
      "[epoch:75,batch:569]:acc: 0.876754,loss:0.286416\n",
      "[epoch:75,batch:599]:acc: 0.876250,loss:0.286584\n",
      "[epoch:75,batch:599]: val_loss:0.355536,val_acc:0.857678,val_total:4539\n",
      "[epoch:75,batch:629]:acc: 0.875744,loss:0.286926\n",
      "[epoch:75,batch:659]:acc: 0.876231,loss:0.286411\n",
      "[epoch:75,batch:689]:acc: 0.876495,loss:0.286181\n",
      "[epoch:75,batch:719]:acc: 0.876302,loss:0.286593\n",
      "[epoch:75,batch:749]:acc: 0.876042,loss:0.286832\n",
      "[epoch:75,batch:779]:acc: 0.876322,loss:0.287079\n",
      "[epoch:75,batch:809]:acc: 0.876119,loss:0.287279\n",
      "[epoch:75,batch:839]:acc: 0.875298,loss:0.288661\n",
      "[epoch:75,batch:869]:acc: 0.875359,loss:0.288882\n",
      "[epoch:75,batch:899]:acc: 0.876111,loss:0.287853\n",
      "[epoch:75,batch:899]: val_loss:0.352201,val_acc:0.857017,val_total:4539\n",
      "[epoch:75,batch:929]:acc: 0.876579,loss:0.287020\n",
      "[epoch:75,batch:959]:acc: 0.876042,loss:0.287285\n",
      "[epoch:75,batch:989]:acc: 0.876168,loss:0.287082\n",
      "[epoch:75] :acc: 0.876092,loss:0.288047,lr:0.001000,patience:0\n",
      "[epoch:75]: val_loss:0.366515,val_acc:0.845781,\n",
      "Epoch 76/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:76,batch:29]:acc: 0.863542,loss:0.281242\n",
      "[epoch:76,batch:59]:acc: 0.874479,loss:0.274767\n",
      "[epoch:76,batch:89]:acc: 0.875347,loss:0.281062\n",
      "[epoch:76,batch:119]:acc: 0.877083,loss:0.280929\n",
      "[epoch:76,batch:149]:acc: 0.876250,loss:0.280058\n",
      "[epoch:76,batch:179]:acc: 0.877951,loss:0.274898\n",
      "[epoch:76,batch:209]:acc: 0.881101,loss:0.271560\n",
      "[epoch:76,batch:239]:acc: 0.881641,loss:0.270976\n",
      "[epoch:76,batch:269]:acc: 0.882176,loss:0.272707\n",
      "[epoch:76,batch:299]:acc: 0.881250,loss:0.273558\n",
      "[epoch:76,batch:299]: val_loss:0.353696,val_acc:0.858339,val_total:4539\n",
      "[epoch:76,batch:329]:acc: 0.881723,loss:0.273409\n",
      "[epoch:76,batch:359]:acc: 0.882031,loss:0.274045\n",
      "[epoch:76,batch:389]:acc: 0.883494,loss:0.272527\n",
      "[epoch:76,batch:419]:acc: 0.883408,loss:0.271289\n",
      "[epoch:76,batch:449]:acc: 0.883125,loss:0.272703\n",
      "[epoch:76,batch:479]:acc: 0.883268,loss:0.272826\n",
      "[epoch:76,batch:509]:acc: 0.883272,loss:0.273290\n",
      "[epoch:76,batch:539]:acc: 0.883102,loss:0.272599\n",
      "[epoch:76,batch:569]:acc: 0.882950,loss:0.272332\n",
      "[epoch:76,batch:599]:acc: 0.883073,loss:0.271971\n",
      "[epoch:76,batch:599]: val_loss:0.352271,val_acc:0.857237,val_total:4539\n",
      "[epoch:76,batch:629]:acc: 0.884375,loss:0.269780\n",
      "[epoch:76,batch:659]:acc: 0.883617,loss:0.269589\n",
      "[epoch:76,batch:689]:acc: 0.884103,loss:0.269183\n",
      "[epoch:76,batch:719]:acc: 0.884332,loss:0.269286\n",
      "[epoch:76,batch:749]:acc: 0.884708,loss:0.268964\n",
      "[epoch:76,batch:779]:acc: 0.884295,loss:0.269202\n",
      "[epoch:76,batch:809]:acc: 0.884336,loss:0.269507\n",
      "[epoch:76,batch:839]:acc: 0.884635,loss:0.269278\n",
      "[epoch:76,batch:869]:acc: 0.884088,loss:0.269978\n",
      "[epoch:76,batch:899]:acc: 0.884653,loss:0.269108\n",
      "[epoch:76,batch:899]: val_loss:0.351548,val_acc:0.857678,val_total:4539\n",
      "[epoch:76,batch:929]:acc: 0.884509,loss:0.268691\n",
      "[epoch:76,batch:959]:acc: 0.884863,loss:0.268243\n",
      "[epoch:76,batch:989]:acc: 0.884628,loss:0.268616\n",
      "[epoch:76] :acc: 0.884668,loss:0.268387,lr:0.000100,patience:1\n",
      "[epoch:76]: val_loss:0.354741,val_acc:0.859881,\n",
      "save new model loss,now loss is  0.3547406494617462\n",
      "Epoch 77/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 0 \n",
      "[epoch:77,batch:29]:acc: 0.870833,loss:0.288175\n",
      "[epoch:77,batch:59]:acc: 0.882812,loss:0.276403\n",
      "[epoch:77,batch:89]:acc: 0.878819,loss:0.281229\n",
      "[epoch:77,batch:119]:acc: 0.882812,loss:0.272471\n",
      "[epoch:77,batch:149]:acc: 0.881042,loss:0.272025\n",
      "[epoch:77,batch:179]:acc: 0.882639,loss:0.270976\n",
      "[epoch:77,batch:209]:acc: 0.882143,loss:0.273908\n",
      "[epoch:77,batch:239]:acc: 0.881641,loss:0.273439\n",
      "[epoch:77,batch:269]:acc: 0.878356,loss:0.278190\n",
      "[epoch:77,batch:299]:acc: 0.879062,loss:0.276283\n",
      "[epoch:77,batch:299]: val_loss:0.352790,val_acc:0.858559,val_total:4539\n",
      "[epoch:77,batch:329]:acc: 0.880398,loss:0.276806\n",
      "[epoch:77,batch:359]:acc: 0.880903,loss:0.276049\n",
      "[epoch:77,batch:389]:acc: 0.880769,loss:0.275717\n",
      "[epoch:77,batch:419]:acc: 0.881250,loss:0.274442\n",
      "[epoch:77,batch:449]:acc: 0.881111,loss:0.273729\n",
      "[epoch:77,batch:479]:acc: 0.881315,loss:0.272795\n",
      "[epoch:77,batch:509]:acc: 0.882966,loss:0.269832\n",
      "[epoch:77,batch:539]:acc: 0.882870,loss:0.271080\n",
      "[epoch:77,batch:569]:acc: 0.882785,loss:0.271784\n",
      "[epoch:77,batch:599]:acc: 0.883333,loss:0.270376\n",
      "[epoch:77,batch:599]: val_loss:0.352843,val_acc:0.858559,val_total:4539\n",
      "[epoch:77,batch:629]:acc: 0.883234,loss:0.270572\n",
      "[epoch:77,batch:659]:acc: 0.882434,loss:0.271840\n",
      "[epoch:77,batch:689]:acc: 0.883062,loss:0.271054\n",
      "[epoch:77,batch:719]:acc: 0.883203,loss:0.270541\n",
      "[epoch:77,batch:749]:acc: 0.883125,loss:0.270131\n",
      "[epoch:77,batch:779]:acc: 0.883253,loss:0.270154\n",
      "[epoch:77,batch:809]:acc: 0.883681,loss:0.270065\n",
      "[epoch:77,batch:839]:acc: 0.883259,loss:0.270039\n",
      "[epoch:77,batch:869]:acc: 0.883405,loss:0.269338\n",
      "[epoch:77,batch:899]:acc: 0.883229,loss:0.268879\n",
      "[epoch:77,batch:899]: val_loss:0.352411,val_acc:0.857237,val_total:4539\n",
      "[epoch:77,batch:929]:acc: 0.883468,loss:0.268093\n",
      "[epoch:77,batch:959]:acc: 0.883464,loss:0.267922\n",
      "[epoch:77,batch:989]:acc: 0.883365,loss:0.268274\n",
      "[epoch:77] :acc: 0.883406,loss:0.268373,lr:0.000100,patience:0\n",
      "[epoch:77]: val_loss:0.350605,val_acc:0.859881,\n",
      "save new model loss,now loss is  0.35060515999794006\n",
      "Epoch 78/89\n",
      "----------\n",
      "lr now is 0.010000\n",
      "now patience is 0 \n",
      "[epoch:78,batch:29]:acc: 0.856250,loss:0.357618\n",
      "[epoch:78,batch:59]:acc: 0.845313,loss:0.380647\n",
      "[epoch:78,batch:89]:acc: 0.844792,loss:0.384137\n",
      "[epoch:78,batch:119]:acc: 0.840625,loss:0.388266\n",
      "[epoch:78,batch:149]:acc: 0.844792,loss:0.382701\n",
      "[epoch:78,batch:179]:acc: 0.842014,loss:0.383996\n",
      "[epoch:78,batch:209]:acc: 0.842411,loss:0.385413\n",
      "[epoch:78,batch:239]:acc: 0.841016,loss:0.387159\n",
      "[epoch:78,batch:269]:acc: 0.837269,loss:0.391591\n",
      "[epoch:78,batch:299]:acc: 0.839792,loss:0.386192\n",
      "[epoch:78,batch:299]: val_loss:0.460425,val_acc:0.817581,val_total:4539\n",
      "[epoch:78,batch:329]:acc: 0.837973,loss:0.392829\n",
      "[epoch:78,batch:359]:acc: 0.838455,loss:0.394830\n",
      "[epoch:78,batch:389]:acc: 0.838061,loss:0.395895\n",
      "[epoch:78,batch:419]:acc: 0.837426,loss:0.395561\n",
      "[epoch:78,batch:449]:acc: 0.835972,loss:0.398464\n",
      "[epoch:78,batch:479]:acc: 0.835677,loss:0.398495\n",
      "[epoch:78,batch:509]:acc: 0.835478,loss:0.400422\n",
      "[epoch:78,batch:539]:acc: 0.834954,loss:0.401843\n",
      "[epoch:78,batch:569]:acc: 0.834868,loss:0.404152\n",
      "[epoch:78,batch:599]:acc: 0.834479,loss:0.406038\n",
      "[epoch:78,batch:599]: val_loss:0.446636,val_acc:0.807667,val_total:4539\n",
      "[epoch:78,batch:629]:acc: 0.834772,loss:0.405408\n",
      "[epoch:78,batch:659]:acc: 0.834564,loss:0.406158\n",
      "[epoch:78,batch:689]:acc: 0.835100,loss:0.403722\n",
      "[epoch:78,batch:719]:acc: 0.836111,loss:0.401975\n",
      "[epoch:78,batch:749]:acc: 0.836542,loss:0.401225\n",
      "[epoch:78,batch:779]:acc: 0.836699,loss:0.400895\n",
      "[epoch:78,batch:809]:acc: 0.836535,loss:0.400355\n",
      "[epoch:78,batch:839]:acc: 0.836384,loss:0.400722\n",
      "[epoch:78,batch:869]:acc: 0.836243,loss:0.400529\n",
      "[epoch:78,batch:899]:acc: 0.835938,loss:0.401393\n",
      "[epoch:78,batch:899]: val_loss:0.429011,val_acc:0.833003,val_total:4539\n",
      "[epoch:78,batch:929]:acc: 0.836055,loss:0.400904\n",
      "[epoch:78,batch:959]:acc: 0.836491,loss:0.399998\n",
      "[epoch:78,batch:989]:acc: 0.836301,loss:0.400444\n",
      "[epoch:78] :acc: 0.836302,loss:0.400674,lr:0.010000,patience:0\n",
      "[epoch:78]: val_loss:0.440823,val_acc:0.819784,\n",
      "Epoch 79/89\n",
      "----------\n",
      "lr now is 0.010000\n",
      "now patience is 1 \n",
      "[epoch:79,batch:29]:acc: 0.857292,loss:0.332503\n",
      "[epoch:79,batch:59]:acc: 0.851562,loss:0.350744\n",
      "[epoch:79,batch:89]:acc: 0.846528,loss:0.362273\n",
      "[epoch:79,batch:119]:acc: 0.848698,loss:0.360131\n",
      "[epoch:79,batch:149]:acc: 0.851042,loss:0.353056\n",
      "[epoch:79,batch:179]:acc: 0.852083,loss:0.352981\n",
      "[epoch:79,batch:209]:acc: 0.853125,loss:0.352224\n",
      "[epoch:79,batch:239]:acc: 0.855339,loss:0.347317\n",
      "[epoch:79,batch:269]:acc: 0.854282,loss:0.349126\n",
      "[epoch:79,batch:299]:acc: 0.853333,loss:0.350830\n",
      "[epoch:79,batch:299]: val_loss:0.485619,val_acc:0.818682,val_total:4539\n",
      "[epoch:79,batch:329]:acc: 0.851799,loss:0.352997\n",
      "[epoch:79,batch:359]:acc: 0.851997,loss:0.351348\n",
      "[epoch:79,batch:389]:acc: 0.850000,loss:0.355682\n",
      "[epoch:79,batch:419]:acc: 0.849554,loss:0.355192\n",
      "[epoch:79,batch:449]:acc: 0.849236,loss:0.356081\n",
      "[epoch:79,batch:479]:acc: 0.849089,loss:0.356965\n",
      "[epoch:79,batch:509]:acc: 0.848284,loss:0.359280\n",
      "[epoch:79,batch:539]:acc: 0.847569,loss:0.360237\n",
      "[epoch:79,batch:569]:acc: 0.847862,loss:0.359410\n",
      "[epoch:79,batch:599]:acc: 0.848333,loss:0.358926\n",
      "[epoch:79,batch:599]: val_loss:0.426870,val_acc:0.837629,val_total:4539\n",
      "[epoch:79,batch:629]:acc: 0.847520,loss:0.359862\n",
      "[epoch:79,batch:659]:acc: 0.847348,loss:0.360315\n",
      "[epoch:79,batch:689]:acc: 0.847101,loss:0.360478\n",
      "[epoch:79,batch:719]:acc: 0.846788,loss:0.361833\n",
      "[epoch:79,batch:749]:acc: 0.847917,loss:0.360900\n",
      "[epoch:79,batch:779]:acc: 0.847917,loss:0.361074\n",
      "[epoch:79,batch:809]:acc: 0.847724,loss:0.362211\n",
      "[epoch:79,batch:839]:acc: 0.847731,loss:0.363201\n",
      "[epoch:79,batch:869]:acc: 0.847055,loss:0.364786\n",
      "[epoch:79,batch:899]:acc: 0.846875,loss:0.365750\n",
      "[epoch:79,batch:899]: val_loss:0.406460,val_acc:0.843137,val_total:4539\n",
      "[epoch:79,batch:929]:acc: 0.846069,loss:0.367782\n",
      "[epoch:79,batch:959]:acc: 0.846354,loss:0.367350\n",
      "[epoch:79,batch:989]:acc: 0.846181,loss:0.368178\n",
      "[epoch:79] :acc: 0.846202,loss:0.368082,lr:0.010000,patience:1\n",
      "[epoch:79]: val_loss:0.442321,val_acc:0.823970,\n",
      "Epoch 80/89\n",
      "----------\n",
      "lr now is 0.001000\n",
      "now patience is 2 \n",
      "[epoch:80,batch:29]:acc: 0.882292,loss:0.306607\n",
      "[epoch:80,batch:59]:acc: 0.879687,loss:0.296541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:80,batch:89]:acc: 0.876736,loss:0.297236\n",
      "[epoch:80,batch:119]:acc: 0.875260,loss:0.303819\n",
      "[epoch:80,batch:149]:acc: 0.880208,loss:0.291964\n",
      "[epoch:80,batch:179]:acc: 0.882118,loss:0.287732\n",
      "[epoch:80,batch:209]:acc: 0.879167,loss:0.287935\n",
      "[epoch:80,batch:239]:acc: 0.879297,loss:0.287737\n",
      "[epoch:80,batch:269]:acc: 0.879051,loss:0.285446\n",
      "[epoch:80,batch:299]:acc: 0.878750,loss:0.283851\n",
      "[epoch:80,batch:299]: val_loss:0.364872,val_acc:0.856356,val_total:4539\n",
      "[epoch:80,batch:329]:acc: 0.878125,loss:0.286736\n",
      "[epoch:80,batch:359]:acc: 0.876910,loss:0.286807\n",
      "[epoch:80,batch:389]:acc: 0.875561,loss:0.286382\n",
      "[epoch:80,batch:419]:acc: 0.874628,loss:0.287495\n",
      "[epoch:80,batch:449]:acc: 0.874514,loss:0.286847\n",
      "[epoch:80,batch:479]:acc: 0.875716,loss:0.285501\n",
      "[epoch:80,batch:509]:acc: 0.875245,loss:0.285267\n",
      "[epoch:80,batch:539]:acc: 0.876157,loss:0.283827\n",
      "[epoch:80,batch:569]:acc: 0.876425,loss:0.283266\n",
      "[epoch:80,batch:599]:acc: 0.876719,loss:0.282896\n",
      "[epoch:80,batch:599]: val_loss:0.361217,val_acc:0.858339,val_total:4539\n",
      "[epoch:80,batch:629]:acc: 0.877232,loss:0.282198\n",
      "[epoch:80,batch:659]:acc: 0.877604,loss:0.281228\n",
      "[epoch:80,batch:689]:acc: 0.878080,loss:0.279901\n",
      "[epoch:80,batch:719]:acc: 0.879210,loss:0.278008\n",
      "[epoch:80,batch:749]:acc: 0.879417,loss:0.277829\n",
      "[epoch:80,batch:779]:acc: 0.879848,loss:0.277954\n",
      "[epoch:80,batch:809]:acc: 0.880247,loss:0.277284\n",
      "[epoch:80,batch:839]:acc: 0.880208,loss:0.276978\n",
      "[epoch:80,batch:869]:acc: 0.879562,loss:0.277620\n",
      "[epoch:80,batch:899]:acc: 0.879757,loss:0.277386\n",
      "[epoch:80,batch:899]: val_loss:0.363458,val_acc:0.863626,val_total:4539\n",
      "[epoch:80,batch:929]:acc: 0.878931,loss:0.278199\n",
      "[epoch:80,batch:959]:acc: 0.879134,loss:0.277640\n",
      "[epoch:80,batch:989]:acc: 0.879324,loss:0.277213\n",
      "[epoch:80] :acc: 0.879371,loss:0.277199,lr:0.001000,patience:2\n",
      "[epoch:80]: val_loss:0.360630,val_acc:0.862745,\n",
      "save new model acc,now acc is  tensor(0.8627, device='cuda:0')\n",
      "Epoch 81/89\n",
      "----------\n",
      "lr now is 0.001000\n",
      "now patience is 3 \n",
      "[epoch:81,batch:29]:acc: 0.887500,loss:0.253173\n",
      "[epoch:81,batch:59]:acc: 0.880208,loss:0.261211\n",
      "[epoch:81,batch:89]:acc: 0.882639,loss:0.256409\n",
      "[epoch:81,batch:119]:acc: 0.884896,loss:0.257985\n",
      "[epoch:81,batch:149]:acc: 0.888542,loss:0.254514\n",
      "[epoch:81,batch:179]:acc: 0.893056,loss:0.250413\n",
      "[epoch:81,batch:209]:acc: 0.892560,loss:0.250503\n",
      "[epoch:81,batch:239]:acc: 0.892578,loss:0.251702\n",
      "[epoch:81,batch:269]:acc: 0.892014,loss:0.251239\n",
      "[epoch:81,batch:299]:acc: 0.891771,loss:0.250545\n",
      "[epoch:81,batch:299]: val_loss:0.366315,val_acc:0.860542,val_total:4539\n",
      "[epoch:81,batch:329]:acc: 0.891004,loss:0.253312\n",
      "[epoch:81,batch:359]:acc: 0.890017,loss:0.252968\n",
      "[epoch:81,batch:389]:acc: 0.890224,loss:0.251516\n",
      "[epoch:81,batch:419]:acc: 0.890030,loss:0.251243\n",
      "[epoch:81,batch:449]:acc: 0.889861,loss:0.251399\n",
      "[epoch:81,batch:479]:acc: 0.891016,loss:0.249584\n",
      "[epoch:81,batch:509]:acc: 0.890441,loss:0.251463\n",
      "[epoch:81,batch:539]:acc: 0.890046,loss:0.251424\n",
      "[epoch:81,batch:569]:acc: 0.889803,loss:0.251976\n",
      "[epoch:81,batch:599]:acc: 0.890365,loss:0.250956\n",
      "[epoch:81,batch:599]: val_loss:0.361262,val_acc:0.859881,val_total:4539\n",
      "[epoch:81,batch:629]:acc: 0.890129,loss:0.252948\n",
      "[epoch:81,batch:659]:acc: 0.891098,loss:0.251415\n",
      "[epoch:81,batch:689]:acc: 0.891667,loss:0.250159\n",
      "[epoch:81,batch:719]:acc: 0.892274,loss:0.249861\n",
      "[epoch:81,batch:749]:acc: 0.892125,loss:0.249792\n",
      "[epoch:81,batch:779]:acc: 0.892308,loss:0.249407\n",
      "[epoch:81,batch:809]:acc: 0.891242,loss:0.251193\n",
      "[epoch:81,batch:839]:acc: 0.891146,loss:0.250818\n",
      "[epoch:81,batch:869]:acc: 0.891164,loss:0.251578\n",
      "[epoch:81,batch:899]:acc: 0.891215,loss:0.251530\n",
      "[epoch:81,batch:899]: val_loss:0.367011,val_acc:0.860983,val_total:4539\n",
      "[epoch:81,batch:929]:acc: 0.891129,loss:0.250992\n",
      "[epoch:81,batch:959]:acc: 0.891732,loss:0.250220\n",
      "[epoch:81,batch:989]:acc: 0.892203,loss:0.249378\n",
      "[epoch:81] :acc: 0.892203,loss:0.249269,lr:0.001000,patience:3\n",
      "[epoch:81]: val_loss:0.366347,val_acc:0.860322,\n",
      "Epoch 82/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 4 \n",
      "[epoch:82,batch:29]:acc: 0.894792,loss:0.251688\n",
      "[epoch:82,batch:59]:acc: 0.896875,loss:0.238892\n",
      "[epoch:82,batch:89]:acc: 0.898958,loss:0.242858\n",
      "[epoch:82,batch:119]:acc: 0.896094,loss:0.243312\n",
      "[epoch:82,batch:149]:acc: 0.896250,loss:0.240268\n",
      "[epoch:82,batch:179]:acc: 0.895660,loss:0.242198\n",
      "[epoch:82,batch:209]:acc: 0.895238,loss:0.239662\n",
      "[epoch:82,batch:239]:acc: 0.895703,loss:0.238434\n",
      "[epoch:82,batch:269]:acc: 0.896181,loss:0.238694\n",
      "[epoch:82,batch:299]:acc: 0.896563,loss:0.238661\n",
      "[epoch:82,batch:299]: val_loss:0.364687,val_acc:0.862965,val_total:4539\n",
      "[epoch:82,batch:329]:acc: 0.896307,loss:0.238359\n",
      "[epoch:82,batch:359]:acc: 0.897135,loss:0.236122\n",
      "[epoch:82,batch:389]:acc: 0.896875,loss:0.237976\n",
      "[epoch:82,batch:419]:acc: 0.897842,loss:0.235550\n",
      "[epoch:82,batch:449]:acc: 0.898194,loss:0.236432\n",
      "[epoch:82,batch:479]:acc: 0.898633,loss:0.236736\n",
      "[epoch:82,batch:509]:acc: 0.898591,loss:0.236321\n",
      "[epoch:82,batch:539]:acc: 0.898958,loss:0.235992\n",
      "[epoch:82,batch:569]:acc: 0.898629,loss:0.235872\n",
      "[epoch:82,batch:599]:acc: 0.899271,loss:0.235365\n",
      "[epoch:82,batch:599]: val_loss:0.364897,val_acc:0.862084,val_total:4539\n",
      "[epoch:82,batch:629]:acc: 0.899256,loss:0.235565\n",
      "[epoch:82,batch:659]:acc: 0.899953,loss:0.234195\n",
      "[epoch:82,batch:689]:acc: 0.900181,loss:0.233509\n",
      "[epoch:82,batch:719]:acc: 0.900608,loss:0.232061\n",
      "[epoch:82,batch:749]:acc: 0.900833,loss:0.231409\n",
      "[epoch:82,batch:779]:acc: 0.901683,loss:0.229970\n",
      "[epoch:82,batch:809]:acc: 0.901890,loss:0.230037\n",
      "[epoch:82,batch:839]:acc: 0.901749,loss:0.230956\n",
      "[epoch:82,batch:869]:acc: 0.900718,loss:0.231438\n",
      "[epoch:82,batch:899]:acc: 0.900556,loss:0.231015\n",
      "[epoch:82,batch:899]: val_loss:0.362397,val_acc:0.863186,val_total:4539\n",
      "[epoch:82,batch:929]:acc: 0.900605,loss:0.230940\n",
      "[epoch:82,batch:959]:acc: 0.900846,loss:0.230111\n",
      "[epoch:82,batch:989]:acc: 0.901294,loss:0.229322\n",
      "[epoch:82] :acc: 0.901252,loss:0.229723,lr:0.000100,patience:4\n",
      "[epoch:82]: val_loss:0.364338,val_acc:0.864287,\n",
      "save new model acc,now acc is  tensor(0.8643, device='cuda:0')\n",
      "Epoch 83/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 5 \n",
      "[epoch:83,batch:29]:acc: 0.914583,loss:0.191603\n",
      "[epoch:83,batch:59]:acc: 0.904167,loss:0.224325\n",
      "[epoch:83,batch:89]:acc: 0.903819,loss:0.225084\n",
      "[epoch:83,batch:119]:acc: 0.903906,loss:0.225689\n",
      "[epoch:83,batch:149]:acc: 0.904167,loss:0.223362\n",
      "[epoch:83,batch:179]:acc: 0.902257,loss:0.226823\n",
      "[epoch:83,batch:209]:acc: 0.903869,loss:0.223370\n",
      "[epoch:83,batch:239]:acc: 0.902604,loss:0.225470\n",
      "[epoch:83,batch:269]:acc: 0.903704,loss:0.224325\n",
      "[epoch:83,batch:299]:acc: 0.903958,loss:0.222735\n",
      "[epoch:83,batch:299]: val_loss:0.365534,val_acc:0.864067,val_total:4539\n",
      "[epoch:83,batch:329]:acc: 0.905019,loss:0.220791\n",
      "[epoch:83,batch:359]:acc: 0.905729,loss:0.219373\n",
      "[epoch:83,batch:389]:acc: 0.904407,loss:0.221304\n",
      "[epoch:83,batch:419]:acc: 0.904613,loss:0.220997\n",
      "[epoch:83,batch:449]:acc: 0.904375,loss:0.221407\n",
      "[epoch:83,batch:479]:acc: 0.904297,loss:0.222634\n",
      "[epoch:83,batch:509]:acc: 0.904902,loss:0.221206\n",
      "[epoch:83,batch:539]:acc: 0.904167,loss:0.223131\n",
      "[epoch:83,batch:569]:acc: 0.903673,loss:0.223223\n",
      "[epoch:83,batch:599]:acc: 0.903385,loss:0.224531\n",
      "[epoch:83,batch:599]: val_loss:0.367386,val_acc:0.864067,val_total:4539\n",
      "[epoch:83,batch:629]:acc: 0.903175,loss:0.224600\n",
      "[epoch:83,batch:659]:acc: 0.902936,loss:0.224774\n",
      "[epoch:83,batch:689]:acc: 0.902310,loss:0.226243\n",
      "[epoch:83,batch:719]:acc: 0.902040,loss:0.227259\n",
      "[epoch:83,batch:749]:acc: 0.901792,loss:0.227821\n",
      "[epoch:83,batch:779]:acc: 0.901442,loss:0.227748\n",
      "[epoch:83,batch:809]:acc: 0.901312,loss:0.228032\n",
      "[epoch:83,batch:839]:acc: 0.901042,loss:0.228405\n",
      "[epoch:83,batch:869]:acc: 0.901114,loss:0.228115\n",
      "[epoch:83,batch:899]:acc: 0.901250,loss:0.228000\n",
      "[epoch:83,batch:899]: val_loss:0.367727,val_acc:0.863406,val_total:4539\n",
      "[epoch:83,batch:929]:acc: 0.900706,loss:0.228299\n",
      "[epoch:83,batch:959]:acc: 0.900651,loss:0.228609\n",
      "[epoch:83,batch:989]:acc: 0.900473,loss:0.228750\n",
      "[epoch:83] :acc: 0.900306,loss:0.229011,lr:0.000100,patience:5\n",
      "[epoch:83]: val_loss:0.367274,val_acc:0.863186,\n",
      "Epoch 84/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 6 \n",
      "[epoch:84,batch:29]:acc: 0.916667,loss:0.219990\n",
      "[epoch:84,batch:59]:acc: 0.913542,loss:0.221676\n",
      "[epoch:84,batch:89]:acc: 0.908333,loss:0.227174\n",
      "[epoch:84,batch:119]:acc: 0.907552,loss:0.225306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:84,batch:149]:acc: 0.911458,loss:0.220377\n",
      "[epoch:84,batch:179]:acc: 0.912847,loss:0.217836\n",
      "[epoch:84,batch:209]:acc: 0.913393,loss:0.214327\n",
      "[epoch:84,batch:239]:acc: 0.912630,loss:0.212774\n",
      "[epoch:84,batch:269]:acc: 0.911806,loss:0.214733\n",
      "[epoch:84,batch:299]:acc: 0.911771,loss:0.214201\n",
      "[epoch:84,batch:299]: val_loss:0.372035,val_acc:0.861643,val_total:4539\n",
      "[epoch:84,batch:329]:acc: 0.911458,loss:0.214872\n",
      "[epoch:84,batch:359]:acc: 0.909896,loss:0.217726\n",
      "[epoch:84,batch:389]:acc: 0.909535,loss:0.218778\n",
      "[epoch:84,batch:419]:acc: 0.909598,loss:0.219495\n",
      "[epoch:84,batch:449]:acc: 0.909306,loss:0.219630\n",
      "[epoch:84,batch:479]:acc: 0.909180,loss:0.220253\n",
      "[epoch:84,batch:509]:acc: 0.909007,loss:0.220358\n",
      "[epoch:84,batch:539]:acc: 0.908681,loss:0.221009\n",
      "[epoch:84,batch:569]:acc: 0.908388,loss:0.220769\n",
      "[epoch:84,batch:599]:acc: 0.909062,loss:0.219857\n",
      "[epoch:84,batch:599]: val_loss:0.371104,val_acc:0.862084,val_total:4539\n",
      "[epoch:84,batch:629]:acc: 0.908482,loss:0.220831\n",
      "[epoch:84,batch:659]:acc: 0.908191,loss:0.221583\n",
      "[epoch:84,batch:689]:acc: 0.907111,loss:0.222675\n",
      "[epoch:84,batch:719]:acc: 0.906988,loss:0.222719\n",
      "[epoch:84,batch:749]:acc: 0.906500,loss:0.223896\n",
      "[epoch:84,batch:779]:acc: 0.906010,loss:0.224454\n",
      "[epoch:84,batch:809]:acc: 0.905903,loss:0.224425\n",
      "[epoch:84,batch:839]:acc: 0.905915,loss:0.224125\n",
      "[epoch:84,batch:869]:acc: 0.905999,loss:0.223517\n",
      "[epoch:84,batch:899]:acc: 0.906007,loss:0.223442\n",
      "[epoch:84,batch:899]: val_loss:0.374193,val_acc:0.861423,val_total:4539\n",
      "[epoch:84,batch:929]:acc: 0.905544,loss:0.224375\n",
      "[epoch:84,batch:959]:acc: 0.905078,loss:0.224556\n",
      "[epoch:84,batch:989]:acc: 0.905208,loss:0.224258\n",
      "[epoch:84] :acc: 0.905130,loss:0.224269,lr:0.000100,patience:6\n",
      "[epoch:84]: val_loss:0.373196,val_acc:0.862304,\n",
      "Epoch 85/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 7 \n",
      "[epoch:85,batch:29]:acc: 0.913542,loss:0.220875\n",
      "[epoch:85,batch:59]:acc: 0.913021,loss:0.209216\n",
      "[epoch:85,batch:89]:acc: 0.906597,loss:0.222490\n",
      "[epoch:85,batch:119]:acc: 0.905208,loss:0.222517\n",
      "[epoch:85,batch:149]:acc: 0.907083,loss:0.219262\n",
      "[epoch:85,batch:179]:acc: 0.905903,loss:0.218577\n",
      "[epoch:85,batch:209]:acc: 0.905208,loss:0.218511\n",
      "[epoch:85,batch:239]:acc: 0.905469,loss:0.218054\n",
      "[epoch:85,batch:269]:acc: 0.905671,loss:0.216739\n",
      "[epoch:85,batch:299]:acc: 0.906042,loss:0.216411\n",
      "[epoch:85,batch:299]: val_loss:0.374451,val_acc:0.862745,val_total:4539\n",
      "[epoch:85,batch:329]:acc: 0.906534,loss:0.215564\n",
      "[epoch:85,batch:359]:acc: 0.906337,loss:0.217482\n",
      "[epoch:85,batch:389]:acc: 0.906090,loss:0.219883\n",
      "[epoch:85,batch:419]:acc: 0.905506,loss:0.220937\n",
      "[epoch:85,batch:449]:acc: 0.906389,loss:0.220256\n",
      "[epoch:85,batch:479]:acc: 0.905729,loss:0.221289\n",
      "[epoch:85,batch:509]:acc: 0.904473,loss:0.222973\n",
      "[epoch:85,batch:539]:acc: 0.904514,loss:0.223590\n",
      "[epoch:85,batch:569]:acc: 0.903893,loss:0.224284\n",
      "[epoch:85,batch:599]:acc: 0.903802,loss:0.224326\n",
      "[epoch:85,batch:599]: val_loss:0.374471,val_acc:0.861643,val_total:4539\n",
      "[epoch:85,batch:629]:acc: 0.904266,loss:0.224763\n",
      "[epoch:85,batch:659]:acc: 0.904119,loss:0.224472\n",
      "[epoch:85,batch:689]:acc: 0.903533,loss:0.224464\n",
      "[epoch:85,batch:719]:acc: 0.903559,loss:0.224694\n",
      "[epoch:85,batch:749]:acc: 0.903042,loss:0.225413\n",
      "[epoch:85,batch:779]:acc: 0.903726,loss:0.224615\n",
      "[epoch:85,batch:809]:acc: 0.903897,loss:0.223913\n",
      "[epoch:85,batch:839]:acc: 0.903497,loss:0.224556\n",
      "[epoch:85,batch:869]:acc: 0.903125,loss:0.225102\n",
      "[epoch:85,batch:899]:acc: 0.902951,loss:0.225763\n",
      "[epoch:85,batch:899]: val_loss:0.376696,val_acc:0.862084,val_total:4539\n",
      "[epoch:85,batch:929]:acc: 0.903091,loss:0.224967\n",
      "[epoch:85,batch:959]:acc: 0.903158,loss:0.224408\n",
      "[epoch:85,batch:989]:acc: 0.903220,loss:0.224049\n",
      "[epoch:85] :acc: 0.903270,loss:0.224108,lr:0.000100,patience:7\n",
      "[epoch:85]: val_loss:0.377074,val_acc:0.861423,\n",
      "Epoch 86/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 8 \n",
      "[epoch:86,batch:29]:acc: 0.875000,loss:0.256222\n",
      "[epoch:86,batch:59]:acc: 0.886458,loss:0.241887\n",
      "[epoch:86,batch:89]:acc: 0.892361,loss:0.245396\n",
      "[epoch:86,batch:119]:acc: 0.896094,loss:0.238493\n",
      "[epoch:86,batch:149]:acc: 0.899167,loss:0.233504\n",
      "[epoch:86,batch:179]:acc: 0.899826,loss:0.232710\n",
      "[epoch:86,batch:209]:acc: 0.900595,loss:0.231003\n",
      "[epoch:86,batch:239]:acc: 0.903255,loss:0.228295\n",
      "[epoch:86,batch:269]:acc: 0.903935,loss:0.226958\n",
      "[epoch:86,batch:299]:acc: 0.903333,loss:0.224116\n",
      "[epoch:86,batch:299]: val_loss:0.375962,val_acc:0.861643,val_total:4539\n",
      "[epoch:86,batch:329]:acc: 0.902746,loss:0.225146\n",
      "[epoch:86,batch:359]:acc: 0.903733,loss:0.223599\n",
      "[epoch:86,batch:389]:acc: 0.902724,loss:0.224855\n",
      "[epoch:86,batch:419]:acc: 0.902827,loss:0.223676\n",
      "[epoch:86,batch:449]:acc: 0.903125,loss:0.222953\n",
      "[epoch:86,batch:479]:acc: 0.904232,loss:0.222215\n",
      "[epoch:86,batch:509]:acc: 0.904105,loss:0.223036\n",
      "[epoch:86,batch:539]:acc: 0.904340,loss:0.222464\n",
      "[epoch:86,batch:569]:acc: 0.904002,loss:0.223063\n",
      "[epoch:86,batch:599]:acc: 0.903490,loss:0.224158\n",
      "[epoch:86,batch:599]: val_loss:0.375885,val_acc:0.861423,val_total:4539\n",
      "[epoch:86,batch:629]:acc: 0.903919,loss:0.223658\n",
      "[epoch:86,batch:659]:acc: 0.904214,loss:0.223428\n",
      "[epoch:86,batch:689]:acc: 0.903759,loss:0.223897\n",
      "[epoch:86,batch:719]:acc: 0.903950,loss:0.223688\n",
      "[epoch:86,batch:749]:acc: 0.904167,loss:0.223352\n",
      "[epoch:86,batch:779]:acc: 0.903566,loss:0.223967\n",
      "[epoch:86,batch:809]:acc: 0.903742,loss:0.223321\n",
      "[epoch:86,batch:839]:acc: 0.904204,loss:0.221922\n",
      "[epoch:86,batch:869]:acc: 0.904023,loss:0.223028\n",
      "[epoch:86,batch:899]:acc: 0.903750,loss:0.222940\n",
      "[epoch:86,batch:899]: val_loss:0.375086,val_acc:0.862304,val_total:4539\n",
      "[epoch:86,batch:929]:acc: 0.903797,loss:0.223614\n",
      "[epoch:86,batch:959]:acc: 0.903711,loss:0.223764\n",
      "[epoch:86,batch:989]:acc: 0.903693,loss:0.223812\n",
      "[epoch:86] :acc: 0.903553,loss:0.224267,lr:0.000100,patience:8\n",
      "[epoch:86]: val_loss:0.377367,val_acc:0.862084,\n",
      "Epoch 87/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 9 \n",
      "[epoch:87,batch:29]:acc: 0.895833,loss:0.233514\n",
      "[epoch:87,batch:59]:acc: 0.900521,loss:0.225354\n",
      "[epoch:87,batch:89]:acc: 0.901389,loss:0.229746\n",
      "[epoch:87,batch:119]:acc: 0.900260,loss:0.229005\n",
      "[epoch:87,batch:149]:acc: 0.897708,loss:0.234845\n",
      "[epoch:87,batch:179]:acc: 0.895486,loss:0.237500\n",
      "[epoch:87,batch:209]:acc: 0.895536,loss:0.235318\n",
      "[epoch:87,batch:239]:acc: 0.897656,loss:0.230510\n",
      "[epoch:87,batch:269]:acc: 0.897685,loss:0.229376\n",
      "[epoch:87,batch:299]:acc: 0.898125,loss:0.230362\n",
      "[epoch:87,batch:299]: val_loss:0.376631,val_acc:0.860322,val_total:4539\n",
      "[epoch:87,batch:329]:acc: 0.899811,loss:0.227741\n",
      "[epoch:87,batch:359]:acc: 0.899826,loss:0.227358\n",
      "[epoch:87,batch:389]:acc: 0.901042,loss:0.226949\n",
      "[epoch:87,batch:419]:acc: 0.901935,loss:0.225220\n",
      "[epoch:87,batch:449]:acc: 0.902569,loss:0.223935\n",
      "[epoch:87,batch:479]:acc: 0.902539,loss:0.223662\n",
      "[epoch:87,batch:509]:acc: 0.903799,loss:0.221253\n",
      "[epoch:87,batch:539]:acc: 0.902778,loss:0.222387\n",
      "[epoch:87,batch:569]:acc: 0.902467,loss:0.223395\n",
      "[epoch:87,batch:599]:acc: 0.902396,loss:0.223264\n",
      "[epoch:87,batch:599]: val_loss:0.373946,val_acc:0.859440,val_total:4539\n",
      "[epoch:87,batch:629]:acc: 0.902728,loss:0.222655\n",
      "[epoch:87,batch:659]:acc: 0.903030,loss:0.223297\n",
      "[epoch:87,batch:689]:acc: 0.903034,loss:0.223230\n",
      "[epoch:87,batch:719]:acc: 0.903125,loss:0.223966\n",
      "[epoch:87,batch:749]:acc: 0.903208,loss:0.223746\n",
      "[epoch:87,batch:779]:acc: 0.903125,loss:0.224039\n",
      "[epoch:87,batch:809]:acc: 0.903472,loss:0.223609\n",
      "[epoch:87,batch:839]:acc: 0.903051,loss:0.224222\n",
      "[epoch:87,batch:869]:acc: 0.903376,loss:0.224223\n",
      "[epoch:87,batch:899]:acc: 0.903299,loss:0.224233\n",
      "[epoch:87,batch:899]: val_loss:0.375187,val_acc:0.860322,val_total:4539\n",
      "[epoch:87,batch:929]:acc: 0.903763,loss:0.223093\n",
      "[epoch:87,batch:959]:acc: 0.903255,loss:0.223429\n",
      "[epoch:87,batch:989]:acc: 0.903567,loss:0.222976\n",
      "[epoch:87] :acc: 0.903616,loss:0.222790,lr:0.000100,patience:9\n",
      "[epoch:87]: val_loss:0.376653,val_acc:0.860762,\n",
      "Epoch 88/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 10 \n",
      "[epoch:88,batch:29]:acc: 0.908333,loss:0.217108\n",
      "[epoch:88,batch:59]:acc: 0.913021,loss:0.205844\n",
      "[epoch:88,batch:89]:acc: 0.914931,loss:0.202529\n",
      "[epoch:88,batch:119]:acc: 0.911198,loss:0.209230\n",
      "[epoch:88,batch:149]:acc: 0.911458,loss:0.210494\n",
      "[epoch:88,batch:179]:acc: 0.913194,loss:0.205631\n",
      "[epoch:88,batch:209]:acc: 0.912054,loss:0.208613\n",
      "[epoch:88,batch:239]:acc: 0.911328,loss:0.210227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:88,batch:269]:acc: 0.911343,loss:0.209785\n",
      "[epoch:88,batch:299]:acc: 0.910625,loss:0.211326\n",
      "[epoch:88,batch:299]: val_loss:0.380486,val_acc:0.861203,val_total:4539\n",
      "[epoch:88,batch:329]:acc: 0.908996,loss:0.213431\n",
      "[epoch:88,batch:359]:acc: 0.909115,loss:0.212269\n",
      "[epoch:88,batch:389]:acc: 0.908494,loss:0.214077\n",
      "[epoch:88,batch:419]:acc: 0.907738,loss:0.215324\n",
      "[epoch:88,batch:449]:acc: 0.907708,loss:0.214403\n",
      "[epoch:88,batch:479]:acc: 0.907813,loss:0.214537\n",
      "[epoch:88,batch:509]:acc: 0.907598,loss:0.214085\n",
      "[epoch:88,batch:539]:acc: 0.907002,loss:0.214436\n",
      "[epoch:88,batch:569]:acc: 0.906579,loss:0.214549\n",
      "[epoch:88,batch:599]:acc: 0.906823,loss:0.215458\n",
      "[epoch:88,batch:599]: val_loss:0.377197,val_acc:0.859661,val_total:4539\n",
      "[epoch:88,batch:629]:acc: 0.906895,loss:0.215894\n",
      "[epoch:88,batch:659]:acc: 0.906013,loss:0.217251\n",
      "[epoch:88,batch:689]:acc: 0.905888,loss:0.217025\n",
      "[epoch:88,batch:719]:acc: 0.905859,loss:0.216799\n",
      "[epoch:88,batch:749]:acc: 0.906000,loss:0.216958\n",
      "[epoch:88,batch:779]:acc: 0.906130,loss:0.216879\n",
      "[epoch:88,batch:809]:acc: 0.905787,loss:0.217349\n",
      "[epoch:88,batch:839]:acc: 0.905655,loss:0.217123\n",
      "[epoch:88,batch:869]:acc: 0.905603,loss:0.216928\n",
      "[epoch:88,batch:899]:acc: 0.905868,loss:0.216711\n",
      "[epoch:88,batch:899]: val_loss:0.376753,val_acc:0.859661,val_total:4539\n",
      "[epoch:88,batch:929]:acc: 0.906015,loss:0.215768\n",
      "[epoch:88,batch:959]:acc: 0.906152,loss:0.215502\n",
      "[epoch:88,batch:989]:acc: 0.906439,loss:0.215714\n",
      "[epoch:88] :acc: 0.906454,loss:0.215679,lr:0.000100,patience:10\n",
      "[epoch:88]: val_loss:0.387752,val_acc:0.859000,\n",
      "Epoch 89/89\n",
      "----------\n",
      "lr now is 0.000100\n",
      "now patience is 11 \n",
      "[epoch:89,batch:29]:acc: 0.921875,loss:0.186475\n",
      "[epoch:89,batch:59]:acc: 0.911979,loss:0.197576\n",
      "[epoch:89,batch:89]:acc: 0.912500,loss:0.198158\n",
      "[epoch:89,batch:119]:acc: 0.913281,loss:0.205716\n",
      "[epoch:89,batch:149]:acc: 0.910208,loss:0.213130\n",
      "[epoch:89,batch:179]:acc: 0.910764,loss:0.212448\n",
      "[epoch:89,batch:209]:acc: 0.910565,loss:0.210659\n",
      "[epoch:89,batch:239]:acc: 0.910026,loss:0.209082\n",
      "[epoch:89,batch:269]:acc: 0.908681,loss:0.211528\n",
      "[epoch:89,batch:299]:acc: 0.909479,loss:0.210256\n",
      "[epoch:89,batch:299]: val_loss:0.383020,val_acc:0.861203,val_total:4539\n",
      "[epoch:89,batch:329]:acc: 0.908333,loss:0.210852\n",
      "[epoch:89,batch:359]:acc: 0.909028,loss:0.210690\n",
      "[epoch:89,batch:389]:acc: 0.908654,loss:0.211421\n",
      "[epoch:89,batch:419]:acc: 0.907961,loss:0.212268\n",
      "[epoch:89,batch:449]:acc: 0.907153,loss:0.213832\n",
      "[epoch:89,batch:479]:acc: 0.907292,loss:0.213674\n",
      "[epoch:89,batch:509]:acc: 0.906556,loss:0.215495\n",
      "[epoch:89,batch:539]:acc: 0.907292,loss:0.214443\n",
      "[epoch:89,batch:569]:acc: 0.906908,loss:0.215697\n",
      "[epoch:89,batch:599]:acc: 0.906302,loss:0.216316\n",
      "[epoch:89,batch:599]: val_loss:0.378720,val_acc:0.860542,val_total:4539\n",
      "[epoch:89,batch:629]:acc: 0.906448,loss:0.215842\n",
      "[epoch:89,batch:659]:acc: 0.906439,loss:0.215397\n",
      "[epoch:89,batch:689]:acc: 0.906522,loss:0.215821\n",
      "[epoch:89,batch:719]:acc: 0.906293,loss:0.216572\n",
      "[epoch:89,batch:749]:acc: 0.905958,loss:0.216704\n",
      "[epoch:89,batch:779]:acc: 0.905809,loss:0.216416\n",
      "[epoch:89,batch:809]:acc: 0.905826,loss:0.216515\n",
      "[epoch:89,batch:839]:acc: 0.905506,loss:0.217414\n",
      "[epoch:89,batch:869]:acc: 0.905747,loss:0.216791\n",
      "[epoch:89,batch:899]:acc: 0.906319,loss:0.215858\n",
      "[epoch:89,batch:899]: val_loss:0.377130,val_acc:0.860762,val_total:4539\n",
      "[epoch:89,batch:929]:acc: 0.906048,loss:0.216085\n",
      "[epoch:89,batch:959]:acc: 0.905599,loss:0.216830\n",
      "[epoch:89,batch:989]:acc: 0.905429,loss:0.217249\n",
      "[epoch:89] :acc: 0.905382,loss:0.217441,lr:0.000100,patience:11\n",
      "[epoch:89]: val_loss:0.385052,val_acc:0.857678,\n"
     ]
    }
   ],
   "source": [
    "reuseTrain('../model/ResNet50/2018-11-08_loss_best.pth',90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model... Done\n",
      "min_loss is :0.350605\n",
      "val_correct is 0.859881\n",
      "Epoch 78/119\n",
      "----------\n",
      "[epoch:78,batch:29]:acc: 0.893750,loss:0.253837\n",
      "[epoch:78,batch:59]:acc: 0.890104,loss:0.260539\n",
      "[epoch:78,batch:89]:acc: 0.888889,loss:0.266730\n",
      "[epoch:78,batch:119]:acc: 0.883594,loss:0.273149\n",
      "[epoch:78,batch:149]:acc: 0.888958,loss:0.262913\n",
      "[epoch:78,batch:179]:acc: 0.887326,loss:0.263965\n",
      "[epoch:78,batch:209]:acc: 0.888988,loss:0.261899\n",
      "[epoch:78,batch:239]:acc: 0.888542,loss:0.263589\n",
      "[epoch:78,batch:269]:acc: 0.889236,loss:0.262266\n",
      "[epoch:78,batch:299]:acc: 0.889479,loss:0.262775\n",
      "[epoch:78,batch:299]: val_loss:0.412199,val_acc:0.854814,val_total:4539\n",
      "[epoch:78,batch:329]:acc: 0.890530,loss:0.261254\n",
      "[epoch:78,batch:359]:acc: 0.890538,loss:0.260609\n",
      "[epoch:78,batch:389]:acc: 0.890064,loss:0.259759\n",
      "[epoch:78,batch:419]:acc: 0.890402,loss:0.258993\n",
      "[epoch:78,batch:449]:acc: 0.891111,loss:0.258031\n",
      "[epoch:78,batch:479]:acc: 0.891276,loss:0.257852\n",
      "[epoch:78,batch:509]:acc: 0.890809,loss:0.258174\n",
      "[epoch:78,batch:539]:acc: 0.890683,loss:0.257623\n",
      "[epoch:78,batch:569]:acc: 0.891009,loss:0.258101\n",
      "[epoch:78,batch:599]:acc: 0.891615,loss:0.256621\n",
      "[epoch:78,batch:599]: val_loss:0.366618,val_acc:0.854594,val_total:4539\n",
      "[epoch:78,batch:629]:acc: 0.891667,loss:0.256570\n",
      "[epoch:78,batch:659]:acc: 0.891714,loss:0.257338\n",
      "[epoch:78,batch:689]:acc: 0.891893,loss:0.257370\n",
      "[epoch:78,batch:719]:acc: 0.892361,loss:0.256607\n",
      "[epoch:78,batch:749]:acc: 0.891958,loss:0.257607\n",
      "[epoch:78,batch:779]:acc: 0.891026,loss:0.258448\n",
      "[epoch:78,batch:809]:acc: 0.891088,loss:0.257793\n",
      "[epoch:78,batch:839]:acc: 0.890997,loss:0.257894\n",
      "[epoch:78,batch:869]:acc: 0.890841,loss:0.257302\n",
      "[epoch:78,batch:899]:acc: 0.891319,loss:0.256484\n",
      "[epoch:78,batch:899]: val_loss:0.406253,val_acc:0.855254,val_total:4539\n",
      "[epoch:78,batch:929]:acc: 0.890625,loss:0.257371\n",
      "[epoch:78,batch:959]:acc: 0.890853,loss:0.256819\n",
      "[epoch:78,batch:989]:acc: 0.890814,loss:0.256993\n",
      "[epoch:78] :acc: 0.890816,loss:0.256808,lr:0.000100,patience:0\n",
      "[epoch:78]: val_loss:0.382819,val_acc:0.857237,\n",
      "Epoch 79/119\n",
      "----------\n",
      "[epoch:79,batch:29]:acc: 0.893750,loss:0.242300\n",
      "[epoch:79,batch:59]:acc: 0.897396,loss:0.245529\n",
      "[epoch:79,batch:89]:acc: 0.902778,loss:0.233316\n",
      "[epoch:79,batch:119]:acc: 0.899219,loss:0.238078\n",
      "[epoch:79,batch:149]:acc: 0.897500,loss:0.238948\n",
      "[epoch:79,batch:179]:acc: 0.897396,loss:0.241434\n",
      "[epoch:79,batch:209]:acc: 0.899851,loss:0.239963\n",
      "[epoch:79,batch:239]:acc: 0.899219,loss:0.242959\n",
      "[epoch:79,batch:269]:acc: 0.898843,loss:0.243409\n",
      "[epoch:79,batch:299]:acc: 0.899583,loss:0.241442\n",
      "[epoch:79,batch:299]: val_loss:0.375350,val_acc:0.857017,val_total:4539\n",
      "[epoch:79,batch:329]:acc: 0.898958,loss:0.242433\n",
      "[epoch:79,batch:359]:acc: 0.898698,loss:0.242269\n",
      "[epoch:79,batch:389]:acc: 0.897676,loss:0.243051\n",
      "[epoch:79,batch:419]:acc: 0.897917,loss:0.242904\n",
      "[epoch:79,batch:449]:acc: 0.898472,loss:0.241727\n",
      "[epoch:79,batch:479]:acc: 0.897721,loss:0.243415\n",
      "[epoch:79,batch:509]:acc: 0.897488,loss:0.243314\n",
      "[epoch:79,batch:539]:acc: 0.897222,loss:0.244823\n",
      "[epoch:79,batch:569]:acc: 0.896382,loss:0.245229\n",
      "[epoch:79,batch:599]:acc: 0.896875,loss:0.244259\n",
      "[epoch:79,batch:599]: val_loss:0.357336,val_acc:0.858779,val_total:4539\n",
      "[epoch:79,batch:629]:acc: 0.896627,loss:0.245698\n",
      "[epoch:79,batch:659]:acc: 0.897017,loss:0.244878\n",
      "[epoch:79,batch:689]:acc: 0.896603,loss:0.244971\n",
      "[epoch:79,batch:719]:acc: 0.896745,loss:0.245564\n",
      "[epoch:79,batch:749]:acc: 0.896292,loss:0.245378\n",
      "[epoch:79,batch:779]:acc: 0.896354,loss:0.244687\n",
      "[epoch:79,batch:809]:acc: 0.896142,loss:0.244939\n",
      "[epoch:79,batch:839]:acc: 0.895350,loss:0.246177\n",
      "[epoch:79,batch:869]:acc: 0.894720,loss:0.246275\n",
      "[epoch:79,batch:899]:acc: 0.894931,loss:0.245949\n",
      "[epoch:79,batch:899]: val_loss:0.365861,val_acc:0.858779,val_total:4539\n",
      "[epoch:79,batch:929]:acc: 0.894456,loss:0.246678\n",
      "[epoch:79,batch:959]:acc: 0.893880,loss:0.247252\n",
      "[epoch:79,batch:989]:acc: 0.893497,loss:0.248054\n",
      "[epoch:79] :acc: 0.893559,loss:0.247849,lr:0.000100,patience:1\n",
      "[epoch:79]: val_loss:0.487408,val_acc:0.854814,\n",
      "Epoch 80/119\n",
      "----------\n",
      "[epoch:80,batch:29]:acc: 0.898958,loss:0.236854\n",
      "[epoch:80,batch:59]:acc: 0.901042,loss:0.228010\n",
      "[epoch:80,batch:89]:acc: 0.901389,loss:0.230529\n",
      "[epoch:80,batch:119]:acc: 0.904167,loss:0.227631\n",
      "[epoch:80,batch:149]:acc: 0.905625,loss:0.224764\n",
      "[epoch:80,batch:179]:acc: 0.903299,loss:0.225499\n",
      "[epoch:80,batch:209]:acc: 0.903125,loss:0.227402\n",
      "[epoch:80,batch:239]:acc: 0.904036,loss:0.225860\n",
      "[epoch:80,batch:269]:acc: 0.904051,loss:0.227732\n",
      "[epoch:80,batch:299]:acc: 0.902292,loss:0.230646\n",
      "[epoch:80,batch:299]: val_loss:0.400860,val_acc:0.856136,val_total:4539\n",
      "[epoch:80,batch:329]:acc: 0.901894,loss:0.230799\n",
      "[epoch:80,batch:359]:acc: 0.901736,loss:0.233387\n",
      "[epoch:80,batch:389]:acc: 0.900481,loss:0.236443\n",
      "[epoch:80,batch:419]:acc: 0.899554,loss:0.237043\n",
      "[epoch:80,batch:449]:acc: 0.898750,loss:0.238596\n",
      "[epoch:80,batch:479]:acc: 0.899740,loss:0.238196\n",
      "[epoch:80,batch:509]:acc: 0.898652,loss:0.240060\n",
      "[epoch:80,batch:539]:acc: 0.897975,loss:0.241768\n",
      "[epoch:80,batch:569]:acc: 0.897917,loss:0.242560\n",
      "[epoch:80,batch:599]:acc: 0.898177,loss:0.241907\n",
      "[epoch:80,batch:599]: val_loss:0.370182,val_acc:0.857678,val_total:4539\n",
      "[epoch:80,batch:629]:acc: 0.898413,loss:0.241826\n",
      "[epoch:80,batch:659]:acc: 0.898201,loss:0.242891\n",
      "[epoch:80,batch:689]:acc: 0.897826,loss:0.243247\n",
      "[epoch:80,batch:719]:acc: 0.897352,loss:0.243097\n",
      "[epoch:80,batch:749]:acc: 0.897208,loss:0.243152\n",
      "[epoch:80,batch:779]:acc: 0.897596,loss:0.242213\n",
      "[epoch:80,batch:809]:acc: 0.897647,loss:0.242026\n",
      "[epoch:80,batch:839]:acc: 0.897693,loss:0.241645\n",
      "[epoch:80,batch:869]:acc: 0.897055,loss:0.243461\n",
      "[epoch:80,batch:899]:acc: 0.897014,loss:0.242961\n",
      "[epoch:80,batch:899]: val_loss:0.366174,val_acc:0.859440,val_total:4539\n",
      "[epoch:80,batch:929]:acc: 0.896573,loss:0.244203\n",
      "[epoch:80,batch:959]:acc: 0.896484,loss:0.244515\n",
      "[epoch:80,batch:989]:acc: 0.896244,loss:0.245132\n",
      "[epoch:80] :acc: 0.896144,loss:0.245621,lr:0.000100,patience:2\n",
      "[epoch:80]: val_loss:0.425124,val_acc:0.856797,\n",
      "Epoch 81/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000020\n",
      "[epoch:81,batch:29]:acc: 0.900000,loss:0.233633\n",
      "[epoch:81,batch:59]:acc: 0.894271,loss:0.237690\n",
      "[epoch:81,batch:89]:acc: 0.894097,loss:0.241766\n",
      "[epoch:81,batch:119]:acc: 0.895052,loss:0.243008\n",
      "[epoch:81,batch:149]:acc: 0.896042,loss:0.245198\n",
      "[epoch:81,batch:179]:acc: 0.894097,loss:0.248330\n",
      "[epoch:81,batch:209]:acc: 0.892411,loss:0.251043\n",
      "[epoch:81,batch:239]:acc: 0.890495,loss:0.255511\n",
      "[epoch:81,batch:269]:acc: 0.887731,loss:0.259210\n",
      "[epoch:81,batch:299]:acc: 0.886979,loss:0.260585\n",
      "[epoch:81,batch:299]: val_loss:0.395200,val_acc:0.853933,val_total:4539\n",
      "[epoch:81,batch:329]:acc: 0.886458,loss:0.260107\n",
      "[epoch:81,batch:359]:acc: 0.886979,loss:0.258010\n",
      "[epoch:81,batch:389]:acc: 0.886058,loss:0.258922\n",
      "[epoch:81,batch:419]:acc: 0.885938,loss:0.260952\n",
      "[epoch:81,batch:449]:acc: 0.886528,loss:0.259933\n",
      "[epoch:81,batch:479]:acc: 0.887565,loss:0.258127\n",
      "[epoch:81,batch:509]:acc: 0.886765,loss:0.260229\n",
      "[epoch:81,batch:539]:acc: 0.886748,loss:0.260239\n",
      "[epoch:81,batch:569]:acc: 0.887884,loss:0.258828\n",
      "[epoch:81,batch:599]:acc: 0.887604,loss:0.259950\n",
      "[epoch:81,batch:599]: val_loss:0.434673,val_acc:0.855254,val_total:4539\n",
      "[epoch:81,batch:629]:acc: 0.887550,loss:0.259350\n",
      "[epoch:81,batch:659]:acc: 0.888210,loss:0.259662\n",
      "[epoch:81,batch:689]:acc: 0.888089,loss:0.260300\n",
      "[epoch:81,batch:719]:acc: 0.887760,loss:0.260816\n",
      "[epoch:81,batch:749]:acc: 0.888250,loss:0.260650\n",
      "[epoch:81,batch:779]:acc: 0.888782,loss:0.259857\n",
      "[epoch:81,batch:809]:acc: 0.888503,loss:0.260292\n",
      "[epoch:81,batch:839]:acc: 0.888653,loss:0.260295\n",
      "[epoch:81,batch:869]:acc: 0.888757,loss:0.259983\n",
      "[epoch:81,batch:899]:acc: 0.889097,loss:0.259548\n",
      "[epoch:81,batch:899]: val_loss:0.432074,val_acc:0.851729,val_total:4539\n",
      "[epoch:81,batch:929]:acc: 0.889415,loss:0.259252\n",
      "[epoch:81,batch:959]:acc: 0.889355,loss:0.258918\n",
      "[epoch:81,batch:989]:acc: 0.889489,loss:0.258616\n",
      "[epoch:81] :acc: 0.889334,loss:0.259460,lr:0.000020,patience:0\n",
      "[epoch:81]: val_loss:0.384336,val_acc:0.852390,\n",
      "Epoch 82/119\n",
      "----------\n",
      "[epoch:82,batch:29]:acc: 0.902083,loss:0.221973\n",
      "[epoch:82,batch:59]:acc: 0.885417,loss:0.258958\n",
      "[epoch:82,batch:89]:acc: 0.888194,loss:0.256801\n",
      "[epoch:82,batch:119]:acc: 0.893229,loss:0.252175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:82,batch:149]:acc: 0.887708,loss:0.259723\n",
      "[epoch:82,batch:179]:acc: 0.888021,loss:0.258426\n",
      "[epoch:82,batch:209]:acc: 0.887649,loss:0.260956\n",
      "[epoch:82,batch:239]:acc: 0.884505,loss:0.263026\n",
      "[epoch:82,batch:269]:acc: 0.884722,loss:0.264424\n",
      "[epoch:82,batch:299]:acc: 0.885417,loss:0.264790\n",
      "[epoch:82,batch:299]: val_loss:0.395720,val_acc:0.854153,val_total:4539\n",
      "[epoch:82,batch:329]:acc: 0.886458,loss:0.264074\n",
      "[epoch:82,batch:359]:acc: 0.886632,loss:0.264641\n",
      "[epoch:82,batch:389]:acc: 0.887340,loss:0.263419\n",
      "[epoch:82,batch:419]:acc: 0.887723,loss:0.263058\n",
      "[epoch:82,batch:449]:acc: 0.887917,loss:0.262170\n",
      "[epoch:82,batch:479]:acc: 0.887760,loss:0.263073\n",
      "[epoch:82,batch:509]:acc: 0.888051,loss:0.261746\n",
      "[epoch:82,batch:539]:acc: 0.887211,loss:0.262430\n",
      "[epoch:82,batch:569]:acc: 0.887226,loss:0.261373\n",
      "[epoch:82,batch:599]:acc: 0.887240,loss:0.261532\n",
      "[epoch:82,batch:599]: val_loss:0.387428,val_acc:0.856576,val_total:4539\n",
      "[epoch:82,batch:629]:acc: 0.888244,loss:0.260103\n",
      "[epoch:82,batch:659]:acc: 0.888826,loss:0.259464\n",
      "[epoch:82,batch:689]:acc: 0.889085,loss:0.258968\n",
      "[epoch:82,batch:719]:acc: 0.889062,loss:0.260068\n",
      "[epoch:82,batch:749]:acc: 0.889542,loss:0.259059\n",
      "[epoch:82,batch:779]:acc: 0.889383,loss:0.259337\n",
      "[epoch:82,batch:809]:acc: 0.889236,loss:0.259292\n",
      "[epoch:82,batch:839]:acc: 0.889397,loss:0.258344\n",
      "[epoch:82,batch:869]:acc: 0.889799,loss:0.257775\n",
      "[epoch:82,batch:899]:acc: 0.890451,loss:0.256854\n",
      "[epoch:82,batch:899]: val_loss:0.414464,val_acc:0.853492,val_total:4539\n",
      "[epoch:82,batch:929]:acc: 0.890491,loss:0.256134\n",
      "[epoch:82,batch:959]:acc: 0.890007,loss:0.256488\n",
      "[epoch:82,batch:989]:acc: 0.890120,loss:0.256519\n",
      "[epoch:82] :acc: 0.890090,loss:0.256431,lr:0.000020,patience:1\n",
      "[epoch:82]: val_loss:0.385876,val_acc:0.857458,\n",
      "Epoch 83/119\n",
      "----------\n",
      "[epoch:83,batch:29]:acc: 0.896875,loss:0.223538\n",
      "[epoch:83,batch:59]:acc: 0.897917,loss:0.242017\n",
      "[epoch:83,batch:89]:acc: 0.893750,loss:0.244828\n",
      "[epoch:83,batch:119]:acc: 0.891927,loss:0.249584\n",
      "[epoch:83,batch:149]:acc: 0.890833,loss:0.257628\n",
      "[epoch:83,batch:179]:acc: 0.893403,loss:0.254909\n",
      "[epoch:83,batch:209]:acc: 0.892113,loss:0.257302\n",
      "[epoch:83,batch:239]:acc: 0.892839,loss:0.256502\n",
      "[epoch:83,batch:269]:acc: 0.892361,loss:0.254033\n",
      "[epoch:83,batch:299]:acc: 0.891563,loss:0.255509\n",
      "[epoch:83,batch:299]: val_loss:0.380120,val_acc:0.856356,val_total:4539\n",
      "[epoch:83,batch:329]:acc: 0.889773,loss:0.258746\n",
      "[epoch:83,batch:359]:acc: 0.889931,loss:0.258388\n",
      "[epoch:83,batch:389]:acc: 0.889343,loss:0.259708\n",
      "[epoch:83,batch:419]:acc: 0.889658,loss:0.258701\n",
      "[epoch:83,batch:449]:acc: 0.890139,loss:0.257649\n",
      "[epoch:83,batch:479]:acc: 0.889844,loss:0.257533\n",
      "[epoch:83,batch:509]:acc: 0.888971,loss:0.258012\n",
      "[epoch:83,batch:539]:acc: 0.889931,loss:0.256138\n",
      "[epoch:83,batch:569]:acc: 0.890351,loss:0.255518\n",
      "[epoch:83,batch:599]:acc: 0.890000,loss:0.256224\n",
      "[epoch:83,batch:599]: val_loss:0.380017,val_acc:0.857898,val_total:4539\n",
      "[epoch:83,batch:629]:acc: 0.890675,loss:0.255372\n",
      "[epoch:83,batch:659]:acc: 0.890294,loss:0.254965\n",
      "[epoch:83,batch:689]:acc: 0.889493,loss:0.255367\n",
      "[epoch:83,batch:719]:acc: 0.889453,loss:0.255965\n",
      "[epoch:83,batch:749]:acc: 0.889083,loss:0.256079\n",
      "[epoch:83,batch:779]:acc: 0.889784,loss:0.255089\n",
      "[epoch:83,batch:809]:acc: 0.890316,loss:0.254233\n",
      "[epoch:83,batch:839]:acc: 0.890216,loss:0.254337\n",
      "[epoch:83,batch:869]:acc: 0.890338,loss:0.254196\n",
      "[epoch:83,batch:899]:acc: 0.890625,loss:0.253046\n",
      "[epoch:83,batch:899]: val_loss:0.397759,val_acc:0.854814,val_total:4539\n",
      "[epoch:83,batch:929]:acc: 0.890759,loss:0.253201\n",
      "[epoch:83,batch:959]:acc: 0.890820,loss:0.253256\n",
      "[epoch:83,batch:989]:acc: 0.890530,loss:0.254108\n",
      "[epoch:83] :acc: 0.890563,loss:0.254366,lr:0.000020,patience:2\n",
      "[epoch:83]: val_loss:0.407929,val_acc:0.856136,\n",
      "Epoch 84/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000004\n",
      "[epoch:84,batch:29]:acc: 0.866667,loss:0.271732\n",
      "[epoch:84,batch:59]:acc: 0.881771,loss:0.268192\n",
      "[epoch:84,batch:89]:acc: 0.878472,loss:0.269949\n",
      "[epoch:84,batch:119]:acc: 0.884375,loss:0.258822\n",
      "[epoch:84,batch:149]:acc: 0.885625,loss:0.259823\n",
      "[epoch:84,batch:179]:acc: 0.886111,loss:0.260973\n",
      "[epoch:84,batch:209]:acc: 0.888095,loss:0.258771\n",
      "[epoch:84,batch:239]:acc: 0.888802,loss:0.257205\n",
      "[epoch:84,batch:269]:acc: 0.888310,loss:0.257532\n",
      "[epoch:84,batch:299]:acc: 0.889375,loss:0.256292\n",
      "[epoch:84,batch:299]: val_loss:0.442203,val_acc:0.852831,val_total:4539\n",
      "[epoch:84,batch:329]:acc: 0.889110,loss:0.256833\n",
      "[epoch:84,batch:359]:acc: 0.888281,loss:0.258752\n",
      "[epoch:84,batch:389]:acc: 0.889744,loss:0.256956\n",
      "[epoch:84,batch:419]:acc: 0.890402,loss:0.256176\n",
      "[epoch:84,batch:449]:acc: 0.890139,loss:0.257057\n",
      "[epoch:84,batch:479]:acc: 0.890885,loss:0.256706\n",
      "[epoch:84,batch:509]:acc: 0.890686,loss:0.255822\n",
      "[epoch:84,batch:539]:acc: 0.889641,loss:0.257083\n",
      "[epoch:84,batch:569]:acc: 0.889309,loss:0.258213\n",
      "[epoch:84,batch:599]:acc: 0.889844,loss:0.257413\n",
      "[epoch:84,batch:599]: val_loss:0.425933,val_acc:0.852831,val_total:4539\n",
      "[epoch:84,batch:629]:acc: 0.888988,loss:0.259538\n",
      "[epoch:84,batch:659]:acc: 0.888826,loss:0.259277\n",
      "[epoch:84,batch:689]:acc: 0.889085,loss:0.258984\n",
      "[epoch:84,batch:719]:acc: 0.888889,loss:0.259546\n",
      "[epoch:84,batch:749]:acc: 0.888833,loss:0.260735\n",
      "[epoch:84,batch:779]:acc: 0.889383,loss:0.259659\n",
      "[epoch:84,batch:809]:acc: 0.889390,loss:0.259612\n",
      "[epoch:84,batch:839]:acc: 0.889583,loss:0.259229\n",
      "[epoch:84,batch:869]:acc: 0.889009,loss:0.259930\n",
      "[epoch:84,batch:899]:acc: 0.889167,loss:0.259534\n",
      "[epoch:84,batch:899]: val_loss:0.441225,val_acc:0.851289,val_total:4539\n",
      "[epoch:84,batch:929]:acc: 0.889046,loss:0.259599\n",
      "[epoch:84,batch:959]:acc: 0.888607,loss:0.260486\n",
      "[epoch:84,batch:989]:acc: 0.888573,loss:0.259884\n",
      "[epoch:84] :acc: 0.888640,loss:0.259924,lr:0.000004,patience:0\n",
      "[epoch:84]: val_loss:0.418940,val_acc:0.854814,\n",
      "Epoch 85/119\n",
      "----------\n",
      "[epoch:85,batch:29]:acc: 0.902083,loss:0.216060\n",
      "[epoch:85,batch:59]:acc: 0.902083,loss:0.229010\n",
      "[epoch:85,batch:89]:acc: 0.894097,loss:0.245137\n",
      "[epoch:85,batch:119]:acc: 0.892969,loss:0.254198\n",
      "[epoch:85,batch:149]:acc: 0.892708,loss:0.252981\n",
      "[epoch:85,batch:179]:acc: 0.889931,loss:0.255103\n",
      "[epoch:85,batch:209]:acc: 0.890179,loss:0.252662\n",
      "[epoch:85,batch:239]:acc: 0.891276,loss:0.252014\n",
      "[epoch:85,batch:269]:acc: 0.891898,loss:0.249483\n",
      "[epoch:85,batch:299]:acc: 0.891458,loss:0.252197\n",
      "[epoch:85,batch:299]: val_loss:0.378724,val_acc:0.854153,val_total:4539\n",
      "[epoch:85,batch:329]:acc: 0.891477,loss:0.252744\n",
      "[epoch:85,batch:359]:acc: 0.890885,loss:0.255001\n",
      "[epoch:85,batch:389]:acc: 0.890625,loss:0.256886\n",
      "[epoch:85,batch:419]:acc: 0.890030,loss:0.257962\n",
      "[epoch:85,batch:449]:acc: 0.889097,loss:0.259714\n",
      "[epoch:85,batch:479]:acc: 0.889714,loss:0.258714\n",
      "[epoch:85,batch:509]:acc: 0.889583,loss:0.257785\n",
      "[epoch:85,batch:539]:acc: 0.890162,loss:0.255652\n",
      "[epoch:85,batch:569]:acc: 0.891064,loss:0.254381\n",
      "[epoch:85,batch:599]:acc: 0.890677,loss:0.254997\n",
      "[epoch:85,batch:599]: val_loss:0.436310,val_acc:0.854594,val_total:4539\n",
      "[epoch:85,batch:629]:acc: 0.890228,loss:0.255559\n",
      "[epoch:85,batch:659]:acc: 0.890530,loss:0.255908\n",
      "[epoch:85,batch:689]:acc: 0.890580,loss:0.256071\n",
      "[epoch:85,batch:719]:acc: 0.889887,loss:0.256691\n",
      "[epoch:85,batch:749]:acc: 0.890083,loss:0.256476\n",
      "[epoch:85,batch:779]:acc: 0.889543,loss:0.257666\n",
      "[epoch:85,batch:809]:acc: 0.889468,loss:0.258040\n",
      "[epoch:85,batch:839]:acc: 0.889435,loss:0.258140\n",
      "[epoch:85,batch:869]:acc: 0.889224,loss:0.258061\n",
      "[epoch:85,batch:899]:acc: 0.889306,loss:0.257864\n",
      "[epoch:85,batch:899]: val_loss:0.428195,val_acc:0.852831,val_total:4539\n",
      "[epoch:85,batch:929]:acc: 0.888945,loss:0.258068\n",
      "[epoch:85,batch:959]:acc: 0.889225,loss:0.258095\n",
      "[epoch:85,batch:989]:acc: 0.889173,loss:0.258671\n",
      "[epoch:85] :acc: 0.889239,loss:0.258414,lr:0.000004,patience:1\n",
      "[epoch:85]: val_loss:0.406099,val_acc:0.853492,\n",
      "Epoch 86/119\n",
      "----------\n",
      "[epoch:86,batch:29]:acc: 0.868750,loss:0.299441\n",
      "[epoch:86,batch:59]:acc: 0.879687,loss:0.279088\n",
      "[epoch:86,batch:89]:acc: 0.879167,loss:0.286527\n",
      "[epoch:86,batch:119]:acc: 0.874740,loss:0.287219\n",
      "[epoch:86,batch:149]:acc: 0.876458,loss:0.283436\n",
      "[epoch:86,batch:179]:acc: 0.880035,loss:0.274775\n",
      "[epoch:86,batch:209]:acc: 0.880208,loss:0.275920\n",
      "[epoch:86,batch:239]:acc: 0.881120,loss:0.273418\n",
      "[epoch:86,batch:269]:acc: 0.884838,loss:0.268012\n",
      "[epoch:86,batch:299]:acc: 0.885104,loss:0.265805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:86,batch:299]: val_loss:0.412145,val_acc:0.853272,val_total:4539\n",
      "[epoch:86,batch:329]:acc: 0.886364,loss:0.262945\n",
      "[epoch:86,batch:359]:acc: 0.887847,loss:0.262643\n",
      "[epoch:86,batch:389]:acc: 0.888942,loss:0.260857\n",
      "[epoch:86,batch:419]:acc: 0.889732,loss:0.260855\n",
      "[epoch:86,batch:449]:acc: 0.889097,loss:0.261477\n",
      "[epoch:86,batch:479]:acc: 0.887891,loss:0.262699\n",
      "[epoch:86,batch:509]:acc: 0.888297,loss:0.262223\n",
      "[epoch:86,batch:539]:acc: 0.888368,loss:0.260964\n",
      "[epoch:86,batch:569]:acc: 0.889419,loss:0.259225\n",
      "[epoch:86,batch:599]:acc: 0.888594,loss:0.259110\n",
      "[epoch:86,batch:599]: val_loss:0.418271,val_acc:0.852831,val_total:4539\n",
      "[epoch:86,batch:629]:acc: 0.889534,loss:0.257539\n",
      "[epoch:86,batch:659]:acc: 0.889678,loss:0.257753\n",
      "[epoch:86,batch:689]:acc: 0.889493,loss:0.257372\n",
      "[epoch:86,batch:719]:acc: 0.890278,loss:0.256917\n",
      "[epoch:86,batch:749]:acc: 0.890458,loss:0.257034\n",
      "[epoch:86,batch:779]:acc: 0.889904,loss:0.257701\n",
      "[epoch:86,batch:809]:acc: 0.889583,loss:0.257960\n",
      "[epoch:86,batch:839]:acc: 0.889249,loss:0.258985\n",
      "[epoch:86,batch:869]:acc: 0.889080,loss:0.258619\n",
      "[epoch:86,batch:899]:acc: 0.889201,loss:0.258295\n",
      "[epoch:86,batch:899]: val_loss:0.402083,val_acc:0.852390,val_total:4539\n",
      "[epoch:86,batch:929]:acc: 0.888945,loss:0.258597\n",
      "[epoch:86,batch:959]:acc: 0.889095,loss:0.258308\n",
      "[epoch:86,batch:989]:acc: 0.888731,loss:0.258747\n",
      "[epoch:86] :acc: 0.888672,loss:0.258622,lr:0.000004,patience:2\n",
      "[epoch:86]: val_loss:0.418743,val_acc:0.853272,\n",
      "Epoch 87/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000001\n",
      "[epoch:87,batch:29]:acc: 0.878125,loss:0.289798\n",
      "[epoch:87,batch:59]:acc: 0.885938,loss:0.274549\n",
      "[epoch:87,batch:89]:acc: 0.886806,loss:0.275050\n",
      "[epoch:87,batch:119]:acc: 0.891146,loss:0.263348\n",
      "[epoch:87,batch:149]:acc: 0.891042,loss:0.262864\n",
      "[epoch:87,batch:179]:acc: 0.890451,loss:0.262424\n",
      "[epoch:87,batch:209]:acc: 0.890327,loss:0.259447\n",
      "[epoch:87,batch:239]:acc: 0.891016,loss:0.261047\n",
      "[epoch:87,batch:269]:acc: 0.890162,loss:0.261814\n",
      "[epoch:87,batch:299]:acc: 0.889167,loss:0.261655\n",
      "[epoch:87,batch:299]: val_loss:0.387498,val_acc:0.855034,val_total:4539\n",
      "[epoch:87,batch:329]:acc: 0.889867,loss:0.261985\n",
      "[epoch:87,batch:359]:acc: 0.889410,loss:0.262253\n",
      "[epoch:87,batch:389]:acc: 0.889984,loss:0.261260\n",
      "[epoch:87,batch:419]:acc: 0.889807,loss:0.262078\n",
      "[epoch:87,batch:449]:acc: 0.890278,loss:0.260870\n",
      "[epoch:87,batch:479]:acc: 0.889844,loss:0.261026\n",
      "[epoch:87,batch:509]:acc: 0.889277,loss:0.260831\n",
      "[epoch:87,batch:539]:acc: 0.889410,loss:0.259902\n",
      "[epoch:87,batch:569]:acc: 0.888761,loss:0.260933\n",
      "[epoch:87,batch:599]:acc: 0.889167,loss:0.259843\n",
      "[epoch:87,batch:599]: val_loss:0.391807,val_acc:0.855475,val_total:4539\n",
      "[epoch:87,batch:629]:acc: 0.889236,loss:0.259869\n",
      "[epoch:87,batch:659]:acc: 0.889583,loss:0.259767\n",
      "[epoch:87,batch:689]:acc: 0.889674,loss:0.259498\n",
      "[epoch:87,batch:719]:acc: 0.889714,loss:0.259505\n",
      "[epoch:87,batch:749]:acc: 0.889292,loss:0.260010\n",
      "[epoch:87,batch:779]:acc: 0.889663,loss:0.260161\n",
      "[epoch:87,batch:809]:acc: 0.889699,loss:0.259828\n",
      "[epoch:87,batch:839]:acc: 0.889025,loss:0.260585\n",
      "[epoch:87,batch:869]:acc: 0.888937,loss:0.260903\n",
      "[epoch:87,batch:899]:acc: 0.889167,loss:0.261050\n",
      "[epoch:87,batch:899]: val_loss:0.416828,val_acc:0.853272,val_total:4539\n",
      "[epoch:87,batch:929]:acc: 0.888978,loss:0.260877\n",
      "[epoch:87,batch:959]:acc: 0.888346,loss:0.260860\n",
      "[epoch:87,batch:989]:acc: 0.888889,loss:0.259882\n",
      "[epoch:87] :acc: 0.888955,loss:0.259977,lr:0.000001,patience:0\n",
      "[epoch:87]: val_loss:0.459888,val_acc:0.852170,\n",
      "Epoch 88/119\n",
      "----------\n",
      "[epoch:88,batch:29]:acc: 0.879167,loss:0.292818\n",
      "[epoch:88,batch:59]:acc: 0.881250,loss:0.277421\n",
      "[epoch:88,batch:89]:acc: 0.881250,loss:0.273437\n",
      "[epoch:88,batch:119]:acc: 0.883073,loss:0.268849\n",
      "[epoch:88,batch:149]:acc: 0.885417,loss:0.262977\n",
      "[epoch:88,batch:179]:acc: 0.886458,loss:0.261432\n",
      "[epoch:88,batch:209]:acc: 0.887798,loss:0.263099\n",
      "[epoch:88,batch:239]:acc: 0.888411,loss:0.259736\n",
      "[epoch:88,batch:269]:acc: 0.889120,loss:0.259139\n",
      "[epoch:88,batch:299]:acc: 0.889375,loss:0.257793\n",
      "[epoch:88,batch:299]: val_loss:0.369224,val_acc:0.854373,val_total:4539\n",
      "[epoch:88,batch:329]:acc: 0.889110,loss:0.258260\n",
      "[epoch:88,batch:359]:acc: 0.889670,loss:0.258658\n",
      "[epoch:88,batch:389]:acc: 0.889824,loss:0.258913\n",
      "[epoch:88,batch:419]:acc: 0.889360,loss:0.259113\n",
      "[epoch:88,batch:449]:acc: 0.889722,loss:0.258705\n",
      "[epoch:88,batch:479]:acc: 0.889518,loss:0.258761\n",
      "[epoch:88,batch:509]:acc: 0.889154,loss:0.258173\n",
      "[epoch:88,batch:539]:acc: 0.888194,loss:0.260234\n",
      "[epoch:88,batch:569]:acc: 0.888213,loss:0.259922\n",
      "[epoch:88,batch:599]:acc: 0.888073,loss:0.260201\n",
      "[epoch:88,batch:599]: val_loss:0.401120,val_acc:0.854814,val_total:4539\n",
      "[epoch:88,batch:629]:acc: 0.888492,loss:0.259153\n",
      "[epoch:88,batch:659]:acc: 0.889015,loss:0.259347\n",
      "[epoch:88,batch:689]:acc: 0.889357,loss:0.258859\n",
      "[epoch:88,batch:719]:acc: 0.888845,loss:0.259902\n",
      "[epoch:88,batch:749]:acc: 0.889417,loss:0.260031\n",
      "[epoch:88,batch:779]:acc: 0.888862,loss:0.261007\n",
      "[epoch:88,batch:809]:acc: 0.888657,loss:0.260970\n",
      "[epoch:88,batch:839]:acc: 0.888467,loss:0.260360\n",
      "[epoch:88,batch:869]:acc: 0.888721,loss:0.260470\n",
      "[epoch:88,batch:899]:acc: 0.888333,loss:0.260901\n",
      "[epoch:88,batch:899]: val_loss:0.404499,val_acc:0.854594,val_total:4539\n",
      "[epoch:88,batch:929]:acc: 0.888978,loss:0.260364\n",
      "[epoch:88,batch:959]:acc: 0.888639,loss:0.260096\n",
      "[epoch:88,batch:989]:acc: 0.888163,loss:0.261013\n",
      "[epoch:88] :acc: 0.888073,loss:0.261126,lr:0.000001,patience:1\n",
      "[epoch:88]: val_loss:0.376301,val_acc:0.857017,\n",
      "Epoch 89/119\n",
      "----------\n",
      "[epoch:89,batch:29]:acc: 0.893750,loss:0.262690\n",
      "[epoch:89,batch:59]:acc: 0.895312,loss:0.257986\n",
      "[epoch:89,batch:89]:acc: 0.898611,loss:0.255632\n",
      "[epoch:89,batch:119]:acc: 0.892188,loss:0.265938\n",
      "[epoch:89,batch:149]:acc: 0.893542,loss:0.258889\n",
      "[epoch:89,batch:179]:acc: 0.896354,loss:0.251025\n",
      "[epoch:89,batch:209]:acc: 0.893304,loss:0.253792\n",
      "[epoch:89,batch:239]:acc: 0.894401,loss:0.252326\n",
      "[epoch:89,batch:269]:acc: 0.892708,loss:0.255075\n",
      "[epoch:89,batch:299]:acc: 0.891771,loss:0.254601\n",
      "[epoch:89,batch:299]: val_loss:0.399910,val_acc:0.855915,val_total:4539\n",
      "[epoch:89,batch:329]:acc: 0.891572,loss:0.256251\n",
      "[epoch:89,batch:359]:acc: 0.890365,loss:0.257078\n",
      "[epoch:89,batch:389]:acc: 0.889984,loss:0.257902\n",
      "[epoch:89,batch:419]:acc: 0.890476,loss:0.257198\n",
      "[epoch:89,batch:449]:acc: 0.890556,loss:0.256851\n",
      "[epoch:89,batch:479]:acc: 0.889648,loss:0.259222\n",
      "[epoch:89,batch:509]:acc: 0.889828,loss:0.258175\n",
      "[epoch:89,batch:539]:acc: 0.889815,loss:0.258166\n",
      "[epoch:89,batch:569]:acc: 0.889583,loss:0.257597\n",
      "[epoch:89,batch:599]:acc: 0.889948,loss:0.257346\n",
      "[epoch:89,batch:599]: val_loss:0.430993,val_acc:0.854594,val_total:4539\n",
      "[epoch:89,batch:629]:acc: 0.888988,loss:0.258450\n",
      "[epoch:89,batch:659]:acc: 0.888826,loss:0.258641\n",
      "[epoch:89,batch:689]:acc: 0.888904,loss:0.257864\n",
      "[epoch:89,batch:719]:acc: 0.888542,loss:0.258742\n",
      "[epoch:89,batch:749]:acc: 0.888958,loss:0.258144\n",
      "[epoch:89,batch:779]:acc: 0.888662,loss:0.258740\n",
      "[epoch:89,batch:809]:acc: 0.889082,loss:0.258324\n",
      "[epoch:89,batch:839]:acc: 0.888690,loss:0.257991\n",
      "[epoch:89,batch:869]:acc: 0.888578,loss:0.258624\n",
      "[epoch:89,batch:899]:acc: 0.888854,loss:0.258194\n",
      "[epoch:89,batch:899]: val_loss:0.396660,val_acc:0.849526,val_total:4539\n",
      "[epoch:89,batch:929]:acc: 0.888743,loss:0.258954\n",
      "[epoch:89,batch:959]:acc: 0.888997,loss:0.258673\n",
      "[epoch:89,batch:989]:acc: 0.888794,loss:0.259038\n",
      "[epoch:89] :acc: 0.888735,loss:0.259164,lr:0.000001,patience:2\n",
      "[epoch:89]: val_loss:0.399401,val_acc:0.853492,\n",
      "Epoch 90/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:90,batch:29]:acc: 0.885417,loss:0.256867\n",
      "[epoch:90,batch:59]:acc: 0.878125,loss:0.264273\n",
      "[epoch:90,batch:89]:acc: 0.882639,loss:0.258586\n",
      "[epoch:90,batch:119]:acc: 0.880729,loss:0.262980\n",
      "[epoch:90,batch:149]:acc: 0.883333,loss:0.261852\n",
      "[epoch:90,batch:179]:acc: 0.885417,loss:0.258970\n",
      "[epoch:90,batch:209]:acc: 0.885863,loss:0.257012\n",
      "[epoch:90,batch:239]:acc: 0.884635,loss:0.260918\n",
      "[epoch:90,batch:269]:acc: 0.885995,loss:0.259804\n",
      "[epoch:90,batch:299]:acc: 0.885521,loss:0.259984\n",
      "[epoch:90,batch:299]: val_loss:0.414907,val_acc:0.854373,val_total:4539\n",
      "[epoch:90,batch:329]:acc: 0.885985,loss:0.259845\n",
      "[epoch:90,batch:359]:acc: 0.885677,loss:0.262375\n",
      "[epoch:90,batch:389]:acc: 0.887179,loss:0.261717\n",
      "[epoch:90,batch:419]:acc: 0.887946,loss:0.261545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:90,batch:449]:acc: 0.887708,loss:0.262626\n",
      "[epoch:90,batch:479]:acc: 0.886458,loss:0.263257\n",
      "[epoch:90,batch:509]:acc: 0.887377,loss:0.262183\n",
      "[epoch:90,batch:539]:acc: 0.887095,loss:0.262031\n",
      "[epoch:90,batch:569]:acc: 0.887555,loss:0.260736\n",
      "[epoch:90,batch:599]:acc: 0.888177,loss:0.260063\n",
      "[epoch:90,batch:599]: val_loss:0.396321,val_acc:0.853492,val_total:4539\n",
      "[epoch:90,batch:629]:acc: 0.888145,loss:0.260986\n",
      "[epoch:90,batch:659]:acc: 0.888636,loss:0.259974\n",
      "[epoch:90,batch:689]:acc: 0.888134,loss:0.260374\n",
      "[epoch:90,batch:719]:acc: 0.888021,loss:0.260361\n",
      "[epoch:90,batch:749]:acc: 0.887667,loss:0.260698\n",
      "[epoch:90,batch:779]:acc: 0.887901,loss:0.260559\n",
      "[epoch:90,batch:809]:acc: 0.887654,loss:0.261582\n",
      "[epoch:90,batch:839]:acc: 0.887984,loss:0.261181\n",
      "[epoch:90,batch:869]:acc: 0.888254,loss:0.260920\n",
      "[epoch:90,batch:899]:acc: 0.887500,loss:0.261859\n",
      "[epoch:90,batch:899]: val_loss:0.421855,val_acc:0.854373,val_total:4539\n",
      "[epoch:90,batch:929]:acc: 0.887702,loss:0.261506\n",
      "[epoch:90,batch:959]:acc: 0.888021,loss:0.260764\n",
      "[epoch:90,batch:989]:acc: 0.888037,loss:0.261585\n",
      "[epoch:90] :acc: 0.887978,loss:0.262374,lr:0.000000,patience:0\n",
      "[epoch:90]: val_loss:0.387895,val_acc:0.854594,\n",
      "Epoch 91/119\n",
      "----------\n",
      "[epoch:91,batch:29]:acc: 0.879167,loss:0.267764\n",
      "[epoch:91,batch:59]:acc: 0.879687,loss:0.270975\n",
      "[epoch:91,batch:89]:acc: 0.880556,loss:0.266220\n",
      "[epoch:91,batch:119]:acc: 0.882552,loss:0.268553\n",
      "[epoch:91,batch:149]:acc: 0.883333,loss:0.265737\n",
      "[epoch:91,batch:179]:acc: 0.883681,loss:0.264043\n",
      "[epoch:91,batch:209]:acc: 0.886756,loss:0.262000\n",
      "[epoch:91,batch:239]:acc: 0.887630,loss:0.260508\n",
      "[epoch:91,batch:269]:acc: 0.887384,loss:0.261055\n",
      "[epoch:91,batch:299]:acc: 0.887500,loss:0.261095\n",
      "[epoch:91,batch:299]: val_loss:0.402342,val_acc:0.853712,val_total:4539\n",
      "[epoch:91,batch:329]:acc: 0.887973,loss:0.260995\n",
      "[epoch:91,batch:359]:acc: 0.888021,loss:0.263069\n",
      "[epoch:91,batch:389]:acc: 0.888782,loss:0.261420\n",
      "[epoch:91,batch:419]:acc: 0.888690,loss:0.261800\n",
      "[epoch:91,batch:449]:acc: 0.888819,loss:0.261933\n",
      "[epoch:91,batch:479]:acc: 0.888607,loss:0.262439\n",
      "[epoch:91,batch:509]:acc: 0.888542,loss:0.262472\n",
      "[epoch:91,batch:539]:acc: 0.889641,loss:0.260975\n",
      "[epoch:91,batch:569]:acc: 0.889309,loss:0.261438\n",
      "[epoch:91,batch:599]:acc: 0.888854,loss:0.260795\n",
      "[epoch:91,batch:599]: val_loss:0.424150,val_acc:0.854373,val_total:4539\n",
      "[epoch:91,batch:629]:acc: 0.888938,loss:0.260904\n",
      "[epoch:91,batch:659]:acc: 0.888968,loss:0.260121\n",
      "[epoch:91,batch:689]:acc: 0.889266,loss:0.259772\n",
      "[epoch:91,batch:719]:acc: 0.889323,loss:0.259845\n",
      "[epoch:91,batch:749]:acc: 0.889292,loss:0.260047\n",
      "[epoch:91,batch:779]:acc: 0.889062,loss:0.259807\n",
      "[epoch:91,batch:809]:acc: 0.888773,loss:0.259695\n",
      "[epoch:91,batch:839]:acc: 0.888653,loss:0.259912\n",
      "[epoch:91,batch:869]:acc: 0.888901,loss:0.259763\n",
      "[epoch:91,batch:899]:acc: 0.889236,loss:0.259515\n",
      "[epoch:91,batch:899]: val_loss:0.376567,val_acc:0.854594,val_total:4539\n",
      "[epoch:91,batch:929]:acc: 0.888609,loss:0.260767\n",
      "[epoch:91,batch:959]:acc: 0.888932,loss:0.260407\n",
      "[epoch:91,batch:989]:acc: 0.888763,loss:0.260213\n",
      "[epoch:91] :acc: 0.888703,loss:0.260313,lr:0.000000,patience:1\n",
      "[epoch:91]: val_loss:0.434661,val_acc:0.851729,\n",
      "Epoch 92/119\n",
      "----------\n",
      "[epoch:92,batch:29]:acc: 0.883333,loss:0.263362\n",
      "[epoch:92,batch:59]:acc: 0.886979,loss:0.261297\n",
      "[epoch:92,batch:89]:acc: 0.888194,loss:0.253626\n",
      "[epoch:92,batch:119]:acc: 0.888281,loss:0.257672\n",
      "[epoch:92,batch:149]:acc: 0.888125,loss:0.254948\n",
      "[epoch:92,batch:179]:acc: 0.889583,loss:0.255467\n",
      "[epoch:92,batch:209]:acc: 0.888690,loss:0.257548\n",
      "[epoch:92,batch:239]:acc: 0.886589,loss:0.258656\n",
      "[epoch:92,batch:269]:acc: 0.887269,loss:0.259150\n",
      "[epoch:92,batch:299]:acc: 0.887708,loss:0.260136\n",
      "[epoch:92,batch:299]: val_loss:0.431563,val_acc:0.853492,val_total:4539\n",
      "[epoch:92,batch:329]:acc: 0.888826,loss:0.259559\n",
      "[epoch:92,batch:359]:acc: 0.889062,loss:0.260259\n",
      "[epoch:92,batch:389]:acc: 0.887901,loss:0.262039\n",
      "[epoch:92,batch:419]:acc: 0.887649,loss:0.262582\n",
      "[epoch:92,batch:449]:acc: 0.887917,loss:0.262147\n",
      "[epoch:92,batch:479]:acc: 0.886849,loss:0.264948\n",
      "[epoch:92,batch:509]:acc: 0.886765,loss:0.264846\n",
      "[epoch:92,batch:539]:acc: 0.886343,loss:0.266080\n",
      "[epoch:92,batch:569]:acc: 0.885965,loss:0.265445\n",
      "[epoch:92,batch:599]:acc: 0.885677,loss:0.264691\n",
      "[epoch:92,batch:599]: val_loss:0.401925,val_acc:0.853933,val_total:4539\n",
      "[epoch:92,batch:629]:acc: 0.886409,loss:0.262675\n",
      "[epoch:92,batch:659]:acc: 0.886884,loss:0.261802\n",
      "[epoch:92,batch:689]:acc: 0.887591,loss:0.261769\n",
      "[epoch:92,batch:719]:acc: 0.887760,loss:0.261979\n",
      "[epoch:92,batch:749]:acc: 0.888042,loss:0.261362\n",
      "[epoch:92,batch:779]:acc: 0.888502,loss:0.260676\n",
      "[epoch:92,batch:809]:acc: 0.888503,loss:0.261385\n",
      "[epoch:92,batch:839]:acc: 0.888132,loss:0.261605\n",
      "[epoch:92,batch:869]:acc: 0.888039,loss:0.261783\n",
      "[epoch:92,batch:899]:acc: 0.887882,loss:0.261826\n",
      "[epoch:92,batch:899]: val_loss:0.436677,val_acc:0.852831,val_total:4539\n",
      "[epoch:92,batch:929]:acc: 0.887634,loss:0.261346\n",
      "[epoch:92,batch:959]:acc: 0.887695,loss:0.261425\n",
      "[epoch:92,batch:989]:acc: 0.888068,loss:0.260799\n",
      "[epoch:92] :acc: 0.888073,loss:0.260841,lr:0.000000,patience:2\n",
      "[epoch:92]: val_loss:0.393797,val_acc:0.852390,\n",
      "Epoch 93/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:93,batch:29]:acc: 0.910417,loss:0.235681\n",
      "[epoch:93,batch:59]:acc: 0.900000,loss:0.254703\n",
      "[epoch:93,batch:89]:acc: 0.889583,loss:0.273211\n",
      "[epoch:93,batch:119]:acc: 0.889323,loss:0.274049\n",
      "[epoch:93,batch:149]:acc: 0.889167,loss:0.267029\n",
      "[epoch:93,batch:179]:acc: 0.884896,loss:0.270552\n",
      "[epoch:93,batch:209]:acc: 0.883780,loss:0.270779\n",
      "[epoch:93,batch:239]:acc: 0.882812,loss:0.271080\n",
      "[epoch:93,batch:269]:acc: 0.882986,loss:0.270162\n",
      "[epoch:93,batch:299]:acc: 0.883854,loss:0.266333\n",
      "[epoch:93,batch:299]: val_loss:0.406891,val_acc:0.853712,val_total:4539\n",
      "[epoch:93,batch:329]:acc: 0.884564,loss:0.266904\n",
      "[epoch:93,batch:359]:acc: 0.883941,loss:0.266615\n",
      "[epoch:93,batch:389]:acc: 0.884615,loss:0.264656\n",
      "[epoch:93,batch:419]:acc: 0.884747,loss:0.264752\n",
      "[epoch:93,batch:449]:acc: 0.884236,loss:0.264933\n",
      "[epoch:93,batch:479]:acc: 0.884505,loss:0.265830\n",
      "[epoch:93,batch:509]:acc: 0.884926,loss:0.265735\n",
      "[epoch:93,batch:539]:acc: 0.884954,loss:0.266357\n",
      "[epoch:93,batch:569]:acc: 0.884101,loss:0.266027\n",
      "[epoch:93,batch:599]:acc: 0.885052,loss:0.265067\n",
      "[epoch:93,batch:599]: val_loss:0.386408,val_acc:0.853492,val_total:4539\n",
      "[epoch:93,batch:629]:acc: 0.885069,loss:0.265278\n",
      "[epoch:93,batch:659]:acc: 0.884848,loss:0.265254\n",
      "[epoch:93,batch:689]:acc: 0.885734,loss:0.263594\n",
      "[epoch:93,batch:719]:acc: 0.886155,loss:0.263090\n",
      "[epoch:93,batch:749]:acc: 0.886500,loss:0.262947\n",
      "[epoch:93,batch:779]:acc: 0.887059,loss:0.261894\n",
      "[epoch:93,batch:809]:acc: 0.887230,loss:0.261217\n",
      "[epoch:93,batch:839]:acc: 0.887091,loss:0.261719\n",
      "[epoch:93,batch:869]:acc: 0.886889,loss:0.262841\n",
      "[epoch:93,batch:899]:acc: 0.886806,loss:0.262722\n",
      "[epoch:93,batch:899]: val_loss:0.360837,val_acc:0.853712,val_total:4539\n",
      "[epoch:93,batch:929]:acc: 0.887433,loss:0.261529\n",
      "[epoch:93,batch:959]:acc: 0.887565,loss:0.261416\n",
      "[epoch:93,batch:989]:acc: 0.887342,loss:0.261573\n",
      "[epoch:93] :acc: 0.887316,loss:0.261699,lr:0.000000,patience:0\n",
      "[epoch:93]: val_loss:0.372141,val_acc:0.854594,\n",
      "Epoch 94/119\n",
      "----------\n",
      "[epoch:94,batch:29]:acc: 0.884375,loss:0.256232\n",
      "[epoch:94,batch:59]:acc: 0.884896,loss:0.254663\n",
      "[epoch:94,batch:89]:acc: 0.886458,loss:0.255977\n",
      "[epoch:94,batch:119]:acc: 0.888542,loss:0.255256\n",
      "[epoch:94,batch:149]:acc: 0.888333,loss:0.254920\n",
      "[epoch:94,batch:179]:acc: 0.887500,loss:0.254648\n",
      "[epoch:94,batch:209]:acc: 0.886607,loss:0.257143\n",
      "[epoch:94,batch:239]:acc: 0.883594,loss:0.262954\n",
      "[epoch:94,batch:269]:acc: 0.882870,loss:0.262260\n",
      "[epoch:94,batch:299]:acc: 0.882396,loss:0.261551\n",
      "[epoch:94,batch:299]: val_loss:0.377446,val_acc:0.855475,val_total:4539\n",
      "[epoch:94,batch:329]:acc: 0.883333,loss:0.261211\n",
      "[epoch:94,batch:359]:acc: 0.883247,loss:0.261705\n",
      "[epoch:94,batch:389]:acc: 0.882772,loss:0.264082\n",
      "[epoch:94,batch:419]:acc: 0.883557,loss:0.261663\n",
      "[epoch:94,batch:449]:acc: 0.883819,loss:0.262692\n",
      "[epoch:94,batch:479]:acc: 0.884701,loss:0.262337\n",
      "[epoch:94,batch:509]:acc: 0.884865,loss:0.262087\n",
      "[epoch:94,batch:539]:acc: 0.884664,loss:0.261729\n",
      "[epoch:94,batch:569]:acc: 0.884704,loss:0.261320\n",
      "[epoch:94,batch:599]:acc: 0.884531,loss:0.262391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:94,batch:599]: val_loss:0.386733,val_acc:0.855034,val_total:4539\n",
      "[epoch:94,batch:629]:acc: 0.885268,loss:0.262494\n",
      "[epoch:94,batch:659]:acc: 0.885701,loss:0.260753\n",
      "[epoch:94,batch:689]:acc: 0.886096,loss:0.260717\n",
      "[epoch:94,batch:719]:acc: 0.886285,loss:0.260646\n",
      "[epoch:94,batch:749]:acc: 0.886208,loss:0.260536\n",
      "[epoch:94,batch:779]:acc: 0.885938,loss:0.261433\n",
      "[epoch:94,batch:809]:acc: 0.886188,loss:0.261222\n",
      "[epoch:94,batch:839]:acc: 0.886235,loss:0.260594\n",
      "[epoch:94,batch:869]:acc: 0.886818,loss:0.259971\n",
      "[epoch:94,batch:899]:acc: 0.887153,loss:0.259165\n",
      "[epoch:94,batch:899]: val_loss:0.425846,val_acc:0.854814,val_total:4539\n",
      "[epoch:94,batch:929]:acc: 0.886895,loss:0.260219\n",
      "[epoch:94,batch:959]:acc: 0.886523,loss:0.260802\n",
      "[epoch:94,batch:989]:acc: 0.886742,loss:0.260110\n",
      "[epoch:94] :acc: 0.886748,loss:0.259989,lr:0.000000,patience:1\n",
      "[epoch:94]: val_loss:0.414167,val_acc:0.853051,\n",
      "Epoch 95/119\n",
      "----------\n",
      "[epoch:95,batch:29]:acc: 0.879167,loss:0.269265\n",
      "[epoch:95,batch:59]:acc: 0.888542,loss:0.258991\n",
      "[epoch:95,batch:89]:acc: 0.889931,loss:0.262679\n",
      "[epoch:95,batch:119]:acc: 0.885938,loss:0.268347\n",
      "[epoch:95,batch:149]:acc: 0.887917,loss:0.265831\n",
      "[epoch:95,batch:179]:acc: 0.888021,loss:0.267136\n",
      "[epoch:95,batch:209]:acc: 0.886458,loss:0.269551\n",
      "[epoch:95,batch:239]:acc: 0.887630,loss:0.265751\n",
      "[epoch:95,batch:269]:acc: 0.888657,loss:0.262173\n",
      "[epoch:95,batch:299]:acc: 0.888750,loss:0.262657\n",
      "[epoch:95,batch:299]: val_loss:0.452521,val_acc:0.853712,val_total:4539\n",
      "[epoch:95,batch:329]:acc: 0.887973,loss:0.263373\n",
      "[epoch:95,batch:359]:acc: 0.888802,loss:0.261430\n",
      "[epoch:95,batch:389]:acc: 0.888862,loss:0.261557\n",
      "[epoch:95,batch:419]:acc: 0.888542,loss:0.262938\n",
      "[epoch:95,batch:449]:acc: 0.888889,loss:0.262700\n",
      "[epoch:95,batch:479]:acc: 0.888411,loss:0.263028\n",
      "[epoch:95,batch:509]:acc: 0.888051,loss:0.263350\n",
      "[epoch:95,batch:539]:acc: 0.887674,loss:0.263098\n",
      "[epoch:95,batch:569]:acc: 0.887336,loss:0.264650\n",
      "[epoch:95,batch:599]:acc: 0.888333,loss:0.261629\n",
      "[epoch:95,batch:599]: val_loss:0.374959,val_acc:0.853933,val_total:4539\n",
      "[epoch:95,batch:629]:acc: 0.889087,loss:0.260773\n",
      "[epoch:95,batch:659]:acc: 0.888873,loss:0.261148\n",
      "[epoch:95,batch:689]:acc: 0.889176,loss:0.260384\n",
      "[epoch:95,batch:719]:acc: 0.888455,loss:0.261106\n",
      "[epoch:95,batch:749]:acc: 0.888792,loss:0.260028\n",
      "[epoch:95,batch:779]:acc: 0.888061,loss:0.260782\n",
      "[epoch:95,batch:809]:acc: 0.888040,loss:0.260909\n",
      "[epoch:95,batch:839]:acc: 0.888579,loss:0.260123\n",
      "[epoch:95,batch:869]:acc: 0.888218,loss:0.260583\n",
      "[epoch:95,batch:899]:acc: 0.887847,loss:0.261357\n",
      "[epoch:95,batch:899]: val_loss:0.441311,val_acc:0.854814,val_total:4539\n",
      "[epoch:95,batch:929]:acc: 0.887735,loss:0.261440\n",
      "[epoch:95,batch:959]:acc: 0.887826,loss:0.261064\n",
      "[epoch:95,batch:989]:acc: 0.887879,loss:0.260940\n",
      "[epoch:95] :acc: 0.887852,loss:0.260673,lr:0.000000,patience:2\n",
      "[epoch:95]: val_loss:0.429646,val_acc:0.852390,\n",
      "Epoch 96/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:96,batch:29]:acc: 0.892708,loss:0.248375\n",
      "[epoch:96,batch:59]:acc: 0.891667,loss:0.242011\n",
      "[epoch:96,batch:89]:acc: 0.892361,loss:0.239489\n",
      "[epoch:96,batch:119]:acc: 0.884375,loss:0.262196\n",
      "[epoch:96,batch:149]:acc: 0.885625,loss:0.263887\n",
      "[epoch:96,batch:179]:acc: 0.886458,loss:0.259533\n",
      "[epoch:96,batch:209]:acc: 0.890774,loss:0.251673\n",
      "[epoch:96,batch:239]:acc: 0.890625,loss:0.252983\n",
      "[epoch:96,batch:269]:acc: 0.891088,loss:0.253443\n",
      "[epoch:96,batch:299]:acc: 0.891458,loss:0.253734\n",
      "[epoch:96,batch:299]: val_loss:0.399452,val_acc:0.853272,val_total:4539\n",
      "[epoch:96,batch:329]:acc: 0.891951,loss:0.252776\n",
      "[epoch:96,batch:359]:acc: 0.888628,loss:0.257354\n",
      "[epoch:96,batch:389]:acc: 0.887660,loss:0.259268\n",
      "[epoch:96,batch:419]:acc: 0.888095,loss:0.259258\n",
      "[epoch:96,batch:449]:acc: 0.889097,loss:0.257286\n",
      "[epoch:96,batch:479]:acc: 0.889128,loss:0.257719\n",
      "[epoch:96,batch:509]:acc: 0.889277,loss:0.257660\n",
      "[epoch:96,batch:539]:acc: 0.889062,loss:0.259277\n",
      "[epoch:96,batch:569]:acc: 0.889090,loss:0.261074\n",
      "[epoch:96,batch:599]:acc: 0.888750,loss:0.261085\n",
      "[epoch:96,batch:599]: val_loss:0.387666,val_acc:0.854814,val_total:4539\n",
      "[epoch:96,batch:629]:acc: 0.888542,loss:0.261184\n",
      "[epoch:96,batch:659]:acc: 0.888447,loss:0.261798\n",
      "[epoch:96,batch:689]:acc: 0.888723,loss:0.261182\n",
      "[epoch:96,batch:719]:acc: 0.888802,loss:0.261122\n",
      "[epoch:96,batch:749]:acc: 0.888167,loss:0.261234\n",
      "[epoch:96,batch:779]:acc: 0.887981,loss:0.261181\n",
      "[epoch:96,batch:809]:acc: 0.887963,loss:0.261545\n",
      "[epoch:96,batch:839]:acc: 0.888021,loss:0.262571\n",
      "[epoch:96,batch:869]:acc: 0.888434,loss:0.261880\n",
      "[epoch:96,batch:899]:acc: 0.888715,loss:0.261625\n",
      "[epoch:96,batch:899]: val_loss:0.446923,val_acc:0.851950,val_total:4539\n",
      "[epoch:96,batch:929]:acc: 0.888474,loss:0.261112\n",
      "[epoch:96,batch:959]:acc: 0.888281,loss:0.261537\n",
      "[epoch:96,batch:989]:acc: 0.887847,loss:0.262270\n",
      "[epoch:96] :acc: 0.887820,loss:0.262602,lr:0.000000,patience:0\n",
      "[epoch:96]: val_loss:0.433027,val_acc:0.854153,\n",
      "Epoch 97/119\n",
      "----------\n",
      "[epoch:97,batch:29]:acc: 0.871875,loss:0.275856\n",
      "[epoch:97,batch:59]:acc: 0.873958,loss:0.277008\n",
      "[epoch:97,batch:89]:acc: 0.872569,loss:0.279821\n",
      "[epoch:97,batch:119]:acc: 0.878125,loss:0.273235\n",
      "[epoch:97,batch:149]:acc: 0.880625,loss:0.269619\n",
      "[epoch:97,batch:179]:acc: 0.881076,loss:0.266892\n",
      "[epoch:97,batch:209]:acc: 0.883333,loss:0.264418\n",
      "[epoch:97,batch:239]:acc: 0.886458,loss:0.259390\n",
      "[epoch:97,batch:269]:acc: 0.886690,loss:0.260308\n",
      "[epoch:97,batch:299]:acc: 0.888021,loss:0.259948\n",
      "[epoch:97,batch:299]: val_loss:0.409380,val_acc:0.854153,val_total:4539\n",
      "[epoch:97,batch:329]:acc: 0.888163,loss:0.260862\n",
      "[epoch:97,batch:359]:acc: 0.888281,loss:0.261657\n",
      "[epoch:97,batch:389]:acc: 0.888462,loss:0.260530\n",
      "[epoch:97,batch:419]:acc: 0.888318,loss:0.260772\n",
      "[epoch:97,batch:449]:acc: 0.888472,loss:0.259367\n",
      "[epoch:97,batch:479]:acc: 0.889062,loss:0.259358\n",
      "[epoch:97,batch:509]:acc: 0.888971,loss:0.260919\n",
      "[epoch:97,batch:539]:acc: 0.889120,loss:0.260052\n",
      "[epoch:97,batch:569]:acc: 0.889857,loss:0.258418\n",
      "[epoch:97,batch:599]:acc: 0.889740,loss:0.258292\n",
      "[epoch:97,batch:599]: val_loss:0.432543,val_acc:0.851950,val_total:4539\n",
      "[epoch:97,batch:629]:acc: 0.889583,loss:0.258668\n",
      "[epoch:97,batch:659]:acc: 0.889347,loss:0.258512\n",
      "[epoch:97,batch:689]:acc: 0.889538,loss:0.258222\n",
      "[epoch:97,batch:719]:acc: 0.889974,loss:0.257508\n",
      "[epoch:97,batch:749]:acc: 0.890458,loss:0.257640\n",
      "[epoch:97,batch:779]:acc: 0.890865,loss:0.257067\n",
      "[epoch:97,batch:809]:acc: 0.890741,loss:0.256879\n",
      "[epoch:97,batch:839]:acc: 0.890290,loss:0.257691\n",
      "[epoch:97,batch:869]:acc: 0.889655,loss:0.258788\n",
      "[epoch:97,batch:899]:acc: 0.889757,loss:0.258445\n",
      "[epoch:97,batch:899]: val_loss:0.365511,val_acc:0.855915,val_total:4539\n",
      "[epoch:97,batch:929]:acc: 0.889550,loss:0.258944\n",
      "[epoch:97,batch:959]:acc: 0.889160,loss:0.259520\n",
      "[epoch:97,batch:989]:acc: 0.888826,loss:0.260024\n",
      "[epoch:97] :acc: 0.888861,loss:0.259779,lr:0.000000,patience:1\n",
      "[epoch:97]: val_loss:0.435526,val_acc:0.851068,\n",
      "Epoch 98/119\n",
      "----------\n",
      "[epoch:98,batch:29]:acc: 0.894792,loss:0.252391\n",
      "[epoch:98,batch:59]:acc: 0.884375,loss:0.272914\n",
      "[epoch:98,batch:89]:acc: 0.877083,loss:0.277186\n",
      "[epoch:98,batch:119]:acc: 0.878385,loss:0.276004\n",
      "[epoch:98,batch:149]:acc: 0.878958,loss:0.274130\n",
      "[epoch:98,batch:179]:acc: 0.881597,loss:0.270010\n",
      "[epoch:98,batch:209]:acc: 0.883482,loss:0.265200\n",
      "[epoch:98,batch:239]:acc: 0.883594,loss:0.265531\n",
      "[epoch:98,batch:269]:acc: 0.883681,loss:0.266115\n",
      "[epoch:98,batch:299]:acc: 0.883958,loss:0.265469\n",
      "[epoch:98,batch:299]: val_loss:0.436818,val_acc:0.853712,val_total:4539\n",
      "[epoch:98,batch:329]:acc: 0.885985,loss:0.262550\n",
      "[epoch:98,batch:359]:acc: 0.886632,loss:0.260332\n",
      "[epoch:98,batch:389]:acc: 0.887500,loss:0.259267\n",
      "[epoch:98,batch:419]:acc: 0.887649,loss:0.261195\n",
      "[epoch:98,batch:449]:acc: 0.887153,loss:0.261432\n",
      "[epoch:98,batch:479]:acc: 0.887500,loss:0.261408\n",
      "[epoch:98,batch:509]:acc: 0.886397,loss:0.262353\n",
      "[epoch:98,batch:539]:acc: 0.887153,loss:0.262174\n",
      "[epoch:98,batch:569]:acc: 0.888432,loss:0.260767\n",
      "[epoch:98,batch:599]:acc: 0.888906,loss:0.260140\n",
      "[epoch:98,batch:599]: val_loss:0.438193,val_acc:0.854814,val_total:4539\n",
      "[epoch:98,batch:629]:acc: 0.888641,loss:0.259828\n",
      "[epoch:98,batch:659]:acc: 0.889205,loss:0.259176\n",
      "[epoch:98,batch:689]:acc: 0.889266,loss:0.258212\n",
      "[epoch:98,batch:719]:acc: 0.889670,loss:0.257759\n",
      "[epoch:98,batch:749]:acc: 0.890208,loss:0.256435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:98,batch:779]:acc: 0.889784,loss:0.257248\n",
      "[epoch:98,batch:809]:acc: 0.889583,loss:0.258368\n",
      "[epoch:98,batch:839]:acc: 0.888728,loss:0.260603\n",
      "[epoch:98,batch:869]:acc: 0.888901,loss:0.260593\n",
      "[epoch:98,batch:899]:acc: 0.888507,loss:0.261335\n",
      "[epoch:98,batch:899]: val_loss:0.382269,val_acc:0.853933,val_total:4539\n",
      "[epoch:98,batch:929]:acc: 0.888642,loss:0.261413\n",
      "[epoch:98,batch:959]:acc: 0.888867,loss:0.260676\n",
      "[epoch:98,batch:989]:acc: 0.888920,loss:0.260472\n",
      "[epoch:98] :acc: 0.888987,loss:0.260532,lr:0.000000,patience:2\n",
      "[epoch:98]: val_loss:0.409185,val_acc:0.851950,\n",
      "Epoch 99/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:99,batch:29]:acc: 0.898958,loss:0.245392\n",
      "[epoch:99,batch:59]:acc: 0.888542,loss:0.264249\n",
      "[epoch:99,batch:89]:acc: 0.880556,loss:0.270208\n",
      "[epoch:99,batch:119]:acc: 0.884896,loss:0.265227\n",
      "[epoch:99,batch:149]:acc: 0.885000,loss:0.263240\n",
      "[epoch:99,batch:179]:acc: 0.888368,loss:0.258638\n",
      "[epoch:99,batch:209]:acc: 0.888095,loss:0.258857\n",
      "[epoch:99,batch:239]:acc: 0.887370,loss:0.259964\n",
      "[epoch:99,batch:269]:acc: 0.889352,loss:0.257547\n",
      "[epoch:99,batch:299]:acc: 0.890417,loss:0.257416\n",
      "[epoch:99,batch:299]: val_loss:0.381239,val_acc:0.855254,val_total:4539\n",
      "[epoch:99,batch:329]:acc: 0.889583,loss:0.259454\n",
      "[epoch:99,batch:359]:acc: 0.887500,loss:0.261276\n",
      "[epoch:99,batch:389]:acc: 0.887660,loss:0.260143\n",
      "[epoch:99,batch:419]:acc: 0.887723,loss:0.259588\n",
      "[epoch:99,batch:449]:acc: 0.888125,loss:0.259065\n",
      "[epoch:99,batch:479]:acc: 0.888867,loss:0.258272\n",
      "[epoch:99,batch:509]:acc: 0.888480,loss:0.259841\n",
      "[epoch:99,batch:539]:acc: 0.887731,loss:0.260909\n",
      "[epoch:99,batch:569]:acc: 0.887774,loss:0.261318\n",
      "[epoch:99,batch:599]:acc: 0.888385,loss:0.260260\n",
      "[epoch:99,batch:599]: val_loss:0.444356,val_acc:0.853712,val_total:4539\n",
      "[epoch:99,batch:629]:acc: 0.888839,loss:0.258929\n",
      "[epoch:99,batch:659]:acc: 0.888542,loss:0.260547\n",
      "[epoch:99,batch:689]:acc: 0.888225,loss:0.260837\n",
      "[epoch:99,batch:719]:acc: 0.888542,loss:0.260138\n",
      "[epoch:99,batch:749]:acc: 0.888708,loss:0.259642\n",
      "[epoch:99,batch:779]:acc: 0.888822,loss:0.259627\n",
      "[epoch:99,batch:809]:acc: 0.889082,loss:0.258683\n",
      "[epoch:99,batch:839]:acc: 0.888579,loss:0.259973\n",
      "[epoch:99,batch:869]:acc: 0.888506,loss:0.260091\n",
      "[epoch:99,batch:899]:acc: 0.888542,loss:0.261072\n",
      "[epoch:99,batch:899]: val_loss:0.448601,val_acc:0.853492,val_total:4539\n",
      "[epoch:99,batch:929]:acc: 0.888239,loss:0.261268\n",
      "[epoch:99,batch:959]:acc: 0.888216,loss:0.261340\n",
      "[epoch:99,batch:989]:acc: 0.887973,loss:0.261367\n",
      "[epoch:99] :acc: 0.888010,loss:0.261513,lr:0.000000,patience:0\n",
      "[epoch:99]: val_loss:0.438274,val_acc:0.853712,\n",
      "Epoch 100/119\n",
      "----------\n",
      "[epoch:100,batch:29]:acc: 0.878125,loss:0.293955\n",
      "[epoch:100,batch:59]:acc: 0.880208,loss:0.269370\n",
      "[epoch:100,batch:89]:acc: 0.881250,loss:0.262100\n",
      "[epoch:100,batch:119]:acc: 0.879427,loss:0.265811\n",
      "[epoch:100,batch:149]:acc: 0.879792,loss:0.267989\n",
      "[epoch:100,batch:179]:acc: 0.885069,loss:0.265188\n",
      "[epoch:100,batch:209]:acc: 0.885565,loss:0.265777\n",
      "[epoch:100,batch:239]:acc: 0.887760,loss:0.261518\n",
      "[epoch:100,batch:269]:acc: 0.886111,loss:0.265261\n",
      "[epoch:100,batch:299]:acc: 0.886250,loss:0.263553\n",
      "[epoch:100,batch:299]: val_loss:0.428101,val_acc:0.854373,val_total:4539\n",
      "[epoch:100,batch:329]:acc: 0.887500,loss:0.260684\n",
      "[epoch:100,batch:359]:acc: 0.886545,loss:0.262906\n",
      "[epoch:100,batch:389]:acc: 0.885337,loss:0.264448\n",
      "[epoch:100,batch:419]:acc: 0.884152,loss:0.265561\n",
      "[epoch:100,batch:449]:acc: 0.884028,loss:0.265762\n",
      "[epoch:100,batch:479]:acc: 0.883854,loss:0.265459\n",
      "[epoch:100,batch:509]:acc: 0.883946,loss:0.264867\n",
      "[epoch:100,batch:539]:acc: 0.884549,loss:0.263361\n",
      "[epoch:100,batch:569]:acc: 0.885581,loss:0.262413\n",
      "[epoch:100,batch:599]:acc: 0.885208,loss:0.263295\n",
      "[epoch:100,batch:599]: val_loss:0.406036,val_acc:0.854153,val_total:4539\n",
      "[epoch:100,batch:629]:acc: 0.884772,loss:0.263724\n",
      "[epoch:100,batch:659]:acc: 0.885085,loss:0.262917\n",
      "[epoch:100,batch:689]:acc: 0.885553,loss:0.262060\n",
      "[epoch:100,batch:719]:acc: 0.886502,loss:0.260335\n",
      "[epoch:100,batch:749]:acc: 0.886625,loss:0.260524\n",
      "[epoch:100,batch:779]:acc: 0.886739,loss:0.260809\n",
      "[epoch:100,batch:809]:acc: 0.886844,loss:0.260331\n",
      "[epoch:100,batch:839]:acc: 0.886421,loss:0.261486\n",
      "[epoch:100,batch:869]:acc: 0.886782,loss:0.261263\n",
      "[epoch:100,batch:899]:acc: 0.887153,loss:0.260593\n",
      "[epoch:100,batch:899]: val_loss:0.456397,val_acc:0.853933,val_total:4539\n",
      "[epoch:100,batch:929]:acc: 0.887130,loss:0.260555\n",
      "[epoch:100,batch:959]:acc: 0.887988,loss:0.259829\n",
      "[epoch:100,batch:989]:acc: 0.888510,loss:0.259886\n",
      "[epoch:100] :acc: 0.888514,loss:0.260402,lr:0.000000,patience:1\n",
      "[epoch:100]: val_loss:0.416271,val_acc:0.853272,\n",
      "Epoch 101/119\n",
      "----------\n",
      "[epoch:101,batch:29]:acc: 0.886458,loss:0.255926\n",
      "[epoch:101,batch:59]:acc: 0.883333,loss:0.265974\n",
      "[epoch:101,batch:89]:acc: 0.884028,loss:0.264654\n",
      "[epoch:101,batch:119]:acc: 0.881510,loss:0.271287\n",
      "[epoch:101,batch:149]:acc: 0.879583,loss:0.273396\n",
      "[epoch:101,batch:179]:acc: 0.881076,loss:0.271550\n",
      "[epoch:101,batch:209]:acc: 0.882589,loss:0.269453\n",
      "[epoch:101,batch:239]:acc: 0.884245,loss:0.268367\n",
      "[epoch:101,batch:269]:acc: 0.884144,loss:0.267622\n",
      "[epoch:101,batch:299]:acc: 0.885104,loss:0.267175\n",
      "[epoch:101,batch:299]: val_loss:0.396102,val_acc:0.852831,val_total:4539\n",
      "[epoch:101,batch:329]:acc: 0.887689,loss:0.262947\n",
      "[epoch:101,batch:359]:acc: 0.887674,loss:0.263161\n",
      "[epoch:101,batch:389]:acc: 0.888061,loss:0.263430\n",
      "[epoch:101,batch:419]:acc: 0.888021,loss:0.263876\n",
      "[epoch:101,batch:449]:acc: 0.887778,loss:0.263461\n",
      "[epoch:101,batch:479]:acc: 0.886328,loss:0.266475\n",
      "[epoch:101,batch:509]:acc: 0.886397,loss:0.265905\n",
      "[epoch:101,batch:539]:acc: 0.886516,loss:0.265958\n",
      "[epoch:101,batch:569]:acc: 0.886568,loss:0.264538\n",
      "[epoch:101,batch:599]:acc: 0.886979,loss:0.263403\n",
      "[epoch:101,batch:599]: val_loss:0.369760,val_acc:0.855915,val_total:4539\n",
      "[epoch:101,batch:629]:acc: 0.887202,loss:0.263792\n",
      "[epoch:101,batch:659]:acc: 0.887500,loss:0.262931\n",
      "[epoch:101,batch:689]:acc: 0.888315,loss:0.261819\n",
      "[epoch:101,batch:719]:acc: 0.888542,loss:0.261506\n",
      "[epoch:101,batch:749]:acc: 0.887458,loss:0.263718\n",
      "[epoch:101,batch:779]:acc: 0.887300,loss:0.263293\n",
      "[epoch:101,batch:809]:acc: 0.887770,loss:0.262438\n",
      "[epoch:101,batch:839]:acc: 0.887537,loss:0.262932\n",
      "[epoch:101,batch:869]:acc: 0.887787,loss:0.262354\n",
      "[epoch:101,batch:899]:acc: 0.887569,loss:0.263220\n",
      "[epoch:101,batch:899]: val_loss:0.396145,val_acc:0.857458,val_total:4539\n",
      "[epoch:101,batch:929]:acc: 0.887567,loss:0.262548\n",
      "[epoch:101,batch:959]:acc: 0.887956,loss:0.262154\n",
      "[epoch:101,batch:989]:acc: 0.887784,loss:0.261584\n",
      "[epoch:101] :acc: 0.887694,loss:0.262536,lr:0.000000,patience:2\n",
      "[epoch:101]: val_loss:0.473337,val_acc:0.850628,\n",
      "Epoch 102/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:102,batch:29]:acc: 0.872917,loss:0.267369\n",
      "[epoch:102,batch:59]:acc: 0.886458,loss:0.252777\n",
      "[epoch:102,batch:89]:acc: 0.886458,loss:0.256755\n",
      "[epoch:102,batch:119]:acc: 0.883073,loss:0.262920\n",
      "[epoch:102,batch:149]:acc: 0.887917,loss:0.257587\n",
      "[epoch:102,batch:179]:acc: 0.886979,loss:0.260117\n",
      "[epoch:102,batch:209]:acc: 0.888839,loss:0.257838\n",
      "[epoch:102,batch:239]:acc: 0.889714,loss:0.259566\n",
      "[epoch:102,batch:269]:acc: 0.889699,loss:0.259294\n",
      "[epoch:102,batch:299]:acc: 0.888854,loss:0.260523\n",
      "[epoch:102,batch:299]: val_loss:0.425531,val_acc:0.855034,val_total:4539\n",
      "[epoch:102,batch:329]:acc: 0.887784,loss:0.262102\n",
      "[epoch:102,batch:359]:acc: 0.887674,loss:0.261117\n",
      "[epoch:102,batch:389]:acc: 0.888221,loss:0.260552\n",
      "[epoch:102,batch:419]:acc: 0.888318,loss:0.260548\n",
      "[epoch:102,batch:449]:acc: 0.888125,loss:0.261866\n",
      "[epoch:102,batch:479]:acc: 0.887826,loss:0.261875\n",
      "[epoch:102,batch:509]:acc: 0.887010,loss:0.262419\n",
      "[epoch:102,batch:539]:acc: 0.887153,loss:0.262799\n",
      "[epoch:102,batch:569]:acc: 0.887610,loss:0.261947\n",
      "[epoch:102,batch:599]:acc: 0.887188,loss:0.261982\n",
      "[epoch:102,batch:599]: val_loss:0.389292,val_acc:0.855254,val_total:4539\n",
      "[epoch:102,batch:629]:acc: 0.886806,loss:0.261626\n",
      "[epoch:102,batch:659]:acc: 0.886600,loss:0.262843\n",
      "[epoch:102,batch:689]:acc: 0.887138,loss:0.262067\n",
      "[epoch:102,batch:719]:acc: 0.887760,loss:0.261087\n",
      "[epoch:102,batch:749]:acc: 0.887500,loss:0.261620\n",
      "[epoch:102,batch:779]:acc: 0.887780,loss:0.261541\n",
      "[epoch:102,batch:809]:acc: 0.887076,loss:0.261570\n",
      "[epoch:102,batch:839]:acc: 0.887388,loss:0.260747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:102,batch:869]:acc: 0.887751,loss:0.259762\n",
      "[epoch:102,batch:899]:acc: 0.887604,loss:0.260142\n",
      "[epoch:102,batch:899]: val_loss:0.390662,val_acc:0.855034,val_total:4539\n",
      "[epoch:102,batch:929]:acc: 0.887500,loss:0.260280\n",
      "[epoch:102,batch:959]:acc: 0.887305,loss:0.260422\n",
      "[epoch:102,batch:989]:acc: 0.887184,loss:0.260510\n",
      "[epoch:102] :acc: 0.887032,loss:0.260574,lr:0.000000,patience:0\n",
      "[epoch:102]: val_loss:0.409745,val_acc:0.854594,\n",
      "Epoch 103/119\n",
      "----------\n",
      "[epoch:103,batch:29]:acc: 0.882292,loss:0.281291\n",
      "[epoch:103,batch:59]:acc: 0.886979,loss:0.266821\n",
      "[epoch:103,batch:89]:acc: 0.888194,loss:0.263103\n",
      "[epoch:103,batch:119]:acc: 0.884115,loss:0.263826\n",
      "[epoch:103,batch:149]:acc: 0.885625,loss:0.264998\n",
      "[epoch:103,batch:179]:acc: 0.883507,loss:0.266289\n",
      "[epoch:103,batch:209]:acc: 0.883631,loss:0.269406\n",
      "[epoch:103,batch:239]:acc: 0.886589,loss:0.264070\n",
      "[epoch:103,batch:269]:acc: 0.887384,loss:0.261121\n",
      "[epoch:103,batch:299]:acc: 0.886667,loss:0.260656\n",
      "[epoch:103,batch:299]: val_loss:0.433419,val_acc:0.854373,val_total:4539\n",
      "[epoch:103,batch:329]:acc: 0.886364,loss:0.261669\n",
      "[epoch:103,batch:359]:acc: 0.886372,loss:0.263025\n",
      "[epoch:103,batch:389]:acc: 0.886298,loss:0.263910\n",
      "[epoch:103,batch:419]:acc: 0.887128,loss:0.261937\n",
      "[epoch:103,batch:449]:acc: 0.887500,loss:0.260097\n",
      "[epoch:103,batch:479]:acc: 0.888086,loss:0.259688\n",
      "[epoch:103,batch:509]:acc: 0.888725,loss:0.258776\n",
      "[epoch:103,batch:539]:acc: 0.888542,loss:0.259291\n",
      "[epoch:103,batch:569]:acc: 0.888048,loss:0.260202\n",
      "[epoch:103,batch:599]:acc: 0.888281,loss:0.259484\n",
      "[epoch:103,batch:599]: val_loss:0.427768,val_acc:0.851068,val_total:4539\n",
      "[epoch:103,batch:629]:acc: 0.888294,loss:0.259331\n",
      "[epoch:103,batch:659]:acc: 0.888163,loss:0.259600\n",
      "[epoch:103,batch:689]:acc: 0.888043,loss:0.260210\n",
      "[epoch:103,batch:719]:acc: 0.887804,loss:0.262231\n",
      "[epoch:103,batch:749]:acc: 0.888167,loss:0.261503\n",
      "[epoch:103,batch:779]:acc: 0.887981,loss:0.261250\n",
      "[epoch:103,batch:809]:acc: 0.887924,loss:0.261586\n",
      "[epoch:103,batch:839]:acc: 0.887984,loss:0.261429\n",
      "[epoch:103,batch:869]:acc: 0.888039,loss:0.261638\n",
      "[epoch:103,batch:899]:acc: 0.887500,loss:0.261928\n",
      "[epoch:103,batch:899]: val_loss:0.442271,val_acc:0.852611,val_total:4539\n",
      "[epoch:103,batch:929]:acc: 0.887534,loss:0.261233\n",
      "[epoch:103,batch:959]:acc: 0.887174,loss:0.261837\n",
      "[epoch:103,batch:989]:acc: 0.887184,loss:0.261232\n",
      "[epoch:103] :acc: 0.887221,loss:0.260954,lr:0.000000,patience:1\n",
      "[epoch:103]: val_loss:0.418749,val_acc:0.851729,\n",
      "Epoch 104/119\n",
      "----------\n",
      "[epoch:104,batch:29]:acc: 0.901042,loss:0.227076\n",
      "[epoch:104,batch:59]:acc: 0.902083,loss:0.240206\n",
      "[epoch:104,batch:89]:acc: 0.894792,loss:0.249271\n",
      "[epoch:104,batch:119]:acc: 0.890625,loss:0.250986\n",
      "[epoch:104,batch:149]:acc: 0.888542,loss:0.256564\n",
      "[epoch:104,batch:179]:acc: 0.889410,loss:0.257716\n",
      "[epoch:104,batch:209]:acc: 0.888690,loss:0.257499\n",
      "[epoch:104,batch:239]:acc: 0.889714,loss:0.256119\n",
      "[epoch:104,batch:269]:acc: 0.889236,loss:0.254679\n",
      "[epoch:104,batch:299]:acc: 0.890000,loss:0.255717\n",
      "[epoch:104,batch:299]: val_loss:0.402511,val_acc:0.853933,val_total:4539\n",
      "[epoch:104,batch:329]:acc: 0.891004,loss:0.255842\n",
      "[epoch:104,batch:359]:acc: 0.891753,loss:0.254491\n",
      "[epoch:104,batch:389]:acc: 0.889744,loss:0.256324\n",
      "[epoch:104,batch:419]:acc: 0.888616,loss:0.257531\n",
      "[epoch:104,batch:449]:acc: 0.888542,loss:0.258030\n",
      "[epoch:104,batch:479]:acc: 0.889844,loss:0.255465\n",
      "[epoch:104,batch:509]:acc: 0.889583,loss:0.255641\n",
      "[epoch:104,batch:539]:acc: 0.888889,loss:0.258516\n",
      "[epoch:104,batch:569]:acc: 0.889090,loss:0.258712\n",
      "[epoch:104,batch:599]:acc: 0.890000,loss:0.256537\n",
      "[epoch:104,batch:599]: val_loss:0.374386,val_acc:0.855695,val_total:4539\n",
      "[epoch:104,batch:629]:acc: 0.889732,loss:0.256951\n",
      "[epoch:104,batch:659]:acc: 0.890104,loss:0.256240\n",
      "[epoch:104,batch:689]:acc: 0.890534,loss:0.255364\n",
      "[epoch:104,batch:719]:acc: 0.889627,loss:0.256803\n",
      "[epoch:104,batch:749]:acc: 0.889042,loss:0.259366\n",
      "[epoch:104,batch:779]:acc: 0.889583,loss:0.258837\n",
      "[epoch:104,batch:809]:acc: 0.889352,loss:0.259359\n",
      "[epoch:104,batch:839]:acc: 0.889360,loss:0.259482\n",
      "[epoch:104,batch:869]:acc: 0.889404,loss:0.259458\n",
      "[epoch:104,batch:899]:acc: 0.889444,loss:0.259438\n",
      "[epoch:104,batch:899]: val_loss:0.398203,val_acc:0.854373,val_total:4539\n",
      "[epoch:104,batch:929]:acc: 0.889281,loss:0.259935\n",
      "[epoch:104,batch:959]:acc: 0.888802,loss:0.260275\n",
      "[epoch:104,batch:989]:acc: 0.888510,loss:0.260426\n",
      "[epoch:104] :acc: 0.888419,loss:0.260695,lr:0.000000,patience:2\n",
      "[epoch:104]: val_loss:0.457503,val_acc:0.852831,\n",
      "Epoch 105/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:105,batch:29]:acc: 0.885417,loss:0.248782\n",
      "[epoch:105,batch:59]:acc: 0.888021,loss:0.255077\n",
      "[epoch:105,batch:89]:acc: 0.887500,loss:0.252004\n",
      "[epoch:105,batch:119]:acc: 0.889844,loss:0.246348\n",
      "[epoch:105,batch:149]:acc: 0.889375,loss:0.245499\n",
      "[epoch:105,batch:179]:acc: 0.889583,loss:0.245966\n",
      "[epoch:105,batch:209]:acc: 0.887351,loss:0.252924\n",
      "[epoch:105,batch:239]:acc: 0.887630,loss:0.251978\n",
      "[epoch:105,batch:269]:acc: 0.888079,loss:0.252082\n",
      "[epoch:105,batch:299]:acc: 0.887500,loss:0.253181\n",
      "[epoch:105,batch:299]: val_loss:0.470598,val_acc:0.852831,val_total:4539\n",
      "[epoch:105,batch:329]:acc: 0.888731,loss:0.253843\n",
      "[epoch:105,batch:359]:acc: 0.888976,loss:0.255138\n",
      "[epoch:105,batch:389]:acc: 0.887580,loss:0.256293\n",
      "[epoch:105,batch:419]:acc: 0.888690,loss:0.255789\n",
      "[epoch:105,batch:449]:acc: 0.888403,loss:0.258918\n",
      "[epoch:105,batch:479]:acc: 0.888802,loss:0.258806\n",
      "[epoch:105,batch:509]:acc: 0.888419,loss:0.258449\n",
      "[epoch:105,batch:539]:acc: 0.887847,loss:0.258717\n",
      "[epoch:105,batch:569]:acc: 0.887884,loss:0.258824\n",
      "[epoch:105,batch:599]:acc: 0.886771,loss:0.260854\n",
      "[epoch:105,batch:599]: val_loss:0.435137,val_acc:0.851068,val_total:4539\n",
      "[epoch:105,batch:629]:acc: 0.887748,loss:0.259406\n",
      "[epoch:105,batch:659]:acc: 0.887547,loss:0.259940\n",
      "[epoch:105,batch:689]:acc: 0.887772,loss:0.258991\n",
      "[epoch:105,batch:719]:acc: 0.887804,loss:0.259061\n",
      "[epoch:105,batch:749]:acc: 0.888000,loss:0.259338\n",
      "[epoch:105,batch:779]:acc: 0.888662,loss:0.258121\n",
      "[epoch:105,batch:809]:acc: 0.888580,loss:0.257807\n",
      "[epoch:105,batch:839]:acc: 0.888802,loss:0.257268\n",
      "[epoch:105,batch:869]:acc: 0.888829,loss:0.258362\n",
      "[epoch:105,batch:899]:acc: 0.888576,loss:0.257882\n",
      "[epoch:105,batch:899]: val_loss:0.361141,val_acc:0.855695,val_total:4539\n",
      "[epoch:105,batch:929]:acc: 0.888743,loss:0.258103\n",
      "[epoch:105,batch:959]:acc: 0.888444,loss:0.258366\n",
      "[epoch:105,batch:989]:acc: 0.887658,loss:0.260051\n",
      "[epoch:105] :acc: 0.887505,loss:0.260398,lr:0.000000,patience:0\n",
      "[epoch:105]: val_loss:0.408264,val_acc:0.853272,\n",
      "Epoch 106/119\n",
      "----------\n",
      "[epoch:106,batch:29]:acc: 0.894792,loss:0.246018\n",
      "[epoch:106,batch:59]:acc: 0.895312,loss:0.243673\n",
      "[epoch:106,batch:89]:acc: 0.894097,loss:0.247509\n",
      "[epoch:106,batch:119]:acc: 0.889583,loss:0.256149\n",
      "[epoch:106,batch:149]:acc: 0.891458,loss:0.252195\n",
      "[epoch:106,batch:179]:acc: 0.891146,loss:0.254086\n",
      "[epoch:106,batch:209]:acc: 0.889435,loss:0.254929\n",
      "[epoch:106,batch:239]:acc: 0.889193,loss:0.254161\n",
      "[epoch:106,batch:269]:acc: 0.891319,loss:0.252128\n",
      "[epoch:106,batch:299]:acc: 0.887396,loss:0.257957\n",
      "[epoch:106,batch:299]: val_loss:0.426579,val_acc:0.853933,val_total:4539\n",
      "[epoch:106,batch:329]:acc: 0.887216,loss:0.256303\n",
      "[epoch:106,batch:359]:acc: 0.886458,loss:0.257311\n",
      "[epoch:106,batch:389]:acc: 0.886458,loss:0.259053\n",
      "[epoch:106,batch:419]:acc: 0.886310,loss:0.259562\n",
      "[epoch:106,batch:449]:acc: 0.886250,loss:0.261361\n",
      "[epoch:106,batch:479]:acc: 0.885938,loss:0.262232\n",
      "[epoch:106,batch:509]:acc: 0.886397,loss:0.260690\n",
      "[epoch:106,batch:539]:acc: 0.887442,loss:0.260637\n",
      "[epoch:106,batch:569]:acc: 0.887774,loss:0.260441\n",
      "[epoch:106,batch:599]:acc: 0.888177,loss:0.259982\n",
      "[epoch:106,batch:599]: val_loss:0.397688,val_acc:0.853492,val_total:4539\n",
      "[epoch:106,batch:629]:acc: 0.888641,loss:0.258814\n",
      "[epoch:106,batch:659]:acc: 0.889441,loss:0.257298\n",
      "[epoch:106,batch:689]:acc: 0.889357,loss:0.257661\n",
      "[epoch:106,batch:719]:acc: 0.889540,loss:0.256744\n",
      "[epoch:106,batch:749]:acc: 0.889292,loss:0.257158\n",
      "[epoch:106,batch:779]:acc: 0.889543,loss:0.257268\n",
      "[epoch:106,batch:809]:acc: 0.889429,loss:0.257257\n",
      "[epoch:106,batch:839]:acc: 0.888839,loss:0.257690\n",
      "[epoch:106,batch:869]:acc: 0.888937,loss:0.257971\n",
      "[epoch:106,batch:899]:acc: 0.888368,loss:0.258777\n",
      "[epoch:106,batch:899]: val_loss:0.392977,val_acc:0.854594,val_total:4539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:106,batch:929]:acc: 0.888138,loss:0.259356\n",
      "[epoch:106,batch:959]:acc: 0.887793,loss:0.259399\n",
      "[epoch:106,batch:989]:acc: 0.887563,loss:0.260364\n",
      "[epoch:106] :acc: 0.887474,loss:0.261588,lr:0.000000,patience:1\n",
      "[epoch:106]: val_loss:0.418577,val_acc:0.853051,\n",
      "Epoch 107/119\n",
      "----------\n",
      "[epoch:107,batch:29]:acc: 0.891667,loss:0.269128\n",
      "[epoch:107,batch:59]:acc: 0.886979,loss:0.278767\n",
      "[epoch:107,batch:89]:acc: 0.889583,loss:0.269595\n",
      "[epoch:107,batch:119]:acc: 0.890104,loss:0.266519\n",
      "[epoch:107,batch:149]:acc: 0.888958,loss:0.272147\n",
      "[epoch:107,batch:179]:acc: 0.889062,loss:0.273830\n",
      "[epoch:107,batch:209]:acc: 0.890327,loss:0.269727\n",
      "[epoch:107,batch:239]:acc: 0.890625,loss:0.268965\n",
      "[epoch:107,batch:269]:acc: 0.890625,loss:0.267839\n",
      "[epoch:107,batch:299]:acc: 0.891458,loss:0.265727\n",
      "[epoch:107,batch:299]: val_loss:0.395824,val_acc:0.854814,val_total:4539\n",
      "[epoch:107,batch:329]:acc: 0.891098,loss:0.266454\n",
      "[epoch:107,batch:359]:acc: 0.891233,loss:0.265313\n",
      "[epoch:107,batch:389]:acc: 0.890224,loss:0.265675\n",
      "[epoch:107,batch:419]:acc: 0.889509,loss:0.264882\n",
      "[epoch:107,batch:449]:acc: 0.889792,loss:0.264658\n",
      "[epoch:107,batch:479]:acc: 0.889974,loss:0.263365\n",
      "[epoch:107,batch:509]:acc: 0.889522,loss:0.264113\n",
      "[epoch:107,batch:539]:acc: 0.890625,loss:0.262325\n",
      "[epoch:107,batch:569]:acc: 0.890680,loss:0.262450\n",
      "[epoch:107,batch:599]:acc: 0.890938,loss:0.263081\n",
      "[epoch:107,batch:599]: val_loss:0.442647,val_acc:0.853712,val_total:4539\n",
      "[epoch:107,batch:629]:acc: 0.891419,loss:0.262517\n",
      "[epoch:107,batch:659]:acc: 0.892045,loss:0.261731\n",
      "[epoch:107,batch:689]:acc: 0.892346,loss:0.260820\n",
      "[epoch:107,batch:719]:acc: 0.892231,loss:0.260457\n",
      "[epoch:107,batch:749]:acc: 0.891917,loss:0.260806\n",
      "[epoch:107,batch:779]:acc: 0.891506,loss:0.261037\n",
      "[epoch:107,batch:809]:acc: 0.891281,loss:0.261396\n",
      "[epoch:107,batch:839]:acc: 0.891443,loss:0.260746\n",
      "[epoch:107,batch:869]:acc: 0.890948,loss:0.260885\n",
      "[epoch:107,batch:899]:acc: 0.890660,loss:0.260651\n",
      "[epoch:107,batch:899]: val_loss:0.442433,val_acc:0.852611,val_total:4539\n",
      "[epoch:107,batch:929]:acc: 0.890827,loss:0.260662\n",
      "[epoch:107,batch:959]:acc: 0.890592,loss:0.260360\n",
      "[epoch:107,batch:989]:acc: 0.890436,loss:0.260671\n",
      "[epoch:107] :acc: 0.890406,loss:0.261022,lr:0.000000,patience:2\n",
      "[epoch:107]: val_loss:0.404617,val_acc:0.855034,\n",
      "Epoch 108/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:108,batch:29]:acc: 0.883333,loss:0.273342\n",
      "[epoch:108,batch:59]:acc: 0.883333,loss:0.270914\n",
      "[epoch:108,batch:89]:acc: 0.882986,loss:0.267502\n",
      "[epoch:108,batch:119]:acc: 0.883854,loss:0.267538\n",
      "[epoch:108,batch:149]:acc: 0.883750,loss:0.263193\n",
      "[epoch:108,batch:179]:acc: 0.885417,loss:0.263748\n",
      "[epoch:108,batch:209]:acc: 0.887054,loss:0.262309\n",
      "[epoch:108,batch:239]:acc: 0.886328,loss:0.263238\n",
      "[epoch:108,batch:269]:acc: 0.887269,loss:0.260589\n",
      "[epoch:108,batch:299]:acc: 0.887292,loss:0.260253\n",
      "[epoch:108,batch:299]: val_loss:0.453303,val_acc:0.851509,val_total:4539\n",
      "[epoch:108,batch:329]:acc: 0.888731,loss:0.258715\n",
      "[epoch:108,batch:359]:acc: 0.890278,loss:0.256932\n",
      "[epoch:108,batch:389]:acc: 0.890385,loss:0.256428\n",
      "[epoch:108,batch:419]:acc: 0.890030,loss:0.256232\n",
      "[epoch:108,batch:449]:acc: 0.890278,loss:0.256058\n",
      "[epoch:108,batch:479]:acc: 0.890690,loss:0.254500\n",
      "[epoch:108,batch:509]:acc: 0.890564,loss:0.255270\n",
      "[epoch:108,batch:539]:acc: 0.890451,loss:0.255589\n",
      "[epoch:108,batch:569]:acc: 0.890077,loss:0.255071\n",
      "[epoch:108,batch:599]:acc: 0.890208,loss:0.255878\n",
      "[epoch:108,batch:599]: val_loss:0.392287,val_acc:0.854814,val_total:4539\n",
      "[epoch:108,batch:629]:acc: 0.890079,loss:0.254927\n",
      "[epoch:108,batch:659]:acc: 0.890530,loss:0.254637\n",
      "[epoch:108,batch:689]:acc: 0.890172,loss:0.255532\n",
      "[epoch:108,batch:719]:acc: 0.890191,loss:0.255726\n",
      "[epoch:108,batch:749]:acc: 0.890208,loss:0.255665\n",
      "[epoch:108,batch:779]:acc: 0.890024,loss:0.256653\n",
      "[epoch:108,batch:809]:acc: 0.890123,loss:0.256819\n",
      "[epoch:108,batch:839]:acc: 0.889993,loss:0.257392\n",
      "[epoch:108,batch:869]:acc: 0.890014,loss:0.257754\n",
      "[epoch:108,batch:899]:acc: 0.890000,loss:0.258109\n",
      "[epoch:108,batch:899]: val_loss:0.364469,val_acc:0.854594,val_total:4539\n",
      "[epoch:108,batch:929]:acc: 0.889415,loss:0.259021\n",
      "[epoch:108,batch:959]:acc: 0.889355,loss:0.258828\n",
      "[epoch:108,batch:989]:acc: 0.889047,loss:0.259303\n",
      "[epoch:108] :acc: 0.889113,loss:0.258999,lr:0.000000,patience:0\n",
      "[epoch:108]: val_loss:0.402815,val_acc:0.851509,\n",
      "Epoch 109/119\n",
      "----------\n",
      "[epoch:109,batch:29]:acc: 0.886458,loss:0.251522\n",
      "[epoch:109,batch:59]:acc: 0.889062,loss:0.244452\n",
      "[epoch:109,batch:89]:acc: 0.889583,loss:0.246085\n",
      "[epoch:109,batch:119]:acc: 0.886719,loss:0.255654\n",
      "[epoch:109,batch:149]:acc: 0.887500,loss:0.257488\n",
      "[epoch:109,batch:179]:acc: 0.886458,loss:0.257464\n",
      "[epoch:109,batch:209]:acc: 0.886458,loss:0.260069\n",
      "[epoch:109,batch:239]:acc: 0.887240,loss:0.258868\n",
      "[epoch:109,batch:269]:acc: 0.887269,loss:0.260695\n",
      "[epoch:109,batch:299]:acc: 0.886667,loss:0.263946\n",
      "[epoch:109,batch:299]: val_loss:0.424131,val_acc:0.854814,val_total:4539\n",
      "[epoch:109,batch:329]:acc: 0.887311,loss:0.261615\n",
      "[epoch:109,batch:359]:acc: 0.888976,loss:0.260696\n",
      "[epoch:109,batch:389]:acc: 0.889022,loss:0.259348\n",
      "[epoch:109,batch:419]:acc: 0.888839,loss:0.261759\n",
      "[epoch:109,batch:449]:acc: 0.888750,loss:0.262202\n",
      "[epoch:109,batch:479]:acc: 0.888867,loss:0.262067\n",
      "[epoch:109,batch:509]:acc: 0.888971,loss:0.262617\n",
      "[epoch:109,batch:539]:acc: 0.888889,loss:0.262437\n",
      "[epoch:109,batch:569]:acc: 0.888268,loss:0.263023\n",
      "[epoch:109,batch:599]:acc: 0.888073,loss:0.262367\n",
      "[epoch:109,batch:599]: val_loss:0.390753,val_acc:0.855254,val_total:4539\n",
      "[epoch:109,batch:629]:acc: 0.888690,loss:0.261626\n",
      "[epoch:109,batch:659]:acc: 0.889205,loss:0.261438\n",
      "[epoch:109,batch:689]:acc: 0.889447,loss:0.260862\n",
      "[epoch:109,batch:719]:acc: 0.888932,loss:0.260442\n",
      "[epoch:109,batch:749]:acc: 0.889500,loss:0.259476\n",
      "[epoch:109,batch:779]:acc: 0.889143,loss:0.259916\n",
      "[epoch:109,batch:809]:acc: 0.888696,loss:0.260847\n",
      "[epoch:109,batch:839]:acc: 0.888132,loss:0.261986\n",
      "[epoch:109,batch:869]:acc: 0.888147,loss:0.261757\n",
      "[epoch:109,batch:899]:acc: 0.888646,loss:0.260930\n",
      "[epoch:109,batch:899]: val_loss:0.369740,val_acc:0.854594,val_total:4539\n",
      "[epoch:109,batch:929]:acc: 0.888777,loss:0.260552\n",
      "[epoch:109,batch:959]:acc: 0.888477,loss:0.261025\n",
      "[epoch:109,batch:989]:acc: 0.888447,loss:0.260663\n",
      "[epoch:109] :acc: 0.888451,loss:0.260664,lr:0.000000,patience:1\n",
      "[epoch:109]: val_loss:0.391902,val_acc:0.855695,\n",
      "Epoch 110/119\n",
      "----------\n",
      "[epoch:110,batch:29]:acc: 0.886458,loss:0.268190\n",
      "[epoch:110,batch:59]:acc: 0.885938,loss:0.272405\n",
      "[epoch:110,batch:89]:acc: 0.890278,loss:0.263689\n",
      "[epoch:110,batch:119]:acc: 0.889844,loss:0.263081\n",
      "[epoch:110,batch:149]:acc: 0.890833,loss:0.263303\n",
      "[epoch:110,batch:179]:acc: 0.889236,loss:0.266193\n",
      "[epoch:110,batch:209]:acc: 0.889732,loss:0.262109\n",
      "[epoch:110,batch:239]:acc: 0.888411,loss:0.264743\n",
      "[epoch:110,batch:269]:acc: 0.889468,loss:0.261074\n",
      "[epoch:110,batch:299]:acc: 0.891042,loss:0.258440\n",
      "[epoch:110,batch:299]: val_loss:0.356786,val_acc:0.856797,val_total:4539\n",
      "[epoch:110,batch:329]:acc: 0.891951,loss:0.257920\n",
      "[epoch:110,batch:359]:acc: 0.892882,loss:0.257023\n",
      "[epoch:110,batch:389]:acc: 0.893269,loss:0.255230\n",
      "[epoch:110,batch:419]:acc: 0.892932,loss:0.255078\n",
      "[epoch:110,batch:449]:acc: 0.891528,loss:0.259167\n",
      "[epoch:110,batch:479]:acc: 0.891862,loss:0.258164\n",
      "[epoch:110,batch:509]:acc: 0.890502,loss:0.258056\n",
      "[epoch:110,batch:539]:acc: 0.889699,loss:0.259625\n",
      "[epoch:110,batch:569]:acc: 0.888706,loss:0.260512\n",
      "[epoch:110,batch:599]:acc: 0.888333,loss:0.261234\n",
      "[epoch:110,batch:599]: val_loss:0.444041,val_acc:0.852170,val_total:4539\n",
      "[epoch:110,batch:629]:acc: 0.888343,loss:0.260831\n",
      "[epoch:110,batch:659]:acc: 0.888873,loss:0.259861\n",
      "[epoch:110,batch:689]:acc: 0.889266,loss:0.258925\n",
      "[epoch:110,batch:719]:acc: 0.888759,loss:0.259611\n",
      "[epoch:110,batch:749]:acc: 0.887375,loss:0.262844\n",
      "[epoch:110,batch:779]:acc: 0.887220,loss:0.263562\n",
      "[epoch:110,batch:809]:acc: 0.887616,loss:0.262563\n",
      "[epoch:110,batch:839]:acc: 0.887612,loss:0.262782\n",
      "[epoch:110,batch:869]:acc: 0.888075,loss:0.261755\n",
      "[epoch:110,batch:899]:acc: 0.888194,loss:0.261079\n",
      "[epoch:110,batch:899]: val_loss:0.447265,val_acc:0.853712,val_total:4539\n",
      "[epoch:110,batch:929]:acc: 0.888407,loss:0.261317\n",
      "[epoch:110,batch:959]:acc: 0.888086,loss:0.261413\n",
      "[epoch:110,batch:989]:acc: 0.887816,loss:0.261952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:110] :acc: 0.887820,loss:0.262268,lr:0.000000,patience:2\n",
      "[epoch:110]: val_loss:0.464799,val_acc:0.849967,\n",
      "Epoch 111/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:111,batch:29]:acc: 0.883333,loss:0.257457\n",
      "[epoch:111,batch:59]:acc: 0.886458,loss:0.258588\n",
      "[epoch:111,batch:89]:acc: 0.889583,loss:0.254153\n",
      "[epoch:111,batch:119]:acc: 0.893490,loss:0.252008\n",
      "[epoch:111,batch:149]:acc: 0.889375,loss:0.263131\n",
      "[epoch:111,batch:179]:acc: 0.888889,loss:0.262898\n",
      "[epoch:111,batch:209]:acc: 0.890030,loss:0.261092\n",
      "[epoch:111,batch:239]:acc: 0.889193,loss:0.261049\n",
      "[epoch:111,batch:269]:acc: 0.891435,loss:0.256767\n",
      "[epoch:111,batch:299]:acc: 0.890521,loss:0.259030\n",
      "[epoch:111,batch:299]: val_loss:0.370693,val_acc:0.853933,val_total:4539\n",
      "[epoch:111,batch:329]:acc: 0.889299,loss:0.261123\n",
      "[epoch:111,batch:359]:acc: 0.889323,loss:0.260397\n",
      "[epoch:111,batch:389]:acc: 0.889744,loss:0.258567\n",
      "[epoch:111,batch:419]:acc: 0.889137,loss:0.260970\n",
      "[epoch:111,batch:449]:acc: 0.889653,loss:0.259396\n",
      "[epoch:111,batch:479]:acc: 0.890365,loss:0.259136\n",
      "[epoch:111,batch:509]:acc: 0.890686,loss:0.257537\n",
      "[epoch:111,batch:539]:acc: 0.891146,loss:0.256310\n",
      "[epoch:111,batch:569]:acc: 0.890461,loss:0.257925\n",
      "[epoch:111,batch:599]:acc: 0.890625,loss:0.257070\n",
      "[epoch:111,batch:599]: val_loss:0.387060,val_acc:0.855034,val_total:4539\n",
      "[epoch:111,batch:629]:acc: 0.891121,loss:0.255780\n",
      "[epoch:111,batch:659]:acc: 0.890814,loss:0.255144\n",
      "[epoch:111,batch:689]:acc: 0.890127,loss:0.255926\n",
      "[epoch:111,batch:719]:acc: 0.890017,loss:0.256854\n",
      "[epoch:111,batch:749]:acc: 0.890417,loss:0.256121\n",
      "[epoch:111,batch:779]:acc: 0.889543,loss:0.258137\n",
      "[epoch:111,batch:809]:acc: 0.888735,loss:0.258651\n",
      "[epoch:111,batch:839]:acc: 0.888504,loss:0.259714\n",
      "[epoch:111,batch:869]:acc: 0.888470,loss:0.259848\n",
      "[epoch:111,batch:899]:acc: 0.888611,loss:0.260343\n",
      "[epoch:111,batch:899]: val_loss:0.378652,val_acc:0.855695,val_total:4539\n",
      "[epoch:111,batch:929]:acc: 0.888374,loss:0.260722\n",
      "[epoch:111,batch:959]:acc: 0.888477,loss:0.260255\n",
      "[epoch:111,batch:989]:acc: 0.888542,loss:0.260141\n",
      "[epoch:111] :acc: 0.888577,loss:0.259883,lr:0.000000,patience:0\n",
      "[epoch:111]: val_loss:0.398007,val_acc:0.853051,\n",
      "Epoch 112/119\n",
      "----------\n",
      "[epoch:112,batch:29]:acc: 0.872917,loss:0.297909\n",
      "[epoch:112,batch:59]:acc: 0.879167,loss:0.279679\n",
      "[epoch:112,batch:89]:acc: 0.887500,loss:0.259508\n",
      "[epoch:112,batch:119]:acc: 0.888281,loss:0.261139\n",
      "[epoch:112,batch:149]:acc: 0.890417,loss:0.258716\n",
      "[epoch:112,batch:179]:acc: 0.892188,loss:0.253323\n",
      "[epoch:112,batch:209]:acc: 0.892857,loss:0.252622\n",
      "[epoch:112,batch:239]:acc: 0.891536,loss:0.254054\n",
      "[epoch:112,batch:269]:acc: 0.891088,loss:0.252502\n",
      "[epoch:112,batch:299]:acc: 0.890208,loss:0.255478\n",
      "[epoch:112,batch:299]: val_loss:0.383178,val_acc:0.856356,val_total:4539\n",
      "[epoch:112,batch:329]:acc: 0.887879,loss:0.258931\n",
      "[epoch:112,batch:359]:acc: 0.887326,loss:0.259275\n",
      "[epoch:112,batch:389]:acc: 0.886779,loss:0.262164\n",
      "[epoch:112,batch:419]:acc: 0.886756,loss:0.262445\n",
      "[epoch:112,batch:449]:acc: 0.886736,loss:0.261721\n",
      "[epoch:112,batch:479]:acc: 0.886068,loss:0.263377\n",
      "[epoch:112,batch:509]:acc: 0.886887,loss:0.261806\n",
      "[epoch:112,batch:539]:acc: 0.886111,loss:0.263144\n",
      "[epoch:112,batch:569]:acc: 0.886184,loss:0.262983\n",
      "[epoch:112,batch:599]:acc: 0.886823,loss:0.262098\n",
      "[epoch:112,batch:599]: val_loss:0.380584,val_acc:0.853933,val_total:4539\n",
      "[epoch:112,batch:629]:acc: 0.887450,loss:0.260593\n",
      "[epoch:112,batch:659]:acc: 0.887737,loss:0.260079\n",
      "[epoch:112,batch:689]:acc: 0.887636,loss:0.261090\n",
      "[epoch:112,batch:719]:acc: 0.888064,loss:0.261144\n",
      "[epoch:112,batch:749]:acc: 0.888292,loss:0.260571\n",
      "[epoch:112,batch:779]:acc: 0.888101,loss:0.260706\n",
      "[epoch:112,batch:809]:acc: 0.887693,loss:0.261037\n",
      "[epoch:112,batch:839]:acc: 0.888281,loss:0.260488\n",
      "[epoch:112,batch:869]:acc: 0.888434,loss:0.260748\n",
      "[epoch:112,batch:899]:acc: 0.888715,loss:0.260198\n",
      "[epoch:112,batch:899]: val_loss:0.410165,val_acc:0.853933,val_total:4539\n",
      "[epoch:112,batch:929]:acc: 0.888508,loss:0.260237\n",
      "[epoch:112,batch:959]:acc: 0.888477,loss:0.261253\n",
      "[epoch:112,batch:989]:acc: 0.888573,loss:0.261820\n",
      "[epoch:112] :acc: 0.888577,loss:0.261855,lr:0.000000,patience:1\n",
      "[epoch:112]: val_loss:0.453839,val_acc:0.849086,\n",
      "Epoch 113/119\n",
      "----------\n",
      "[epoch:113,batch:29]:acc: 0.895833,loss:0.253416\n",
      "[epoch:113,batch:59]:acc: 0.891146,loss:0.264076\n",
      "[epoch:113,batch:89]:acc: 0.890972,loss:0.262555\n",
      "[epoch:113,batch:119]:acc: 0.891927,loss:0.262219\n",
      "[epoch:113,batch:149]:acc: 0.892917,loss:0.258613\n",
      "[epoch:113,batch:179]:acc: 0.888021,loss:0.265560\n",
      "[epoch:113,batch:209]:acc: 0.884970,loss:0.268450\n",
      "[epoch:113,batch:239]:acc: 0.886589,loss:0.263950\n",
      "[epoch:113,batch:269]:acc: 0.886574,loss:0.263492\n",
      "[epoch:113,batch:299]:acc: 0.887396,loss:0.262892\n",
      "[epoch:113,batch:299]: val_loss:0.398402,val_acc:0.853933,val_total:4539\n",
      "[epoch:113,batch:329]:acc: 0.888731,loss:0.262384\n",
      "[epoch:113,batch:359]:acc: 0.887847,loss:0.263346\n",
      "[epoch:113,batch:389]:acc: 0.888462,loss:0.261828\n",
      "[epoch:113,batch:419]:acc: 0.888021,loss:0.263178\n",
      "[epoch:113,batch:449]:acc: 0.887847,loss:0.263429\n",
      "[epoch:113,batch:479]:acc: 0.887174,loss:0.265443\n",
      "[epoch:113,batch:509]:acc: 0.887806,loss:0.264329\n",
      "[epoch:113,batch:539]:acc: 0.888252,loss:0.263824\n",
      "[epoch:113,batch:569]:acc: 0.888871,loss:0.263026\n",
      "[epoch:113,batch:599]:acc: 0.889583,loss:0.262220\n",
      "[epoch:113,batch:599]: val_loss:0.371276,val_acc:0.856576,val_total:4539\n",
      "[epoch:113,batch:629]:acc: 0.889931,loss:0.261056\n",
      "[epoch:113,batch:659]:acc: 0.889867,loss:0.260948\n",
      "[epoch:113,batch:689]:acc: 0.889810,loss:0.261038\n",
      "[epoch:113,batch:719]:acc: 0.889366,loss:0.262748\n",
      "[epoch:113,batch:749]:acc: 0.888958,loss:0.263383\n",
      "[epoch:113,batch:779]:acc: 0.888942,loss:0.262729\n",
      "[epoch:113,batch:809]:acc: 0.889043,loss:0.262103\n",
      "[epoch:113,batch:839]:acc: 0.888802,loss:0.262671\n",
      "[epoch:113,batch:869]:acc: 0.888721,loss:0.261966\n",
      "[epoch:113,batch:899]:acc: 0.888785,loss:0.261261\n",
      "[epoch:113,batch:899]: val_loss:0.371996,val_acc:0.855915,val_total:4539\n",
      "[epoch:113,batch:929]:acc: 0.888911,loss:0.261077\n",
      "[epoch:113,batch:959]:acc: 0.888932,loss:0.260719\n",
      "[epoch:113,batch:989]:acc: 0.888510,loss:0.260999\n",
      "[epoch:113] :acc: 0.888388,loss:0.261471,lr:0.000000,patience:2\n",
      "[epoch:113]: val_loss:0.453974,val_acc:0.854153,\n",
      "Epoch 114/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:114,batch:29]:acc: 0.878125,loss:0.265308\n",
      "[epoch:114,batch:59]:acc: 0.883333,loss:0.275023\n",
      "[epoch:114,batch:89]:acc: 0.887847,loss:0.267869\n",
      "[epoch:114,batch:119]:acc: 0.888021,loss:0.273494\n",
      "[epoch:114,batch:149]:acc: 0.887500,loss:0.274632\n",
      "[epoch:114,batch:179]:acc: 0.887674,loss:0.268162\n",
      "[epoch:114,batch:209]:acc: 0.887649,loss:0.266354\n",
      "[epoch:114,batch:239]:acc: 0.888151,loss:0.265075\n",
      "[epoch:114,batch:269]:acc: 0.889005,loss:0.264839\n",
      "[epoch:114,batch:299]:acc: 0.888125,loss:0.264813\n",
      "[epoch:114,batch:299]: val_loss:0.386852,val_acc:0.854373,val_total:4539\n",
      "[epoch:114,batch:329]:acc: 0.888826,loss:0.263535\n",
      "[epoch:114,batch:359]:acc: 0.889323,loss:0.262471\n",
      "[epoch:114,batch:389]:acc: 0.888381,loss:0.262479\n",
      "[epoch:114,batch:419]:acc: 0.889360,loss:0.262302\n",
      "[epoch:114,batch:449]:acc: 0.888194,loss:0.263608\n",
      "[epoch:114,batch:479]:acc: 0.886589,loss:0.265531\n",
      "[epoch:114,batch:509]:acc: 0.885539,loss:0.266540\n",
      "[epoch:114,batch:539]:acc: 0.885417,loss:0.266534\n",
      "[epoch:114,batch:569]:acc: 0.885581,loss:0.267048\n",
      "[epoch:114,batch:599]:acc: 0.886406,loss:0.267114\n",
      "[epoch:114,batch:599]: val_loss:0.417417,val_acc:0.854594,val_total:4539\n",
      "[epoch:114,batch:629]:acc: 0.886607,loss:0.265827\n",
      "[epoch:114,batch:659]:acc: 0.886884,loss:0.265874\n",
      "[epoch:114,batch:689]:acc: 0.887953,loss:0.263911\n",
      "[epoch:114,batch:719]:acc: 0.887630,loss:0.264121\n",
      "[epoch:114,batch:749]:acc: 0.887417,loss:0.264157\n",
      "[epoch:114,batch:779]:acc: 0.887620,loss:0.263532\n",
      "[epoch:114,batch:809]:acc: 0.887963,loss:0.262466\n",
      "[epoch:114,batch:839]:acc: 0.887946,loss:0.263548\n",
      "[epoch:114,batch:869]:acc: 0.887931,loss:0.263851\n",
      "[epoch:114,batch:899]:acc: 0.888229,loss:0.263288\n",
      "[epoch:114,batch:899]: val_loss:0.381493,val_acc:0.852831,val_total:4539\n",
      "[epoch:114,batch:929]:acc: 0.888138,loss:0.262778\n",
      "[epoch:114,batch:959]:acc: 0.888835,loss:0.261662\n",
      "[epoch:114,batch:989]:acc: 0.888857,loss:0.261087\n",
      "[epoch:114] :acc: 0.888861,loss:0.261210,lr:0.000000,patience:0\n",
      "[epoch:114]: val_loss:0.422266,val_acc:0.853933,\n",
      "Epoch 115/119\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:115,batch:29]:acc: 0.906250,loss:0.241701\n",
      "[epoch:115,batch:59]:acc: 0.902604,loss:0.237186\n",
      "[epoch:115,batch:89]:acc: 0.889583,loss:0.256565\n",
      "[epoch:115,batch:119]:acc: 0.882031,loss:0.267559\n",
      "[epoch:115,batch:149]:acc: 0.882917,loss:0.271262\n",
      "[epoch:115,batch:179]:acc: 0.883333,loss:0.272726\n",
      "[epoch:115,batch:209]:acc: 0.884673,loss:0.269369\n",
      "[epoch:115,batch:239]:acc: 0.885286,loss:0.269059\n",
      "[epoch:115,batch:269]:acc: 0.885185,loss:0.268083\n",
      "[epoch:115,batch:299]:acc: 0.885938,loss:0.267469\n",
      "[epoch:115,batch:299]: val_loss:0.384222,val_acc:0.854814,val_total:4539\n",
      "[epoch:115,batch:329]:acc: 0.886932,loss:0.265883\n",
      "[epoch:115,batch:359]:acc: 0.886372,loss:0.267627\n",
      "[epoch:115,batch:389]:acc: 0.885256,loss:0.269389\n",
      "[epoch:115,batch:419]:acc: 0.884970,loss:0.268367\n",
      "[epoch:115,batch:449]:acc: 0.884028,loss:0.268788\n",
      "[epoch:115,batch:479]:acc: 0.884440,loss:0.267237\n",
      "[epoch:115,batch:509]:acc: 0.884681,loss:0.267359\n",
      "[epoch:115,batch:539]:acc: 0.884259,loss:0.268647\n",
      "[epoch:115,batch:569]:acc: 0.885197,loss:0.266955\n",
      "[epoch:115,batch:599]:acc: 0.885260,loss:0.266082\n",
      "[epoch:115,batch:599]: val_loss:0.398191,val_acc:0.856797,val_total:4539\n",
      "[epoch:115,batch:629]:acc: 0.885813,loss:0.264961\n",
      "[epoch:115,batch:659]:acc: 0.886742,loss:0.263624\n",
      "[epoch:115,batch:689]:acc: 0.886730,loss:0.263823\n",
      "[epoch:115,batch:719]:acc: 0.887196,loss:0.263101\n",
      "[epoch:115,batch:749]:acc: 0.887917,loss:0.262106\n",
      "[epoch:115,batch:779]:acc: 0.887941,loss:0.261954\n",
      "[epoch:115,batch:809]:acc: 0.888040,loss:0.261203\n",
      "[epoch:115,batch:839]:acc: 0.888281,loss:0.260854\n",
      "[epoch:115,batch:869]:acc: 0.888362,loss:0.260516\n",
      "[epoch:115,batch:899]:acc: 0.888750,loss:0.259605\n",
      "[epoch:115,batch:899]: val_loss:0.439637,val_acc:0.855695,val_total:4539\n",
      "[epoch:115,batch:929]:acc: 0.888743,loss:0.259628\n",
      "[epoch:115,batch:959]:acc: 0.888346,loss:0.260015\n",
      "[epoch:115,batch:989]:acc: 0.888889,loss:0.259915\n",
      "[epoch:115] :acc: 0.888861,loss:0.259962,lr:0.000000,patience:1\n",
      "[epoch:115]: val_loss:0.419369,val_acc:0.855254,\n",
      "Epoch 116/119\n",
      "----------\n",
      "[epoch:116,batch:29]:acc: 0.891667,loss:0.247736\n",
      "[epoch:116,batch:59]:acc: 0.895833,loss:0.249555\n",
      "[epoch:116,batch:89]:acc: 0.892014,loss:0.255393\n",
      "[epoch:116,batch:119]:acc: 0.890365,loss:0.256925\n",
      "[epoch:116,batch:149]:acc: 0.892500,loss:0.253918\n",
      "[epoch:116,batch:179]:acc: 0.892014,loss:0.254186\n",
      "[epoch:116,batch:209]:acc: 0.891220,loss:0.257162\n",
      "[epoch:116,batch:239]:acc: 0.890495,loss:0.259476\n",
      "[epoch:116,batch:269]:acc: 0.889583,loss:0.262525\n",
      "[epoch:116,batch:299]:acc: 0.888125,loss:0.265197\n",
      "[epoch:116,batch:299]: val_loss:0.418124,val_acc:0.855915,val_total:4539\n",
      "[epoch:116,batch:329]:acc: 0.889489,loss:0.263051\n",
      "[epoch:116,batch:359]:acc: 0.889062,loss:0.262535\n",
      "[epoch:116,batch:389]:acc: 0.889103,loss:0.262309\n",
      "[epoch:116,batch:419]:acc: 0.889211,loss:0.262508\n",
      "[epoch:116,batch:449]:acc: 0.889375,loss:0.261088\n",
      "[epoch:116,batch:479]:acc: 0.889453,loss:0.259612\n",
      "[epoch:116,batch:509]:acc: 0.889583,loss:0.258811\n",
      "[epoch:116,batch:539]:acc: 0.889120,loss:0.260477\n",
      "[epoch:116,batch:569]:acc: 0.888980,loss:0.261772\n",
      "[epoch:116,batch:599]:acc: 0.888437,loss:0.262815\n",
      "[epoch:116,batch:599]: val_loss:0.376784,val_acc:0.855254,val_total:4539\n",
      "[epoch:116,batch:629]:acc: 0.888591,loss:0.262968\n",
      "[epoch:116,batch:659]:acc: 0.887784,loss:0.262754\n",
      "[epoch:116,batch:689]:acc: 0.887591,loss:0.262343\n",
      "[epoch:116,batch:719]:acc: 0.887500,loss:0.261743\n",
      "[epoch:116,batch:749]:acc: 0.887625,loss:0.261627\n",
      "[epoch:116,batch:779]:acc: 0.887901,loss:0.261065\n",
      "[epoch:116,batch:809]:acc: 0.887809,loss:0.261699\n",
      "[epoch:116,batch:839]:acc: 0.887835,loss:0.262458\n",
      "[epoch:116,batch:869]:acc: 0.887967,loss:0.262076\n",
      "[epoch:116,batch:899]:acc: 0.887743,loss:0.262452\n",
      "[epoch:116,batch:899]: val_loss:0.400963,val_acc:0.853051,val_total:4539\n",
      "[epoch:116,batch:929]:acc: 0.887265,loss:0.262424\n",
      "[epoch:116,batch:959]:acc: 0.886979,loss:0.263000\n",
      "[epoch:116,batch:989]:acc: 0.887216,loss:0.262193\n",
      "[epoch:116] :acc: 0.887284,loss:0.262156,lr:0.000000,patience:2\n",
      "[epoch:116]: val_loss:0.425773,val_acc:0.852170,\n",
      "Epoch 117/119\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:117,batch:29]:acc: 0.896875,loss:0.260439\n",
      "[epoch:117,batch:59]:acc: 0.894792,loss:0.262758\n",
      "[epoch:117,batch:89]:acc: 0.895833,loss:0.254250\n",
      "[epoch:117,batch:119]:acc: 0.895052,loss:0.253505\n",
      "[epoch:117,batch:149]:acc: 0.893333,loss:0.253762\n",
      "[epoch:117,batch:179]:acc: 0.890799,loss:0.258902\n",
      "[epoch:117,batch:209]:acc: 0.891071,loss:0.260063\n",
      "[epoch:117,batch:239]:acc: 0.891667,loss:0.258327\n",
      "[epoch:117,batch:269]:acc: 0.891667,loss:0.257639\n",
      "[epoch:117,batch:299]:acc: 0.894167,loss:0.252900\n",
      "[epoch:117,batch:299]: val_loss:0.368510,val_acc:0.852170,val_total:4539\n",
      "[epoch:117,batch:329]:acc: 0.893561,loss:0.252256\n",
      "[epoch:117,batch:359]:acc: 0.891233,loss:0.256496\n",
      "[epoch:117,batch:389]:acc: 0.892067,loss:0.255611\n",
      "[epoch:117,batch:419]:acc: 0.891071,loss:0.257211\n",
      "[epoch:117,batch:449]:acc: 0.890764,loss:0.258495\n",
      "[epoch:117,batch:479]:acc: 0.891211,loss:0.258055\n",
      "[epoch:117,batch:509]:acc: 0.891789,loss:0.257666\n",
      "[epoch:117,batch:539]:acc: 0.891898,loss:0.256921\n",
      "[epoch:117,batch:569]:acc: 0.891612,loss:0.256920\n",
      "[epoch:117,batch:599]:acc: 0.891354,loss:0.256393\n",
      "[epoch:117,batch:599]: val_loss:0.492524,val_acc:0.854814,val_total:4539\n",
      "[epoch:117,batch:629]:acc: 0.890873,loss:0.257211\n",
      "[epoch:117,batch:659]:acc: 0.890672,loss:0.257348\n",
      "[epoch:117,batch:689]:acc: 0.890580,loss:0.256936\n",
      "[epoch:117,batch:719]:acc: 0.889974,loss:0.257683\n",
      "[epoch:117,batch:749]:acc: 0.889792,loss:0.258252\n",
      "[epoch:117,batch:779]:acc: 0.888582,loss:0.260194\n",
      "[epoch:117,batch:809]:acc: 0.888580,loss:0.259746\n",
      "[epoch:117,batch:839]:acc: 0.888728,loss:0.259611\n",
      "[epoch:117,batch:869]:acc: 0.888290,loss:0.260657\n",
      "[epoch:117,batch:899]:acc: 0.888229,loss:0.261425\n",
      "[epoch:117,batch:899]: val_loss:0.385469,val_acc:0.853712,val_total:4539\n",
      "[epoch:117,batch:929]:acc: 0.888172,loss:0.261556\n",
      "[epoch:117,batch:959]:acc: 0.888281,loss:0.261100\n",
      "[epoch:117,batch:989]:acc: 0.888163,loss:0.261637\n",
      "[epoch:117] :acc: 0.888167,loss:0.261393,lr:0.000000,patience:0\n",
      "[epoch:117]: val_loss:0.388106,val_acc:0.853492,\n",
      "Epoch 118/119\n",
      "----------\n",
      "[epoch:118,batch:29]:acc: 0.877083,loss:0.263336\n",
      "[epoch:118,batch:59]:acc: 0.874479,loss:0.268980\n",
      "[epoch:118,batch:89]:acc: 0.886111,loss:0.258146\n",
      "[epoch:118,batch:119]:acc: 0.885677,loss:0.266490\n",
      "[epoch:118,batch:149]:acc: 0.888125,loss:0.261024\n",
      "[epoch:118,batch:179]:acc: 0.888889,loss:0.260076\n",
      "[epoch:118,batch:209]:acc: 0.886756,loss:0.262846\n",
      "[epoch:118,batch:239]:acc: 0.885547,loss:0.265623\n",
      "[epoch:118,batch:269]:acc: 0.886690,loss:0.262375\n",
      "[epoch:118,batch:299]:acc: 0.885833,loss:0.263893\n",
      "[epoch:118,batch:299]: val_loss:0.405088,val_acc:0.855034,val_total:4539\n",
      "[epoch:118,batch:329]:acc: 0.885795,loss:0.263803\n",
      "[epoch:118,batch:359]:acc: 0.886458,loss:0.261598\n",
      "[epoch:118,batch:389]:acc: 0.887340,loss:0.260522\n",
      "[epoch:118,batch:419]:acc: 0.887649,loss:0.259855\n",
      "[epoch:118,batch:449]:acc: 0.888542,loss:0.258555\n",
      "[epoch:118,batch:479]:acc: 0.886914,loss:0.260014\n",
      "[epoch:118,batch:509]:acc: 0.887255,loss:0.260155\n",
      "[epoch:118,batch:539]:acc: 0.886806,loss:0.261204\n",
      "[epoch:118,batch:569]:acc: 0.886732,loss:0.261064\n",
      "[epoch:118,batch:599]:acc: 0.887240,loss:0.260532\n",
      "[epoch:118,batch:599]: val_loss:0.406640,val_acc:0.855915,val_total:4539\n",
      "[epoch:118,batch:629]:acc: 0.887054,loss:0.261713\n",
      "[epoch:118,batch:659]:acc: 0.888116,loss:0.260188\n",
      "[epoch:118,batch:689]:acc: 0.888406,loss:0.260083\n",
      "[epoch:118,batch:719]:acc: 0.888368,loss:0.260501\n",
      "[epoch:118,batch:749]:acc: 0.888542,loss:0.260597\n",
      "[epoch:118,batch:779]:acc: 0.888862,loss:0.260065\n",
      "[epoch:118,batch:809]:acc: 0.888735,loss:0.259771\n",
      "[epoch:118,batch:839]:acc: 0.888951,loss:0.259325\n",
      "[epoch:118,batch:869]:acc: 0.889296,loss:0.258761\n",
      "[epoch:118,batch:899]:acc: 0.889167,loss:0.259205\n",
      "[epoch:118,batch:899]: val_loss:0.421788,val_acc:0.853272,val_total:4539\n",
      "[epoch:118,batch:929]:acc: 0.888508,loss:0.259895\n",
      "[epoch:118,batch:959]:acc: 0.888770,loss:0.259471\n",
      "[epoch:118,batch:989]:acc: 0.888826,loss:0.259544\n",
      "[epoch:118] :acc: 0.888829,loss:0.259475,lr:0.000000,patience:1\n",
      "[epoch:118]: val_loss:0.438209,val_acc:0.852390,\n",
      "Epoch 119/119\n",
      "----------\n",
      "[epoch:119,batch:29]:acc: 0.889583,loss:0.253428\n",
      "[epoch:119,batch:59]:acc: 0.889583,loss:0.262357\n",
      "[epoch:119,batch:89]:acc: 0.885417,loss:0.259870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:119,batch:119]:acc: 0.888281,loss:0.258984\n",
      "[epoch:119,batch:149]:acc: 0.891250,loss:0.256048\n",
      "[epoch:119,batch:179]:acc: 0.888715,loss:0.260054\n",
      "[epoch:119,batch:209]:acc: 0.886905,loss:0.261515\n",
      "[epoch:119,batch:239]:acc: 0.887240,loss:0.260043\n",
      "[epoch:119,batch:269]:acc: 0.886574,loss:0.260045\n",
      "[epoch:119,batch:299]:acc: 0.886667,loss:0.259486\n",
      "[epoch:119,batch:299]: val_loss:0.411343,val_acc:0.853492,val_total:4539\n",
      "[epoch:119,batch:329]:acc: 0.886932,loss:0.257248\n",
      "[epoch:119,batch:359]:acc: 0.886545,loss:0.257834\n",
      "[epoch:119,batch:389]:acc: 0.886779,loss:0.256451\n",
      "[epoch:119,batch:419]:acc: 0.888393,loss:0.253207\n",
      "[epoch:119,batch:449]:acc: 0.888056,loss:0.253502\n",
      "[epoch:119,batch:479]:acc: 0.887565,loss:0.254426\n",
      "[epoch:119,batch:509]:acc: 0.888235,loss:0.254163\n",
      "[epoch:119,batch:539]:acc: 0.888079,loss:0.254213\n",
      "[epoch:119,batch:569]:acc: 0.887993,loss:0.253975\n",
      "[epoch:119,batch:599]:acc: 0.888542,loss:0.253874\n",
      "[epoch:119,batch:599]: val_loss:0.409454,val_acc:0.852611,val_total:4539\n",
      "[epoch:119,batch:629]:acc: 0.888294,loss:0.255289\n",
      "[epoch:119,batch:659]:acc: 0.888210,loss:0.255522\n",
      "[epoch:119,batch:689]:acc: 0.887455,loss:0.257526\n",
      "[epoch:119,batch:719]:acc: 0.887066,loss:0.260038\n",
      "[epoch:119,batch:749]:acc: 0.887333,loss:0.259637\n",
      "[epoch:119,batch:779]:acc: 0.887420,loss:0.259405\n",
      "[epoch:119,batch:809]:acc: 0.887346,loss:0.259432\n",
      "[epoch:119,batch:839]:acc: 0.887426,loss:0.259582\n",
      "[epoch:119,batch:869]:acc: 0.887177,loss:0.260352\n",
      "[epoch:119,batch:899]:acc: 0.887604,loss:0.259120\n",
      "[epoch:119,batch:899]: val_loss:0.402013,val_acc:0.854373,val_total:4539\n",
      "[epoch:119,batch:929]:acc: 0.887634,loss:0.258925\n",
      "[epoch:119,batch:959]:acc: 0.887207,loss:0.260620\n",
      "[epoch:119,batch:989]:acc: 0.887721,loss:0.259978\n",
      "[epoch:119] :acc: 0.887694,loss:0.259820,lr:0.000000,patience:2\n",
      "[epoch:119]: val_loss:0.490092,val_acc:0.849967,\n"
     ]
    }
   ],
   "source": [
    "TrainWithRawData('../model/ResNet50/2018-11-09_loss_best.pth',120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model... Done\n"
     ]
    }
   ],
   "source": [
    "model=getmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetFinetune(\n",
       "  (net): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=59, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1199]],\n",
       "\n",
       "         [[-0.0907]],\n",
       "\n",
       "         [[ 0.0677]],\n",
       "\n",
       "         [[ 0.0502]],\n",
       "\n",
       "         [[-0.1503]],\n",
       "\n",
       "         [[-0.1222]],\n",
       "\n",
       "         [[-0.0225]],\n",
       "\n",
       "         [[ 0.1698]],\n",
       "\n",
       "         [[ 0.1923]],\n",
       "\n",
       "         [[ 0.0396]],\n",
       "\n",
       "         [[ 0.0742]],\n",
       "\n",
       "         [[ 0.2630]],\n",
       "\n",
       "         [[ 0.0454]],\n",
       "\n",
       "         [[ 0.2154]],\n",
       "\n",
       "         [[-0.1502]],\n",
       "\n",
       "         [[ 0.0754]],\n",
       "\n",
       "         [[ 0.1026]],\n",
       "\n",
       "         [[ 0.0296]],\n",
       "\n",
       "         [[ 0.0801]],\n",
       "\n",
       "         [[ 0.0084]],\n",
       "\n",
       "         [[ 0.0664]],\n",
       "\n",
       "         [[-0.2356]],\n",
       "\n",
       "         [[ 0.1217]],\n",
       "\n",
       "         [[ 0.1353]],\n",
       "\n",
       "         [[ 0.1134]],\n",
       "\n",
       "         [[-0.0969]],\n",
       "\n",
       "         [[-0.0584]],\n",
       "\n",
       "         [[-0.1067]],\n",
       "\n",
       "         [[-0.3733]],\n",
       "\n",
       "         [[ 0.0310]],\n",
       "\n",
       "         [[ 0.1004]],\n",
       "\n",
       "         [[ 0.0485]],\n",
       "\n",
       "         [[-0.0359]],\n",
       "\n",
       "         [[-0.0651]],\n",
       "\n",
       "         [[-0.0701]],\n",
       "\n",
       "         [[ 0.0512]],\n",
       "\n",
       "         [[-0.0109]],\n",
       "\n",
       "         [[ 0.0539]],\n",
       "\n",
       "         [[ 0.1152]],\n",
       "\n",
       "         [[ 0.0118]],\n",
       "\n",
       "         [[-0.3467]],\n",
       "\n",
       "         [[ 0.0484]],\n",
       "\n",
       "         [[-0.1393]],\n",
       "\n",
       "         [[ 0.1184]],\n",
       "\n",
       "         [[-0.0437]],\n",
       "\n",
       "         [[-0.0026]],\n",
       "\n",
       "         [[-0.1817]],\n",
       "\n",
       "         [[-0.0424]],\n",
       "\n",
       "         [[ 0.0377]],\n",
       "\n",
       "         [[ 0.1089]],\n",
       "\n",
       "         [[ 0.1216]],\n",
       "\n",
       "         [[ 0.2868]],\n",
       "\n",
       "         [[-0.1083]],\n",
       "\n",
       "         [[-0.1988]],\n",
       "\n",
       "         [[ 0.0223]],\n",
       "\n",
       "         [[-0.1502]],\n",
       "\n",
       "         [[ 0.1079]],\n",
       "\n",
       "         [[-0.0968]],\n",
       "\n",
       "         [[ 0.2024]],\n",
       "\n",
       "         [[ 0.0133]],\n",
       "\n",
       "         [[ 0.0856]],\n",
       "\n",
       "         [[-0.2467]],\n",
       "\n",
       "         [[-0.1575]],\n",
       "\n",
       "         [[ 0.1688]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.AdaptiveAvgPool2d(1)\n",
    "input = torch.randn(1, 64, 8, 9)\n",
    "m(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Conda_Env_Pytorch]",
   "language": "python",
   "name": "conda-env-Conda_Env_Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
