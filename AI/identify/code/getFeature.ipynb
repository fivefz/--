{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "dataFrame 为训练样本和validation样本共同组成的dataFrame\n",
    "testPath是测试样本所在的文件夹\n",
    "outputPath是提取的feature文件输出的文件夹\n",
    "network为提取特征使用的网络结构\n",
    "'''\n",
    "def  getFeatures(dataframe,testPath,outputPath,network,batchsize=batch_size,cudaDevice='3'):\n",
    "    if network == 'resnet18':\n",
    "        model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])#python中单个星号表示该位置接收任意多个非关键字参数 并转化为元表\n",
    "        featurenum=512\n",
    "    elif network=='resnet34':\n",
    "        model_conv = torchvision.models.resnet34(pretrained=True)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        featurenum = 512\n",
    "    elif network=='resnet50':\n",
    "        model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        featurenum = 2048\n",
    "    elif network=='resnet152':\n",
    "        model_conv = torchvision.models.resnet152(pretrained=True)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        featurenum = 2048\n",
    "    elif network == 'vgg19':\n",
    "        model_conv = torchvision.models.vgg19(pretrained=True)\n",
    "        model_conv.classifier = nn.Sequential(*list(model_conv.classifier.children())[:-1])\n",
    "        featurenum = 4096\n",
    "    elif network == 'densenet161':\n",
    "        model_conv = torchvision.models.densenet161(pretrained=True)\n",
    "        model_conv.classifier = nn.Sequential(*list(model_conv.classifier.children())[:-1])\n",
    "        featurenum = 2208\n",
    "    elif network == 'densenet169':\n",
    "        model_conv = torchvision.models.densenet169(pretrained=True)\n",
    "        model_conv.classifier = nn.Sequential(*list(model_conv.classifier.children())[:-1])\n",
    "        featurenum = 1664\n",
    "    elif network== 'inception_v3':\n",
    "        model_conv = torchvision.models.inception_v3(pretrained = True,transform_input=False)\n",
    "        featurenum = 1000\n",
    "    if type(cudaDevice) is not str and type(cudaDevice) is not list:\n",
    "        raise Exception('Error type of the CUDA Device')\n",
    "    if type(cudaDevice) is str:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = cudaDevice\n",
    "        model_conv.cuda()\n",
    "    if type(cudaDevice) is list:\n",
    "        model_conv=nn.DataParallel(model_conv,device_ids=cudaDevice)\n",
    "    model_conv.eval()\n",
    "    if network == 'inception_v3':\n",
    "        train_transform=transforms.Compose([\n",
    "            transforms.Resize(320),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "#                                  std = [ 0.229, 0.224, 0.225 ]) # 这里的mean和std对应的都是Imagenet中的mean和std\n",
    "        ])\n",
    "    else:\n",
    "         train_transform=transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "#                                  std = [ 0.229, 0.224, 0.225 ])\n",
    "        ]) #可以增加Normolization\n",
    "    train_feature = []\n",
    "    for idx in range(0, dataframe.shape[0], batchsize):\n",
    "        if idx + batchsize < dataframe.shape[0]:\n",
    "            ff = read_img(dataframe['image_id'].iloc[idx: idx + batchsize].values) #获取dataFrame中某一属性的Series 在某一范围内的对象 并获取其valus 表示为array\n",
    "            ff = [train_transform(x) for x in ff]\n",
    "            ff = torch.stack(ff)\n",
    "            ff = model_conv(Variable(ff.cuda())).view(-1, featurenum)\n",
    "            train_feature.append(ff.data.cpu().numpy())\n",
    "            del ff; gc.collect()\n",
    "        else:\n",
    "            ff = read_img(dataframe['image_id'].iloc[idx: ].values)\n",
    "            ff = [train_transform(x) for x in ff]\n",
    "            ff = torch.stack(ff)\n",
    "            ff = model_conv(Variable(ff.cuda())).view(-1, featurenum)\n",
    "            train_feature.append(ff.data.cpu().numpy())\n",
    "            del ff; gc.collect()\n",
    "        print('Train', idx, train_val.shape[0])\n",
    "    train_feature = np.array(train_feature)\n",
    "    test=os.listdir(testPath)\n",
    "    test=[testPath+x for x in test]\n",
    "    test_feature=[]\n",
    "    for idx in range(0, len(test), batchsize):\n",
    "        if idx + batchsize < len(test):\n",
    "            ff = read_img(test[idx: idx + batchsize])\n",
    "            ff = [train_transform(x) for x in ff]\n",
    "            ff = torch.stack(ff)\n",
    "            ff = model_conv(Variable(ff.cuda())).view(-1, featurenum)\n",
    "            test_feature.append(ff.data.cpu().numpy())\n",
    "            del ff; gc.collect()\n",
    "        else:\n",
    "            ff = read_img(test[idx: ])\n",
    "            ff = [train_transform(x) for x in ff]\n",
    "            ff = torch.stack(ff)\n",
    "            ff = model_conv(Variable(ff.cuda())).view(-1, featurenum)\n",
    "            test_feature.append(ff.data.cpu().numpy())\n",
    "            del ff; gc.collect()\n",
    "        print('Test', idx, len(test))\n",
    "    test_feature = np.array(test_feature)\n",
    "    train_feature = np.concatenate(train_feature, 0).reshape(-1, featurenum)\n",
    "    test_feature = np.concatenate(test_feature, 0).reshape(-1, featurenum)\n",
    "    with h5py.File(outputPath+network+'.h5', \"w\") as f:\n",
    "        f.create_dataset(\"train_feature\", data=train_feature)\n",
    "        f.create_dataset(\"test_feature\", data=test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "通过提取到的特征训练最后一层全连接层 可以替换成SVM等\n",
    "featurefile 表示提取的特征所在的目录\n",
    "testPath: 测试图像所在的目录\n",
    "model：训练的模型名称 这里使用上述定义的modelnn\n",
    "\n",
    "'''    \n",
    "def trainLastLinear(feature_file,testPath,epochsize=80):\n",
    "    train_feat, test_feat = [], []\n",
    "    for ffile in os.listdir(feature_file):\n",
    "        with h5py.File(feature_file+ffile, \"r\") as f:\n",
    "            train_feat.append(f['train_feature'][:])\n",
    "            test_feat.append(f['test_feature'][:])\n",
    "    train_feat = np.concatenate(train_feat, 1)#在列上进行合并 相当于把[[1,2,3],[4,5,6]]和[[1,2],[3,4]]合并为[[1,2,3,1,2],[4,5,6,3,4]]\n",
    "    test_feat = np.concatenate(test_feat, 1)\n",
    "    print('Feature:', train_feat.shape)\n",
    "    print(feature_file)\n",
    "    skf=StratifiedKFold(n_splits=6)\n",
    "    train_preds, test_preds = np.zeros(train_feat.shape[0]), []\n",
    "    train_logs = [[], [], [], []]\n",
    "    for train_index, test_index in skf.split(train_feat, train_val['disease_class']):\n",
    "        X_train, X_test = train_feat[train_index, :], train_feat[test_index, :]\n",
    "        y_train, y_test = train_val['disease_class'].values[train_index], train_val['disease_class'].values[test_index]\n",
    "        train_set = ArrayLoader(X_train, y_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size = 64, shuffle=True, num_workers=4)\n",
    "        val_set = ArrayLoader(X_test, y_test)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size = 64, shuffle=True, num_workers=4)\n",
    "        model=modelnn(train_feat.shape[1])\n",
    "        model=model.cuda()\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "        optimizer_ft = torch.optim.SGD(model.parameters(), lr = 0.0001, momentum = 0.75, weight_decay = 1e-4)\n",
    "        for epoch in range(epochsize):\n",
    "            adjust_learning_rate(optimizer_ft, epoch)\n",
    "            running_corrects = 0.0\n",
    "            running_loss = 0.0\n",
    "            for data in train_loader:\n",
    "                dta_x, dta_y = data\n",
    "                dta_x, dta_y = Variable(dta_x.cuda()), Variable(dta_y.cuda().view(dta_y.size(0)))\n",
    "                optimizer_ft.zero_grad()\n",
    "                outputs = model(dta_x)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "#                 print(dta_y)\n",
    "#                 print(preds)\n",
    "                loss = criterion(outputs, dta_y)\n",
    "                loss.backward()\n",
    "                optimizer_ft.step()\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == dta_y.data)\n",
    "            train_loss = running_loss / len(train_set)\n",
    "            train_acc = float(running_corrects) / len(train_set)\n",
    "            running_corrects = 0.0\n",
    "            running_loss = 0.0\n",
    "            for data in val_loader:\n",
    "                dta_x,dta_y=data\n",
    "                dta_x, dta_y = Variable(dta_x.cuda()), Variable(dta_y.cuda().view(dta_y.size(0)))\n",
    "                outputs = model(dta_x)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, dta_y)\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == dta_y.data)\n",
    "            val_loss = running_loss / len(val_set)\n",
    "            val_acc = float(running_corrects) / len(val_set)\n",
    "            epoch_log = '[%d/%d] Loss %.6f/%.6f Acc %.6f/%.6f' % (epoch, epochsize, train_loss, val_loss, train_acc, val_acc)\n",
    "            print(epoch_log)\n",
    "        val_set = ArrayLoader(X_test, y_test)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size = 1, shuffle = False, num_workers=4)\n",
    "        val_pred = []\n",
    "        for data in val_loader:\n",
    "            dta_x, _ = data\n",
    "            dta_x = Variable(dta_x.cuda())\n",
    "            outputs = model(dta_x)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_pred.append(preds.cpu().numpy()[0])       \n",
    "        train_preds[test_index] = val_pred\n",
    "        train_logs[0].append(train_loss)\n",
    "        train_logs[1].append(val_loss)\n",
    "        train_logs[2].append(train_acc)\n",
    "        train_logs[3].append(val_acc)\n",
    "        print('Val:', sum(train_preds[test_index] == y_test) * 1.0 / len(y_test))\n",
    "        test_set = ArrayLoader(test_feat, np.zeros_like(test_feat))\n",
    "        test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, shuffle = False, num_workers=4)\n",
    "        test_pred = []\n",
    "        for data in test_loader:\n",
    "            dta_x, _ = data\n",
    "            dta_x = Variable(dta_x.cuda())\n",
    "            outputs = model(dta_x)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            test_pred.append(preds.cpu().numpy()[0])\n",
    "        test_preds.append(test_pred)\n",
    "#         test=[x for x in os.listdir(testPath)]\n",
    "#         with codecs.open('test_.txt' + str(train_logs[3][-1]), 'w') as f:\n",
    "#             for i in range(len(test)):\n",
    "#                 f.write(str(test_pred[i])  + '\\t' + test[i] + '\\n')\n",
    "    print('+++ Loss %.6f/%.6f Acc %.6f/%.6f' % (np.mean(train_logs[0]), np.mean(train_logs[1]), np.mean(train_logs[2]), np.mean(train_logs[3])))\n",
    "    test_preds=np.array(test_preds)\n",
    "    print('test_preds shape is :',test_preds.shape)\n",
    "    result=[np.argmax(np.bincount(test_preds[:,i])) for i in range(0,test_preds.shape[1])]\n",
    "    uploadFile=[]\n",
    "    for index,img in enumerate(os.listdir(testPath)):\n",
    "        a={\"image_id\":img,\"disease_class\":int(result[index])}\n",
    "        uploadFile.append(a.copy())\n",
    "    with open(\"result.json\",'w') as f:\n",
    "        json.dump(uploadFile,f,ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Conda_Env_Pytorch]",
   "language": "python",
   "name": "conda-env-Conda_Env_Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
