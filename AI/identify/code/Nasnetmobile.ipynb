{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CropModels\n",
    "from CropDataset import MyDataSet,normalize_torch,normalize_05,normalize_dataset,preprocess,preprocess_hflip,preprocess_with_augmentation\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils import RunningMean\n",
    "import utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "NB_CLASS=59\n",
    "SEED=888\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "IMAGE_SIZE=224    # 不同模型修改不同的Size\n",
    "IMAGE_TRAIN_PRE='../data/AgriculturalDisease_trainingset/images/'\n",
    "ANNOTATION_TRAIN='../data/AgriculturalDisease_trainingset/AgriculturalDisease_train_annotations_deleteNoise.json' #是否需要剔除两类异常类\n",
    "IMAGE_VAL_PRE='../data/AgriculturalDisease_validationset/images/'\n",
    "ANNOTATION_VAL='../data/AgriculturalDisease_validationset/AgriculturalDisease_validation_annotations_deleteNoise.json' #是否需要剔除两类异常类\n",
    "date=str(datetime.date.today())\n",
    "with open(ANNOTATION_TRAIN) as datafile1:\n",
    "    trainDataFram=pd.read_json(datafile1,orient='records')\n",
    "with open(ANNOTATION_VAL) as datafile2: #first check if it's a valid json file or not\n",
    "    validateDataFram =pd.read_json(datafile2,orient='records')    \n",
    "def getmodel():\n",
    "    print('[+] loading model... ', end='', flush=True)\n",
    "    model=CropModels.nasnetmobile(NB_CLASS)\n",
    "    model.cuda()\n",
    "    print('Done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochNum):\n",
    "    writer=SummaryWriter('log/'+date+'/NasnetMobile/') # 创建 /log/日期/InceptionResnet的组织形式  不同模型需要修改不同名称\n",
    "    train_dataset=MyDataSet(json_Description=ANNOTATION_TRAIN,transform=preprocess_with_augmentation(normalize_05,IMAGE_SIZE),path_pre=IMAGE_TRAIN_PRE)\n",
    "    val_dataset=MyDataSet(json_Description=ANNOTATION_VAL,transform=preprocess(normalize_05,IMAGE_SIZE),path_pre=IMAGE_VAL_PRE)\n",
    "    train_dataLoader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,num_workers=16,shuffle=True)\n",
    "    val_dataLoader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,num_workers=1,shuffle=False)\n",
    "    model=getmodel()\n",
    "    weight=torch.Tensor([1,3,3,3,3,4,2,3,3,3,3,3,3,3,3,3,2,3,3,3,2,3,4,2,3,1,1,3,2,2,1,3,3,1,3,2,3,3,3,3,2,1,3,2,3,3,3,1,3,3,4,4,3,2,2,3,1,1,3]).cuda()\n",
    "    criterion=nn.CrossEntropyLoss(weight=weight).cuda()\n",
    "#     lx, px = utils.predict(model,val_dataLoader)\n",
    "#     min_loss = criterion(Variable(px), Variable(lx)).item()\n",
    "    min_loss=4.1\n",
    "    print('min_loss is :%f'%(min_loss))\n",
    "    min_acc=0.80\n",
    "    patience=0\n",
    "    lr=0.0\n",
    "    momentum=0.0\n",
    "    for epoch in range(epochNum):\n",
    "        print('Epoch {}/{}'.format(epoch, epochNum - 1))\n",
    "        print('-' * 10)\n",
    "        if epoch==3 or epoch==4 or epoch==5:\n",
    "            lr=0.00006\n",
    "            momentum=0.95\n",
    "            print('set lr=:%f,momentum=%f'%(lr,momentum))\n",
    "        if epoch==6:\n",
    "            lr=1e-4\n",
    "            momentum=0.9\n",
    "            print('set lr=:%f,momentum=%f'%(lr,momentum))\n",
    "        if patience==2:\n",
    "            patience=0\n",
    "            model.load_state_dict(torch.load('../model/NasnetMobile/'+date+'_loss_best.pth')['state_dict'])\n",
    "            lr=lr/10\n",
    "            print('loss has increased lr divide 10 lr now is :%f'%(lr))\n",
    "        if epoch==0 or epoch==1 or epoch==2: #第一轮首先训练全连接层\n",
    "            lr=1e-3\n",
    "#             optimizer=torch.optim.SGD(params=model.fresh_params(),lr=lr,momentum=0.9)\n",
    "            optimizer = torch.optim.Adam(model.fresh_params(),lr = lr,amsgrad=True,weight_decay=1e-4)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(model.parameters(),lr = lr,amsgrad=True,weight_decay=1e-4)\n",
    "#             optimizer=torch.optim.SGD(params=model.parameters(),lr=lr,momentum=momentum)\n",
    "        running_loss = RunningMean()\n",
    "        running_corrects = RunningMean()\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_dataLoader):\n",
    "            model.train(True)\n",
    "            n_batchsize=inputs.size(0)\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            if isinstance(outputs,tuple):\n",
    "                loss=sum((criterion(o,labels)) for o in outputs)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss.update(loss.item(),1)\n",
    "            running_corrects.update(torch.sum(preds == labels.data).data,n_batchsize)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx%30==29:\n",
    "                print('[epoch:%d,batch:%d]:acc: %f,loss:%f'%(epoch,batch_idx,running_corrects.value,running_loss.value))\n",
    "                if batch_idx%300==299: \n",
    "                    niter = epoch * len(train_dataset)/BATCH_SIZE + batch_idx\n",
    "                    writer.add_scalar('Train/Acc',running_corrects.value,niter)\n",
    "                    writer.add_scalar('Train/Loss',running_loss.value,niter)\n",
    "                    lx,px=utils.predict(model,val_dataLoader)\n",
    "                    log_loss = criterion(Variable(px), Variable(lx))\n",
    "                    log_loss = log_loss.item()\n",
    "                    _, preds = torch.max(px, dim=1)\n",
    "                    accuracy = torch.mean((preds == lx).float())\n",
    "                    writer.add_scalar('Val/Acc',accuracy,niter)\n",
    "                    writer.add_scalar('Val/Loss',log_loss,niter)\n",
    "                    print('[epoch:%d,batch:%d]: val_loss:%f,val_acc:%f,val_total:%d'%(epoch,batch_idx,log_loss,accuracy,len(val_dataset)))\n",
    "        print('[epoch:%d] :acc: %f,loss:%f,lr:%f,patience:%d'%(epoch,running_corrects.value,running_loss.value,lr,patience))       \n",
    "        lx,px=utils.predict(model,val_dataLoader)\n",
    "        log_loss = criterion(Variable(px), Variable(lx))\n",
    "        log_loss = log_loss.item()\n",
    "        _, preds = torch.max(px, dim=1)\n",
    "        accuracy = torch.mean((preds == lx).float())\n",
    "        writer.add_scalar('Val/Acc',accuracy,(epoch+1) * len(train_dataset)/BATCH_SIZE)\n",
    "        writer.add_scalar('Val/Loss',log_loss,(epoch+1) * len(train_dataset)/BATCH_SIZE)\n",
    "        print('[epoch:%d]: val_loss:%f,val_acc:%f,'%(epoch,log_loss,accuracy))\n",
    "        if  log_loss < min_loss:\n",
    "            utils.snapshot('../model/', 'NasnetMobile', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy })          \n",
    "            patience = 0\n",
    "            min_loss=log_loss\n",
    "            print('save new model loss,now loss is ',min_loss)\n",
    "        else:\n",
    "            patience += 1\n",
    "        if accuracy>min_acc:\n",
    "            utils.snapshot('../model/', 'NasnetMobile', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy },key='acc') \n",
    "            min_acc=accuracy\n",
    "            print('save new model acc,now acc is ',min_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model... Done\n",
      "min_loss is :4.100000\n",
      "Epoch 0/59\n",
      "----------\n",
      "[epoch:0,batch:29]:acc: 0.134375,loss:3.926591\n",
      "[epoch:0,batch:59]:acc: 0.206771,loss:3.678492\n",
      "[epoch:0,batch:89]:acc: 0.263542,loss:3.434125\n",
      "[epoch:0,batch:119]:acc: 0.303906,loss:3.256706\n",
      "[epoch:0,batch:149]:acc: 0.340833,loss:3.095744\n",
      "[epoch:0,batch:179]:acc: 0.365625,loss:2.965924\n",
      "[epoch:0,batch:209]:acc: 0.383036,loss:2.855124\n",
      "[epoch:0,batch:239]:acc: 0.400000,loss:2.763887\n",
      "[epoch:0,batch:269]:acc: 0.416204,loss:2.673652\n",
      "[epoch:0,batch:299]:acc: 0.429896,loss:2.590477\n",
      "[epoch:0,batch:299]: val_loss:1.777935,val_acc:0.599912,val_total:4539\n",
      "[epoch:0,batch:329]:acc: 0.441477,loss:2.518498\n",
      "[epoch:0,batch:359]:acc: 0.447049,loss:2.464793\n",
      "[epoch:0,batch:389]:acc: 0.456250,loss:2.411397\n",
      "[epoch:0,batch:419]:acc: 0.465253,loss:2.358708\n",
      "[epoch:0,batch:449]:acc: 0.471875,loss:2.315168\n",
      "[epoch:0,batch:479]:acc: 0.478125,loss:2.270495\n",
      "[epoch:0,batch:509]:acc: 0.484069,loss:2.229955\n",
      "[epoch:0,batch:539]:acc: 0.488831,loss:2.195394\n",
      "[epoch:0,batch:569]:acc: 0.493860,loss:2.162023\n",
      "[epoch:0,batch:599]:acc: 0.497969,loss:2.134221\n",
      "[epoch:0,batch:599]: val_loss:1.423362,val_acc:0.628332,val_total:4539\n",
      "[epoch:0,batch:629]:acc: 0.503869,loss:2.100400\n",
      "[epoch:0,batch:659]:acc: 0.508144,loss:2.072196\n",
      "[epoch:0,batch:689]:acc: 0.511504,loss:2.046906\n",
      "[epoch:0,batch:719]:acc: 0.514106,loss:2.024446\n",
      "[epoch:0,batch:749]:acc: 0.518750,loss:2.000811\n",
      "[epoch:0,batch:779]:acc: 0.521314,loss:1.979322\n",
      "[epoch:0,batch:809]:acc: 0.524691,loss:1.955226\n",
      "[epoch:0,batch:839]:acc: 0.527530,loss:1.936132\n",
      "[epoch:0,batch:869]:acc: 0.530747,loss:1.916927\n",
      "[epoch:0,batch:899]:acc: 0.533299,loss:1.898315\n",
      "[epoch:0,batch:899]: val_loss:1.205489,val_acc:0.655431,val_total:4539\n",
      "[epoch:0,batch:929]:acc: 0.535517,loss:1.881460\n",
      "[epoch:0,batch:959]:acc: 0.538184,loss:1.863478\n",
      "[epoch:0,batch:989]:acc: 0.540372,loss:1.847367\n",
      "[epoch:0] :acc: 0.540436,loss:1.846112,lr:0.001000,patience:0\n",
      "[epoch:0]: val_loss:1.233026,val_acc:0.668429,\n",
      "save new model loss,now loss is  1.2330256700515747\n",
      "Epoch 1/59\n",
      "----------\n",
      "[epoch:1,batch:29]:acc: 0.590625,loss:1.413596\n",
      "[epoch:1,batch:59]:acc: 0.615104,loss:1.368989\n",
      "[epoch:1,batch:89]:acc: 0.616667,loss:1.348441\n",
      "[epoch:1,batch:119]:acc: 0.619271,loss:1.329670\n",
      "[epoch:1,batch:149]:acc: 0.617500,loss:1.325757\n",
      "[epoch:1,batch:179]:acc: 0.619097,loss:1.306122\n",
      "[epoch:1,batch:209]:acc: 0.617560,loss:1.307735\n",
      "[epoch:1,batch:239]:acc: 0.615755,loss:1.311644\n",
      "[epoch:1,batch:269]:acc: 0.614931,loss:1.301307\n",
      "[epoch:1,batch:299]:acc: 0.613958,loss:1.297638\n",
      "[epoch:1,batch:299]: val_loss:1.083534,val_acc:0.693104,val_total:4539\n",
      "[epoch:1,batch:329]:acc: 0.615246,loss:1.294801\n",
      "[epoch:1,batch:359]:acc: 0.617101,loss:1.288765\n",
      "[epoch:1,batch:389]:acc: 0.617869,loss:1.284631\n",
      "[epoch:1,batch:419]:acc: 0.616741,loss:1.285838\n",
      "[epoch:1,batch:449]:acc: 0.617153,loss:1.285701\n",
      "[epoch:1,batch:479]:acc: 0.618815,loss:1.280917\n",
      "[epoch:1,batch:509]:acc: 0.618260,loss:1.279585\n",
      "[epoch:1,batch:539]:acc: 0.619907,loss:1.272638\n",
      "[epoch:1,batch:569]:acc: 0.621436,loss:1.267107\n",
      "[epoch:1,batch:599]:acc: 0.622344,loss:1.262544\n",
      "[epoch:1,batch:599]: val_loss:1.041291,val_acc:0.688257,val_total:4539\n",
      "[epoch:1,batch:629]:acc: 0.622222,loss:1.263546\n",
      "[epoch:1,batch:659]:acc: 0.622585,loss:1.262679\n",
      "[epoch:1,batch:689]:acc: 0.622781,loss:1.258981\n",
      "[epoch:1,batch:719]:acc: 0.623828,loss:1.256072\n",
      "[epoch:1,batch:749]:acc: 0.624917,loss:1.251500\n",
      "[epoch:1,batch:779]:acc: 0.625361,loss:1.249619\n",
      "[epoch:1,batch:809]:acc: 0.625231,loss:1.247365\n",
      "[epoch:1,batch:839]:acc: 0.625930,loss:1.245311\n",
      "[epoch:1,batch:869]:acc: 0.626114,loss:1.244462\n",
      "[epoch:1,batch:899]:acc: 0.626007,loss:1.242853\n",
      "[epoch:1,batch:899]: val_loss:0.979558,val_acc:0.709848,val_total:4539\n",
      "[epoch:1,batch:929]:acc: 0.626042,loss:1.241341\n",
      "[epoch:1,batch:959]:acc: 0.626204,loss:1.239558\n",
      "[epoch:1,batch:989]:acc: 0.626894,loss:1.237004\n",
      "[epoch:1] :acc: 0.626888,loss:1.236445,lr:0.001000,patience:0\n",
      "[epoch:1]: val_loss:1.041832,val_acc:0.685834,\n",
      "save new model loss,now loss is  1.041832447052002\n",
      "Epoch 2/59\n",
      "----------\n",
      "[epoch:2,batch:29]:acc: 0.650000,loss:1.177026\n",
      "[epoch:2,batch:59]:acc: 0.645833,loss:1.184791\n",
      "[epoch:2,batch:89]:acc: 0.645833,loss:1.179943\n",
      "[epoch:2,batch:119]:acc: 0.645573,loss:1.174075\n",
      "[epoch:2,batch:149]:acc: 0.637917,loss:1.176409\n",
      "[epoch:2,batch:179]:acc: 0.637326,loss:1.187229\n",
      "[epoch:2,batch:209]:acc: 0.640476,loss:1.178903\n",
      "[epoch:2,batch:239]:acc: 0.644661,loss:1.172626\n",
      "[epoch:2,batch:269]:acc: 0.647222,loss:1.168853\n",
      "[epoch:2,batch:299]:acc: 0.647500,loss:1.172392\n",
      "[epoch:2,batch:299]: val_loss:1.017838,val_acc:0.675259,val_total:4539\n",
      "[epoch:2,batch:329]:acc: 0.647348,loss:1.169673\n",
      "[epoch:2,batch:359]:acc: 0.645747,loss:1.168072\n",
      "[epoch:2,batch:389]:acc: 0.643590,loss:1.170098\n",
      "[epoch:2,batch:419]:acc: 0.640699,loss:1.169869\n",
      "[epoch:2,batch:449]:acc: 0.641181,loss:1.167412\n",
      "[epoch:2,batch:479]:acc: 0.642643,loss:1.160473\n",
      "[epoch:2,batch:509]:acc: 0.643689,loss:1.153065\n",
      "[epoch:2,batch:539]:acc: 0.642940,loss:1.155290\n",
      "[epoch:2,batch:569]:acc: 0.642873,loss:1.155549\n",
      "[epoch:2,batch:599]:acc: 0.642344,loss:1.152985\n",
      "[epoch:2,batch:599]: val_loss:0.970982,val_acc:0.694867,val_total:4539\n",
      "[epoch:2,batch:629]:acc: 0.641865,loss:1.154800\n",
      "[epoch:2,batch:659]:acc: 0.641761,loss:1.153443\n",
      "[epoch:2,batch:689]:acc: 0.641712,loss:1.150795\n",
      "[epoch:2,batch:719]:acc: 0.642925,loss:1.147133\n",
      "[epoch:2,batch:749]:acc: 0.642000,loss:1.146269\n",
      "[epoch:2,batch:779]:acc: 0.641627,loss:1.144613\n",
      "[epoch:2,batch:809]:acc: 0.640741,loss:1.145937\n",
      "[epoch:2,batch:839]:acc: 0.641481,loss:1.145101\n",
      "[epoch:2,batch:869]:acc: 0.641810,loss:1.143079\n",
      "[epoch:2,batch:899]:acc: 0.642014,loss:1.143379\n",
      "[epoch:2,batch:899]: val_loss:0.949067,val_acc:0.694426,val_total:4539\n",
      "[epoch:2,batch:929]:acc: 0.641465,loss:1.144057\n",
      "[epoch:2,batch:959]:acc: 0.641211,loss:1.143985\n",
      "[epoch:2,batch:989]:acc: 0.641383,loss:1.144465\n",
      "[epoch:2] :acc: 0.641423,loss:1.144186,lr:0.001000,patience:0\n",
      "[epoch:2]: val_loss:0.887476,val_acc:0.716017,\n",
      "save new model loss,now loss is  0.887475848197937\n",
      "Epoch 3/59\n",
      "----------\n",
      "set lr=:0.000060,momentum=0.950000\n",
      "[epoch:3,batch:29]:acc: 0.666667,loss:1.025257\n",
      "[epoch:3,batch:59]:acc: 0.671875,loss:0.990890\n",
      "[epoch:3,batch:89]:acc: 0.678819,loss:0.975911\n",
      "[epoch:3,batch:119]:acc: 0.685677,loss:0.962818\n",
      "[epoch:3,batch:149]:acc: 0.692500,loss:0.944327\n",
      "[epoch:3,batch:179]:acc: 0.699132,loss:0.917149\n",
      "[epoch:3,batch:209]:acc: 0.703720,loss:0.893162\n",
      "[epoch:3,batch:239]:acc: 0.708464,loss:0.878839\n",
      "[epoch:3,batch:269]:acc: 0.711458,loss:0.867701\n",
      "[epoch:3,batch:299]:acc: 0.713333,loss:0.856449\n",
      "[epoch:3,batch:299]: val_loss:0.628219,val_acc:0.775281,val_total:4539\n",
      "[epoch:3,batch:329]:acc: 0.714867,loss:0.853265\n",
      "[epoch:3,batch:359]:acc: 0.714497,loss:0.851596\n",
      "[epoch:3,batch:389]:acc: 0.715946,loss:0.844520\n",
      "[epoch:3,batch:419]:acc: 0.719048,loss:0.835781\n",
      "[epoch:3,batch:449]:acc: 0.723264,loss:0.822572\n",
      "[epoch:3,batch:479]:acc: 0.725846,loss:0.811323\n",
      "[epoch:3,batch:509]:acc: 0.727451,loss:0.802665\n",
      "[epoch:3,batch:539]:acc: 0.728704,loss:0.795637\n",
      "[epoch:3,batch:569]:acc: 0.731031,loss:0.788570\n",
      "[epoch:3,batch:599]:acc: 0.732917,loss:0.780943\n",
      "[epoch:3,batch:599]: val_loss:0.555851,val_acc:0.794668,val_total:4539\n",
      "[epoch:3,batch:629]:acc: 0.733978,loss:0.774437\n",
      "[epoch:3,batch:659]:acc: 0.734517,loss:0.768493\n",
      "[epoch:3,batch:689]:acc: 0.736368,loss:0.760581\n",
      "[epoch:3,batch:719]:acc: 0.738628,loss:0.752451\n",
      "[epoch:3,batch:749]:acc: 0.739417,loss:0.750300\n",
      "[epoch:3,batch:779]:acc: 0.741466,loss:0.743383\n",
      "[epoch:3,batch:809]:acc: 0.742708,loss:0.740620\n",
      "[epoch:3,batch:839]:acc: 0.744866,loss:0.734605\n",
      "[epoch:3,batch:869]:acc: 0.745366,loss:0.731223\n",
      "[epoch:3,batch:899]:acc: 0.746667,loss:0.724844\n",
      "[epoch:3,batch:899]: val_loss:0.506123,val_acc:0.811412,val_total:4539\n",
      "[epoch:3,batch:929]:acc: 0.747614,loss:0.721564\n",
      "[epoch:3,batch:959]:acc: 0.749121,loss:0.717303\n",
      "[epoch:3,batch:989]:acc: 0.749779,loss:0.714307\n",
      "[epoch:3] :acc: 0.749850,loss:0.715340,lr:0.000060,patience:0\n",
      "[epoch:3]: val_loss:0.502076,val_acc:0.814497,\n",
      "save new model loss,now loss is  0.5020756721496582\n",
      "save new model acc,now acc is  tensor(0.8145, device='cuda:0')\n",
      "Epoch 4/59\n",
      "----------\n",
      "set lr=:0.000060,momentum=0.950000\n",
      "[epoch:4,batch:29]:acc: 0.802083,loss:0.574439\n",
      "[epoch:4,batch:59]:acc: 0.799479,loss:0.574898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:4,batch:89]:acc: 0.794444,loss:0.588114\n",
      "[epoch:4,batch:119]:acc: 0.792969,loss:0.580286\n",
      "[epoch:4,batch:149]:acc: 0.795000,loss:0.568641\n",
      "[epoch:4,batch:179]:acc: 0.797222,loss:0.562046\n",
      "[epoch:4,batch:209]:acc: 0.798810,loss:0.558643\n",
      "[epoch:4,batch:239]:acc: 0.801172,loss:0.558706\n",
      "[epoch:4,batch:269]:acc: 0.800926,loss:0.550815\n",
      "[epoch:4,batch:299]:acc: 0.799375,loss:0.547913\n",
      "[epoch:4,batch:299]: val_loss:0.485960,val_acc:0.813175,val_total:4539\n",
      "[epoch:4,batch:329]:acc: 0.800189,loss:0.543621\n",
      "[epoch:4,batch:359]:acc: 0.801736,loss:0.537692\n",
      "[epoch:4,batch:389]:acc: 0.801603,loss:0.533546\n",
      "[epoch:4,batch:419]:acc: 0.801637,loss:0.530913\n",
      "[epoch:4,batch:449]:acc: 0.801736,loss:0.533578\n",
      "[epoch:4,batch:479]:acc: 0.803125,loss:0.527971\n",
      "[epoch:4,batch:509]:acc: 0.802696,loss:0.527473\n",
      "[epoch:4,batch:539]:acc: 0.804167,loss:0.525547\n",
      "[epoch:4,batch:569]:acc: 0.804715,loss:0.526363\n",
      "[epoch:4,batch:599]:acc: 0.805000,loss:0.526511\n",
      "[epoch:4,batch:599]: val_loss:0.453628,val_acc:0.829037,val_total:4539\n",
      "[epoch:4,batch:629]:acc: 0.804960,loss:0.528060\n",
      "[epoch:4,batch:659]:acc: 0.804830,loss:0.527138\n",
      "[epoch:4,batch:689]:acc: 0.805254,loss:0.527713\n",
      "[epoch:4,batch:719]:acc: 0.805122,loss:0.526189\n",
      "[epoch:4,batch:749]:acc: 0.805917,loss:0.523539\n",
      "[epoch:4,batch:779]:acc: 0.806530,loss:0.522266\n",
      "[epoch:4,batch:809]:acc: 0.806829,loss:0.521170\n",
      "[epoch:4,batch:839]:acc: 0.806213,loss:0.521741\n",
      "[epoch:4,batch:869]:acc: 0.805963,loss:0.521383\n",
      "[epoch:4,batch:899]:acc: 0.806389,loss:0.520444\n",
      "[epoch:4,batch:899]: val_loss:0.448277,val_acc:0.824631,val_total:4539\n",
      "[epoch:4,batch:929]:acc: 0.806015,loss:0.519135\n",
      "[epoch:4,batch:959]:acc: 0.805892,loss:0.517975\n",
      "[epoch:4,batch:989]:acc: 0.806061,loss:0.517152\n",
      "[epoch:4] :acc: 0.805972,loss:0.517242,lr:0.000060,patience:0\n",
      "[epoch:4]: val_loss:0.463127,val_acc:0.828376,\n",
      "save new model loss,now loss is  0.4631274342536926\n",
      "save new model acc,now acc is  tensor(0.8284, device='cuda:0')\n",
      "Epoch 5/59\n",
      "----------\n",
      "set lr=:0.000060,momentum=0.950000\n",
      "[epoch:5,batch:29]:acc: 0.807292,loss:0.494582\n",
      "[epoch:5,batch:59]:acc: 0.808854,loss:0.487625\n",
      "[epoch:5,batch:89]:acc: 0.817014,loss:0.476414\n",
      "[epoch:5,batch:119]:acc: 0.818490,loss:0.469035\n",
      "[epoch:5,batch:149]:acc: 0.815208,loss:0.470077\n",
      "[epoch:5,batch:179]:acc: 0.820312,loss:0.454350\n",
      "[epoch:5,batch:209]:acc: 0.821875,loss:0.448897\n",
      "[epoch:5,batch:239]:acc: 0.825130,loss:0.441223\n",
      "[epoch:5,batch:269]:acc: 0.827662,loss:0.438725\n",
      "[epoch:5,batch:299]:acc: 0.829375,loss:0.436760\n",
      "[epoch:5,batch:299]: val_loss:0.444625,val_acc:0.832783,val_total:4539\n",
      "[epoch:5,batch:329]:acc: 0.827273,loss:0.439857\n",
      "[epoch:5,batch:359]:acc: 0.826389,loss:0.437943\n",
      "[epoch:5,batch:389]:acc: 0.827644,loss:0.436836\n",
      "[epoch:5,batch:419]:acc: 0.826786,loss:0.439595\n",
      "[epoch:5,batch:449]:acc: 0.825417,loss:0.443339\n",
      "[epoch:5,batch:479]:acc: 0.824154,loss:0.446384\n",
      "[epoch:5,batch:509]:acc: 0.823897,loss:0.446312\n",
      "[epoch:5,batch:539]:acc: 0.823669,loss:0.448208\n",
      "[epoch:5,batch:569]:acc: 0.822752,loss:0.450994\n",
      "[epoch:5,batch:599]:acc: 0.822292,loss:0.451356\n",
      "[epoch:5,batch:599]: val_loss:0.439615,val_acc:0.839392,val_total:4539\n",
      "[epoch:5,batch:629]:acc: 0.824206,loss:0.448201\n",
      "[epoch:5,batch:659]:acc: 0.824432,loss:0.449281\n",
      "[epoch:5,batch:689]:acc: 0.825453,loss:0.448569\n",
      "[epoch:5,batch:719]:acc: 0.824392,loss:0.448926\n",
      "[epoch:5,batch:749]:acc: 0.823750,loss:0.448832\n",
      "[epoch:5,batch:779]:acc: 0.823357,loss:0.448865\n",
      "[epoch:5,batch:809]:acc: 0.822724,loss:0.450879\n",
      "[epoch:5,batch:839]:acc: 0.822284,loss:0.451928\n",
      "[epoch:5,batch:869]:acc: 0.822557,loss:0.452051\n",
      "[epoch:5,batch:899]:acc: 0.822604,loss:0.450934\n",
      "[epoch:5,batch:899]: val_loss:0.424856,val_acc:0.842917,val_total:4539\n",
      "[epoch:5,batch:929]:acc: 0.823152,loss:0.450622\n",
      "[epoch:5,batch:959]:acc: 0.823014,loss:0.450958\n",
      "[epoch:5,batch:989]:acc: 0.822885,loss:0.451796\n",
      "[epoch:5] :acc: 0.822934,loss:0.452425,lr:0.000060,patience:0\n",
      "[epoch:5]: val_loss:0.428663,val_acc:0.844459,\n",
      "save new model loss,now loss is  0.4286632537841797\n",
      "save new model acc,now acc is  tensor(0.8445, device='cuda:0')\n",
      "Epoch 6/59\n",
      "----------\n",
      "set lr=:0.000100,momentum=0.900000\n",
      "[epoch:6,batch:29]:acc: 0.826042,loss:0.464876\n",
      "[epoch:6,batch:59]:acc: 0.816146,loss:0.473665\n",
      "[epoch:6,batch:89]:acc: 0.821875,loss:0.467038\n",
      "[epoch:6,batch:119]:acc: 0.830208,loss:0.447637\n",
      "[epoch:6,batch:149]:acc: 0.833958,loss:0.433170\n",
      "[epoch:6,batch:179]:acc: 0.829340,loss:0.438022\n",
      "[epoch:6,batch:209]:acc: 0.833780,loss:0.426516\n",
      "[epoch:6,batch:239]:acc: 0.830729,loss:0.431394\n",
      "[epoch:6,batch:269]:acc: 0.824884,loss:0.441447\n",
      "[epoch:6,batch:299]:acc: 0.825417,loss:0.445370\n",
      "[epoch:6,batch:299]: val_loss:0.420973,val_acc:0.847764,val_total:4539\n",
      "[epoch:6,batch:329]:acc: 0.827273,loss:0.440769\n",
      "[epoch:6,batch:359]:acc: 0.829167,loss:0.437119\n",
      "[epoch:6,batch:389]:acc: 0.828766,loss:0.437204\n",
      "[epoch:6,batch:419]:acc: 0.830357,loss:0.433560\n",
      "[epoch:6,batch:449]:acc: 0.830764,loss:0.429711\n",
      "[epoch:6,batch:479]:acc: 0.832292,loss:0.424026\n",
      "[epoch:6,batch:509]:acc: 0.831066,loss:0.425840\n",
      "[epoch:6,batch:539]:acc: 0.831887,loss:0.422383\n",
      "[epoch:6,batch:569]:acc: 0.831798,loss:0.425410\n",
      "[epoch:6,batch:599]:acc: 0.832656,loss:0.423893\n",
      "[epoch:6,batch:599]: val_loss:0.434822,val_acc:0.831240,val_total:4539\n",
      "[epoch:6,batch:629]:acc: 0.831944,loss:0.425093\n",
      "[epoch:6,batch:659]:acc: 0.831203,loss:0.425954\n",
      "[epoch:6,batch:689]:acc: 0.830435,loss:0.428502\n",
      "[epoch:6,batch:719]:acc: 0.830556,loss:0.426977\n",
      "[epoch:6,batch:749]:acc: 0.830833,loss:0.427705\n",
      "[epoch:6,batch:779]:acc: 0.831050,loss:0.427440\n",
      "[epoch:6,batch:809]:acc: 0.830093,loss:0.428305\n",
      "[epoch:6,batch:839]:acc: 0.830134,loss:0.427979\n",
      "[epoch:6,batch:869]:acc: 0.829490,loss:0.428831\n",
      "[epoch:6,batch:899]:acc: 0.829306,loss:0.428872\n",
      "[epoch:6,batch:899]: val_loss:0.427742,val_acc:0.834545,val_total:4539\n",
      "[epoch:6,batch:929]:acc: 0.829267,loss:0.428151\n",
      "[epoch:6,batch:959]:acc: 0.829753,loss:0.427565\n",
      "[epoch:6,batch:989]:acc: 0.829703,loss:0.428674\n",
      "[epoch:6] :acc: 0.829744,loss:0.428516,lr:0.000100,patience:0\n",
      "[epoch:6]: val_loss:0.417609,val_acc:0.845561,\n",
      "save new model loss,now loss is  0.41760945320129395\n",
      "save new model acc,now acc is  tensor(0.8456, device='cuda:0')\n",
      "Epoch 7/59\n",
      "----------\n",
      "[epoch:7,batch:29]:acc: 0.862500,loss:0.354340\n",
      "[epoch:7,batch:59]:acc: 0.861458,loss:0.343687\n",
      "[epoch:7,batch:89]:acc: 0.863194,loss:0.336212\n",
      "[epoch:7,batch:119]:acc: 0.858333,loss:0.346986\n",
      "[epoch:7,batch:149]:acc: 0.855417,loss:0.364726\n",
      "[epoch:7,batch:179]:acc: 0.853646,loss:0.371012\n",
      "[epoch:7,batch:209]:acc: 0.854464,loss:0.366625\n",
      "[epoch:7,batch:239]:acc: 0.852734,loss:0.372424\n",
      "[epoch:7,batch:269]:acc: 0.850579,loss:0.373471\n",
      "[epoch:7,batch:299]:acc: 0.849792,loss:0.375991\n",
      "[epoch:7,batch:299]: val_loss:0.435200,val_acc:0.837850,val_total:4539\n",
      "[epoch:7,batch:329]:acc: 0.849053,loss:0.376061\n",
      "[epoch:7,batch:359]:acc: 0.847917,loss:0.377570\n",
      "[epoch:7,batch:389]:acc: 0.847196,loss:0.378772\n",
      "[epoch:7,batch:419]:acc: 0.845908,loss:0.381858\n",
      "[epoch:7,batch:449]:acc: 0.844931,loss:0.383498\n",
      "[epoch:7,batch:479]:acc: 0.844141,loss:0.383604\n",
      "[epoch:7,batch:509]:acc: 0.844424,loss:0.385353\n",
      "[epoch:7,batch:539]:acc: 0.845370,loss:0.383454\n",
      "[epoch:7,batch:569]:acc: 0.845066,loss:0.384178\n",
      "[epoch:7,batch:599]:acc: 0.844896,loss:0.385138\n",
      "[epoch:7,batch:599]: val_loss:0.421631,val_acc:0.844459,val_total:4539\n",
      "[epoch:7,batch:629]:acc: 0.844395,loss:0.386019\n",
      "[epoch:7,batch:659]:acc: 0.844650,loss:0.385536\n",
      "[epoch:7,batch:689]:acc: 0.845018,loss:0.384298\n",
      "[epoch:7,batch:719]:acc: 0.845573,loss:0.385077\n",
      "[epoch:7,batch:749]:acc: 0.845083,loss:0.385131\n",
      "[epoch:7,batch:779]:acc: 0.844551,loss:0.386113\n",
      "[epoch:7,batch:809]:acc: 0.844869,loss:0.385444\n",
      "[epoch:7,batch:839]:acc: 0.844308,loss:0.386612\n",
      "[epoch:7,batch:869]:acc: 0.844935,loss:0.386178\n",
      "[epoch:7,batch:899]:acc: 0.845278,loss:0.385514\n",
      "[epoch:7,batch:899]: val_loss:0.417493,val_acc:0.844239,val_total:4539\n",
      "[epoch:7,batch:929]:acc: 0.845228,loss:0.384835\n",
      "[epoch:7,batch:959]:acc: 0.845117,loss:0.384849\n",
      "[epoch:7,batch:989]:acc: 0.845013,loss:0.384950\n",
      "[epoch:7] :acc: 0.845036,loss:0.386382,lr:0.000100,patience:0\n",
      "[epoch:7]: val_loss:0.422607,val_acc:0.843578,\n",
      "Epoch 8/59\n",
      "----------\n",
      "[epoch:8,batch:29]:acc: 0.856250,loss:0.335740\n",
      "[epoch:8,batch:59]:acc: 0.867708,loss:0.318700\n",
      "[epoch:8,batch:89]:acc: 0.861458,loss:0.336318\n",
      "[epoch:8,batch:119]:acc: 0.859115,loss:0.347566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:8,batch:149]:acc: 0.861250,loss:0.346700\n",
      "[epoch:8,batch:179]:acc: 0.860243,loss:0.349774\n",
      "[epoch:8,batch:209]:acc: 0.861161,loss:0.346463\n",
      "[epoch:8,batch:239]:acc: 0.861328,loss:0.346013\n",
      "[epoch:8,batch:269]:acc: 0.859259,loss:0.347743\n",
      "[epoch:8,batch:299]:acc: 0.859479,loss:0.345000\n",
      "[epoch:8,batch:299]: val_loss:0.436724,val_acc:0.845340,val_total:4539\n",
      "[epoch:8,batch:329]:acc: 0.858239,loss:0.348898\n",
      "[epoch:8,batch:359]:acc: 0.858247,loss:0.348623\n",
      "[epoch:8,batch:389]:acc: 0.858894,loss:0.350182\n",
      "[epoch:8,batch:419]:acc: 0.858631,loss:0.350581\n",
      "[epoch:8,batch:449]:acc: 0.857847,loss:0.351519\n",
      "[epoch:8,batch:479]:acc: 0.857552,loss:0.352957\n",
      "[epoch:8,batch:509]:acc: 0.857782,loss:0.351632\n",
      "[epoch:8,batch:539]:acc: 0.856366,loss:0.356330\n",
      "[epoch:8,batch:569]:acc: 0.855702,loss:0.358551\n",
      "[epoch:8,batch:599]:acc: 0.855573,loss:0.359303\n",
      "[epoch:8,batch:599]: val_loss:0.403691,val_acc:0.844459,val_total:4539\n",
      "[epoch:8,batch:629]:acc: 0.856151,loss:0.359774\n",
      "[epoch:8,batch:659]:acc: 0.856013,loss:0.359917\n",
      "[epoch:8,batch:689]:acc: 0.855299,loss:0.361303\n",
      "[epoch:8,batch:719]:acc: 0.855165,loss:0.361185\n",
      "[epoch:8,batch:749]:acc: 0.855292,loss:0.362398\n",
      "[epoch:8,batch:779]:acc: 0.854848,loss:0.362116\n",
      "[epoch:8,batch:809]:acc: 0.854630,loss:0.363048\n",
      "[epoch:8,batch:839]:acc: 0.854390,loss:0.363473\n",
      "[epoch:8,batch:869]:acc: 0.854526,loss:0.361833\n",
      "[epoch:8,batch:899]:acc: 0.854514,loss:0.361478\n",
      "[epoch:8,batch:899]: val_loss:0.399482,val_acc:0.852390,val_total:4539\n",
      "[epoch:8,batch:929]:acc: 0.854671,loss:0.360707\n",
      "[epoch:8,batch:959]:acc: 0.854590,loss:0.360981\n",
      "[epoch:8,batch:989]:acc: 0.854545,loss:0.360705\n",
      "[epoch:8] :acc: 0.854431,loss:0.361221,lr:0.000100,patience:1\n",
      "[epoch:8]: val_loss:0.418822,val_acc:0.844900,\n",
      "Epoch 9/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000010\n",
      "[epoch:9,batch:29]:acc: 0.858333,loss:0.364581\n",
      "[epoch:9,batch:59]:acc: 0.848958,loss:0.378912\n",
      "[epoch:9,batch:89]:acc: 0.849306,loss:0.369420\n",
      "[epoch:9,batch:119]:acc: 0.844531,loss:0.380583\n",
      "[epoch:9,batch:149]:acc: 0.848542,loss:0.367279\n",
      "[epoch:9,batch:179]:acc: 0.844792,loss:0.380585\n",
      "[epoch:9,batch:209]:acc: 0.845685,loss:0.378978\n",
      "[epoch:9,batch:239]:acc: 0.847526,loss:0.375947\n",
      "[epoch:9,batch:269]:acc: 0.849190,loss:0.372154\n",
      "[epoch:9,batch:299]:acc: 0.850729,loss:0.368493\n",
      "[epoch:9,batch:299]: val_loss:0.402331,val_acc:0.847984,val_total:4539\n",
      "[epoch:9,batch:329]:acc: 0.851799,loss:0.362872\n",
      "[epoch:9,batch:359]:acc: 0.852778,loss:0.361758\n",
      "[epoch:9,batch:389]:acc: 0.853205,loss:0.359150\n",
      "[epoch:9,batch:419]:acc: 0.854241,loss:0.357883\n",
      "[epoch:9,batch:449]:acc: 0.853472,loss:0.358951\n",
      "[epoch:9,batch:479]:acc: 0.853581,loss:0.359495\n",
      "[epoch:9,batch:509]:acc: 0.853983,loss:0.358097\n",
      "[epoch:9,batch:539]:acc: 0.854398,loss:0.356079\n",
      "[epoch:9,batch:569]:acc: 0.855044,loss:0.354293\n",
      "[epoch:9,batch:599]:acc: 0.854010,loss:0.355332\n",
      "[epoch:9,batch:599]: val_loss:0.401396,val_acc:0.851950,val_total:4539\n",
      "[epoch:9,batch:629]:acc: 0.855060,loss:0.351964\n",
      "[epoch:9,batch:659]:acc: 0.855871,loss:0.351202\n",
      "[epoch:9,batch:689]:acc: 0.856522,loss:0.350927\n",
      "[epoch:9,batch:719]:acc: 0.856727,loss:0.350940\n",
      "[epoch:9,batch:749]:acc: 0.856500,loss:0.352405\n",
      "[epoch:9,batch:779]:acc: 0.856050,loss:0.352307\n",
      "[epoch:9,batch:809]:acc: 0.856327,loss:0.351476\n",
      "[epoch:9,batch:839]:acc: 0.856994,loss:0.349555\n",
      "[epoch:9,batch:869]:acc: 0.856142,loss:0.350487\n",
      "[epoch:9,batch:899]:acc: 0.856563,loss:0.350403\n",
      "[epoch:9,batch:899]: val_loss:0.403554,val_acc:0.848425,val_total:4539\n",
      "[epoch:9,batch:929]:acc: 0.856048,loss:0.350794\n",
      "[epoch:9,batch:959]:acc: 0.856836,loss:0.350715\n",
      "[epoch:9,batch:989]:acc: 0.856471,loss:0.350701\n",
      "[epoch:9] :acc: 0.856323,loss:0.350926,lr:0.000010,patience:0\n",
      "[epoch:9]: val_loss:0.399716,val_acc:0.852170,\n",
      "save new model loss,now loss is  0.3997156023979187\n",
      "save new model acc,now acc is  tensor(0.8522, device='cuda:0')\n",
      "Epoch 10/59\n",
      "----------\n",
      "[epoch:10,batch:29]:acc: 0.818750,loss:0.370099\n",
      "[epoch:10,batch:59]:acc: 0.834375,loss:0.356254\n",
      "[epoch:10,batch:89]:acc: 0.849306,loss:0.344590\n",
      "[epoch:10,batch:119]:acc: 0.851823,loss:0.335363\n",
      "[epoch:10,batch:149]:acc: 0.855417,loss:0.333351\n",
      "[epoch:10,batch:179]:acc: 0.859549,loss:0.327743\n",
      "[epoch:10,batch:209]:acc: 0.860863,loss:0.328604\n",
      "[epoch:10,batch:239]:acc: 0.863281,loss:0.327941\n",
      "[epoch:10,batch:269]:acc: 0.864815,loss:0.329863\n",
      "[epoch:10,batch:299]:acc: 0.865000,loss:0.329296\n",
      "[epoch:10,batch:299]: val_loss:0.404966,val_acc:0.850848,val_total:4539\n",
      "[epoch:10,batch:329]:acc: 0.863068,loss:0.331615\n",
      "[epoch:10,batch:359]:acc: 0.861719,loss:0.332883\n",
      "[epoch:10,batch:389]:acc: 0.859936,loss:0.333788\n",
      "[epoch:10,batch:419]:acc: 0.860640,loss:0.331265\n",
      "[epoch:10,batch:449]:acc: 0.861111,loss:0.329656\n",
      "[epoch:10,batch:479]:acc: 0.861784,loss:0.330014\n",
      "[epoch:10,batch:509]:acc: 0.862132,loss:0.331304\n",
      "[epoch:10,batch:539]:acc: 0.861690,loss:0.332758\n",
      "[epoch:10,batch:569]:acc: 0.861842,loss:0.332472\n",
      "[epoch:10,batch:599]:acc: 0.861250,loss:0.333703\n",
      "[epoch:10,batch:599]: val_loss:0.399191,val_acc:0.851729,val_total:4539\n",
      "[epoch:10,batch:629]:acc: 0.860665,loss:0.334363\n",
      "[epoch:10,batch:659]:acc: 0.861080,loss:0.334902\n",
      "[epoch:10,batch:689]:acc: 0.861685,loss:0.333044\n",
      "[epoch:10,batch:719]:acc: 0.861632,loss:0.332735\n",
      "[epoch:10,batch:749]:acc: 0.862833,loss:0.330543\n",
      "[epoch:10,batch:779]:acc: 0.862740,loss:0.330950\n",
      "[epoch:10,batch:809]:acc: 0.862731,loss:0.330633\n",
      "[epoch:10,batch:839]:acc: 0.862909,loss:0.329958\n",
      "[epoch:10,batch:869]:acc: 0.863757,loss:0.328289\n",
      "[epoch:10,batch:899]:acc: 0.863194,loss:0.328856\n",
      "[epoch:10,batch:899]: val_loss:0.399584,val_acc:0.849967,val_total:4539\n",
      "[epoch:10,batch:929]:acc: 0.863474,loss:0.328050\n",
      "[epoch:10,batch:959]:acc: 0.862598,loss:0.329441\n",
      "[epoch:10,batch:989]:acc: 0.862816,loss:0.328960\n",
      "[epoch:10] :acc: 0.862818,loss:0.328828,lr:0.000010,patience:0\n",
      "[epoch:10]: val_loss:0.399637,val_acc:0.853712,\n",
      "save new model loss,now loss is  0.39963749051094055\n",
      "save new model acc,now acc is  tensor(0.8537, device='cuda:0')\n",
      "Epoch 11/59\n",
      "----------\n",
      "[epoch:11,batch:29]:acc: 0.865625,loss:0.366545\n",
      "[epoch:11,batch:59]:acc: 0.865625,loss:0.356717\n",
      "[epoch:11,batch:89]:acc: 0.867708,loss:0.338526\n",
      "[epoch:11,batch:119]:acc: 0.864583,loss:0.342167\n",
      "[epoch:11,batch:149]:acc: 0.865833,loss:0.333850\n",
      "[epoch:11,batch:179]:acc: 0.867708,loss:0.329565\n",
      "[epoch:11,batch:209]:acc: 0.869196,loss:0.325932\n",
      "[epoch:11,batch:239]:acc: 0.869922,loss:0.325701\n",
      "[epoch:11,batch:269]:acc: 0.866088,loss:0.329705\n",
      "[epoch:11,batch:299]:acc: 0.866563,loss:0.326422\n",
      "[epoch:11,batch:299]: val_loss:0.392984,val_acc:0.850628,val_total:4539\n",
      "[epoch:11,batch:329]:acc: 0.867803,loss:0.324229\n",
      "[epoch:11,batch:359]:acc: 0.868490,loss:0.322358\n",
      "[epoch:11,batch:389]:acc: 0.869391,loss:0.321045\n",
      "[epoch:11,batch:419]:acc: 0.868229,loss:0.323859\n",
      "[epoch:11,batch:449]:acc: 0.868264,loss:0.322846\n",
      "[epoch:11,batch:479]:acc: 0.867643,loss:0.323605\n",
      "[epoch:11,batch:509]:acc: 0.867463,loss:0.324677\n",
      "[epoch:11,batch:539]:acc: 0.867361,loss:0.324502\n",
      "[epoch:11,batch:569]:acc: 0.867105,loss:0.325196\n",
      "[epoch:11,batch:599]:acc: 0.867448,loss:0.325023\n",
      "[epoch:11,batch:599]: val_loss:0.398764,val_acc:0.850187,val_total:4539\n",
      "[epoch:11,batch:629]:acc: 0.866865,loss:0.325544\n",
      "[epoch:11,batch:659]:acc: 0.867093,loss:0.324569\n",
      "[epoch:11,batch:689]:acc: 0.867391,loss:0.324610\n",
      "[epoch:11,batch:719]:acc: 0.866970,loss:0.324602\n",
      "[epoch:11,batch:749]:acc: 0.866750,loss:0.323809\n",
      "[epoch:11,batch:779]:acc: 0.866867,loss:0.322617\n",
      "[epoch:11,batch:809]:acc: 0.866821,loss:0.322972\n",
      "[epoch:11,batch:839]:acc: 0.866592,loss:0.322362\n",
      "[epoch:11,batch:869]:acc: 0.866990,loss:0.321609\n",
      "[epoch:11,batch:899]:acc: 0.867153,loss:0.320771\n",
      "[epoch:11,batch:899]: val_loss:0.396733,val_acc:0.855034,val_total:4539\n",
      "[epoch:11,batch:929]:acc: 0.866902,loss:0.320826\n",
      "[epoch:11,batch:959]:acc: 0.867090,loss:0.319987\n",
      "[epoch:11,batch:989]:acc: 0.867330,loss:0.319241\n",
      "[epoch:11] :acc: 0.867358,loss:0.319216,lr:0.000010,patience:0\n",
      "[epoch:11]: val_loss:0.404274,val_acc:0.850848,\n",
      "Epoch 12/59\n",
      "----------\n",
      "[epoch:12,batch:29]:acc: 0.858333,loss:0.332317\n",
      "[epoch:12,batch:59]:acc: 0.859375,loss:0.329848\n",
      "[epoch:12,batch:89]:acc: 0.853472,loss:0.337165\n",
      "[epoch:12,batch:119]:acc: 0.858594,loss:0.330128\n",
      "[epoch:12,batch:149]:acc: 0.862083,loss:0.320891\n",
      "[epoch:12,batch:179]:acc: 0.863889,loss:0.319199\n",
      "[epoch:12,batch:209]:acc: 0.862500,loss:0.315888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:12,batch:239]:acc: 0.862109,loss:0.314709\n",
      "[epoch:12,batch:269]:acc: 0.865046,loss:0.310415\n",
      "[epoch:12,batch:299]:acc: 0.865729,loss:0.312620\n",
      "[epoch:12,batch:299]: val_loss:0.403073,val_acc:0.848645,val_total:4539\n",
      "[epoch:12,batch:329]:acc: 0.866288,loss:0.313496\n",
      "[epoch:12,batch:359]:acc: 0.865191,loss:0.314718\n",
      "[epoch:12,batch:389]:acc: 0.864824,loss:0.317274\n",
      "[epoch:12,batch:419]:acc: 0.865923,loss:0.316628\n",
      "[epoch:12,batch:449]:acc: 0.866042,loss:0.314818\n",
      "[epoch:12,batch:479]:acc: 0.866471,loss:0.314110\n",
      "[epoch:12,batch:509]:acc: 0.866973,loss:0.312220\n",
      "[epoch:12,batch:539]:acc: 0.867477,loss:0.310318\n",
      "[epoch:12,batch:569]:acc: 0.866338,loss:0.314283\n",
      "[epoch:12,batch:599]:acc: 0.866719,loss:0.313692\n",
      "[epoch:12,batch:599]: val_loss:0.398726,val_acc:0.851950,val_total:4539\n",
      "[epoch:12,batch:629]:acc: 0.867361,loss:0.312367\n",
      "[epoch:12,batch:659]:acc: 0.867898,loss:0.312291\n",
      "[epoch:12,batch:689]:acc: 0.867980,loss:0.311529\n",
      "[epoch:12,batch:719]:acc: 0.868186,loss:0.311129\n",
      "[epoch:12,batch:749]:acc: 0.868208,loss:0.310617\n",
      "[epoch:12,batch:779]:acc: 0.867748,loss:0.310852\n",
      "[epoch:12,batch:809]:acc: 0.867554,loss:0.311044\n",
      "[epoch:12,batch:839]:acc: 0.868043,loss:0.310099\n",
      "[epoch:12,batch:869]:acc: 0.867565,loss:0.311290\n",
      "[epoch:12,batch:899]:acc: 0.867812,loss:0.311198\n",
      "[epoch:12,batch:899]: val_loss:0.392745,val_acc:0.856576,val_total:4539\n",
      "[epoch:12,batch:929]:acc: 0.867406,loss:0.311579\n",
      "[epoch:12,batch:959]:acc: 0.867188,loss:0.312359\n",
      "[epoch:12,batch:989]:acc: 0.867393,loss:0.311876\n",
      "[epoch:12] :acc: 0.867264,loss:0.312613,lr:0.000010,patience:1\n",
      "[epoch:12]: val_loss:0.396104,val_acc:0.853933,\n",
      "save new model loss,now loss is  0.3961043655872345\n",
      "save new model acc,now acc is  tensor(0.8539, device='cuda:0')\n",
      "Epoch 13/59\n",
      "----------\n",
      "[epoch:13,batch:29]:acc: 0.867708,loss:0.308266\n",
      "[epoch:13,batch:59]:acc: 0.870313,loss:0.300348\n",
      "[epoch:13,batch:89]:acc: 0.869444,loss:0.309717\n",
      "[epoch:13,batch:119]:acc: 0.868229,loss:0.306673\n",
      "[epoch:13,batch:149]:acc: 0.869583,loss:0.300130\n",
      "[epoch:13,batch:179]:acc: 0.871007,loss:0.298570\n",
      "[epoch:13,batch:209]:acc: 0.873214,loss:0.297289\n",
      "[epoch:13,batch:239]:acc: 0.872526,loss:0.304976\n",
      "[epoch:13,batch:269]:acc: 0.872801,loss:0.304218\n",
      "[epoch:13,batch:299]:acc: 0.871979,loss:0.304282\n",
      "[epoch:13,batch:299]: val_loss:0.396664,val_acc:0.853712,val_total:4539\n",
      "[epoch:13,batch:329]:acc: 0.871591,loss:0.305627\n",
      "[epoch:13,batch:359]:acc: 0.872830,loss:0.302712\n",
      "[epoch:13,batch:389]:acc: 0.871554,loss:0.305397\n",
      "[epoch:13,batch:419]:acc: 0.872917,loss:0.302775\n",
      "[epoch:13,batch:449]:acc: 0.872222,loss:0.302659\n",
      "[epoch:13,batch:479]:acc: 0.871745,loss:0.301419\n",
      "[epoch:13,batch:509]:acc: 0.872426,loss:0.300405\n",
      "[epoch:13,batch:539]:acc: 0.872512,loss:0.300452\n",
      "[epoch:13,batch:569]:acc: 0.872314,loss:0.301469\n",
      "[epoch:13,batch:599]:acc: 0.872292,loss:0.301113\n",
      "[epoch:13,batch:599]: val_loss:0.398161,val_acc:0.851950,val_total:4539\n",
      "[epoch:13,batch:629]:acc: 0.872073,loss:0.301194\n",
      "[epoch:13,batch:659]:acc: 0.872443,loss:0.300194\n",
      "[epoch:13,batch:689]:acc: 0.871966,loss:0.302142\n",
      "[epoch:13,batch:719]:acc: 0.872005,loss:0.301718\n",
      "[epoch:13,batch:749]:acc: 0.873167,loss:0.300163\n",
      "[epoch:13,batch:779]:acc: 0.873037,loss:0.300601\n",
      "[epoch:13,batch:809]:acc: 0.872647,loss:0.300830\n",
      "[epoch:13,batch:839]:acc: 0.872396,loss:0.301826\n",
      "[epoch:13,batch:869]:acc: 0.872522,loss:0.301029\n",
      "[epoch:13,batch:899]:acc: 0.872153,loss:0.301620\n",
      "[epoch:13,batch:899]: val_loss:0.397938,val_acc:0.851729,val_total:4539\n",
      "[epoch:13,batch:929]:acc: 0.871606,loss:0.302388\n",
      "[epoch:13,batch:959]:acc: 0.871940,loss:0.301161\n",
      "[epoch:13,batch:989]:acc: 0.872285,loss:0.300283\n",
      "[epoch:13] :acc: 0.872214,loss:0.300134,lr:0.000010,patience:0\n",
      "[epoch:13]: val_loss:0.401887,val_acc:0.850628,\n",
      "Epoch 14/59\n",
      "----------\n",
      "[epoch:14,batch:29]:acc: 0.868750,loss:0.298049\n",
      "[epoch:14,batch:59]:acc: 0.870833,loss:0.305983\n",
      "[epoch:14,batch:89]:acc: 0.878819,loss:0.289596\n",
      "[epoch:14,batch:119]:acc: 0.882031,loss:0.287265\n",
      "[epoch:14,batch:149]:acc: 0.879792,loss:0.291000\n",
      "[epoch:14,batch:179]:acc: 0.878993,loss:0.287799\n",
      "[epoch:14,batch:209]:acc: 0.879315,loss:0.287247\n",
      "[epoch:14,batch:239]:acc: 0.878646,loss:0.289842\n",
      "[epoch:14,batch:269]:acc: 0.879514,loss:0.288194\n",
      "[epoch:14,batch:299]:acc: 0.878854,loss:0.291316\n",
      "[epoch:14,batch:299]: val_loss:0.395242,val_acc:0.853712,val_total:4539\n",
      "[epoch:14,batch:329]:acc: 0.879356,loss:0.291999\n",
      "[epoch:14,batch:359]:acc: 0.878993,loss:0.292945\n",
      "[epoch:14,batch:389]:acc: 0.879087,loss:0.291636\n",
      "[epoch:14,batch:419]:acc: 0.877307,loss:0.294947\n",
      "[epoch:14,batch:449]:acc: 0.876667,loss:0.294551\n",
      "[epoch:14,batch:479]:acc: 0.875911,loss:0.296189\n",
      "[epoch:14,batch:509]:acc: 0.876103,loss:0.297139\n",
      "[epoch:14,batch:539]:acc: 0.875694,loss:0.299695\n",
      "[epoch:14,batch:569]:acc: 0.876042,loss:0.298578\n",
      "[epoch:14,batch:599]:acc: 0.875938,loss:0.297984\n",
      "[epoch:14,batch:599]: val_loss:0.394685,val_acc:0.855254,val_total:4539\n",
      "[epoch:14,batch:629]:acc: 0.875744,loss:0.297704\n",
      "[epoch:14,batch:659]:acc: 0.876136,loss:0.299039\n",
      "[epoch:14,batch:689]:acc: 0.875634,loss:0.300275\n",
      "[epoch:14,batch:719]:acc: 0.876389,loss:0.298717\n",
      "[epoch:14,batch:749]:acc: 0.876458,loss:0.298176\n",
      "[epoch:14,batch:779]:acc: 0.877003,loss:0.298262\n",
      "[epoch:14,batch:809]:acc: 0.877778,loss:0.296912\n",
      "[epoch:14,batch:839]:acc: 0.877604,loss:0.298233\n",
      "[epoch:14,batch:869]:acc: 0.877191,loss:0.298123\n",
      "[epoch:14,batch:899]:acc: 0.877222,loss:0.296997\n",
      "[epoch:14,batch:899]: val_loss:0.391252,val_acc:0.858339,val_total:4539\n",
      "[epoch:14,batch:929]:acc: 0.877587,loss:0.296087\n",
      "[epoch:14,batch:959]:acc: 0.877539,loss:0.294993\n",
      "[epoch:14,batch:989]:acc: 0.877746,loss:0.295024\n",
      "[epoch:14] :acc: 0.877668,loss:0.294763,lr:0.000010,patience:1\n",
      "[epoch:14]: val_loss:0.396626,val_acc:0.853933,\n",
      "Epoch 15/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000001\n",
      "[epoch:15,batch:29]:acc: 0.875000,loss:0.298206\n",
      "[epoch:15,batch:59]:acc: 0.872917,loss:0.305944\n",
      "[epoch:15,batch:89]:acc: 0.870833,loss:0.309806\n",
      "[epoch:15,batch:119]:acc: 0.870573,loss:0.314858\n",
      "[epoch:15,batch:149]:acc: 0.867500,loss:0.317579\n",
      "[epoch:15,batch:179]:acc: 0.868056,loss:0.317108\n",
      "[epoch:15,batch:209]:acc: 0.867560,loss:0.314488\n",
      "[epoch:15,batch:239]:acc: 0.867578,loss:0.314622\n",
      "[epoch:15,batch:269]:acc: 0.869444,loss:0.310798\n",
      "[epoch:15,batch:299]:acc: 0.870521,loss:0.308168\n",
      "[epoch:15,batch:299]: val_loss:0.393734,val_acc:0.854594,val_total:4539\n",
      "[epoch:15,batch:329]:acc: 0.871117,loss:0.308421\n",
      "[epoch:15,batch:359]:acc: 0.873437,loss:0.304219\n",
      "[epoch:15,batch:389]:acc: 0.872516,loss:0.304666\n",
      "[epoch:15,batch:419]:acc: 0.871726,loss:0.305563\n",
      "[epoch:15,batch:449]:acc: 0.872500,loss:0.305311\n",
      "[epoch:15,batch:479]:acc: 0.871615,loss:0.305255\n",
      "[epoch:15,batch:509]:acc: 0.871936,loss:0.303755\n",
      "[epoch:15,batch:539]:acc: 0.871701,loss:0.302519\n",
      "[epoch:15,batch:569]:acc: 0.871601,loss:0.300944\n",
      "[epoch:15,batch:599]:acc: 0.871198,loss:0.302675\n",
      "[epoch:15,batch:599]: val_loss:0.393275,val_acc:0.855475,val_total:4539\n",
      "[epoch:15,batch:629]:acc: 0.871577,loss:0.301051\n",
      "[epoch:15,batch:659]:acc: 0.871686,loss:0.301307\n",
      "[epoch:15,batch:689]:acc: 0.871332,loss:0.301046\n",
      "[epoch:15,batch:719]:acc: 0.870920,loss:0.301663\n",
      "[epoch:15,batch:749]:acc: 0.870875,loss:0.301962\n",
      "[epoch:15,batch:779]:acc: 0.871314,loss:0.301854\n",
      "[epoch:15,batch:809]:acc: 0.871103,loss:0.302121\n",
      "[epoch:15,batch:839]:acc: 0.871019,loss:0.301848\n",
      "[epoch:15,batch:869]:acc: 0.871157,loss:0.302030\n",
      "[epoch:15,batch:899]:acc: 0.871111,loss:0.302247\n",
      "[epoch:15,batch:899]: val_loss:0.396065,val_acc:0.853272,val_total:4539\n",
      "[epoch:15,batch:929]:acc: 0.870934,loss:0.302803\n",
      "[epoch:15,batch:959]:acc: 0.871191,loss:0.302388\n",
      "[epoch:15,batch:989]:acc: 0.871780,loss:0.300702\n",
      "[epoch:15] :acc: 0.871804,loss:0.300609,lr:0.000001,patience:0\n",
      "[epoch:15]: val_loss:0.398448,val_acc:0.855254,\n",
      "save new model acc,now acc is  tensor(0.8553, device='cuda:0')\n",
      "Epoch 16/59\n",
      "----------\n",
      "[epoch:16,batch:29]:acc: 0.864583,loss:0.293557\n",
      "[epoch:16,batch:59]:acc: 0.869271,loss:0.312139\n",
      "[epoch:16,batch:89]:acc: 0.867708,loss:0.316425\n",
      "[epoch:16,batch:119]:acc: 0.867448,loss:0.315928\n",
      "[epoch:16,batch:149]:acc: 0.867917,loss:0.316019\n",
      "[epoch:16,batch:179]:acc: 0.867708,loss:0.315494\n",
      "[epoch:16,batch:209]:acc: 0.867857,loss:0.311224\n",
      "[epoch:16,batch:239]:acc: 0.867448,loss:0.309270\n",
      "[epoch:16,batch:269]:acc: 0.867477,loss:0.310394\n",
      "[epoch:16,batch:299]:acc: 0.867917,loss:0.307958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:16,batch:299]: val_loss:0.393488,val_acc:0.853933,val_total:4539\n",
      "[epoch:16,batch:329]:acc: 0.869129,loss:0.307170\n",
      "[epoch:16,batch:359]:acc: 0.869358,loss:0.306453\n",
      "[epoch:16,batch:389]:acc: 0.869151,loss:0.305719\n",
      "[epoch:16,batch:419]:acc: 0.870238,loss:0.305391\n",
      "[epoch:16,batch:449]:acc: 0.870278,loss:0.305622\n",
      "[epoch:16,batch:479]:acc: 0.870443,loss:0.305089\n",
      "[epoch:16,batch:509]:acc: 0.870772,loss:0.304500\n",
      "[epoch:16,batch:539]:acc: 0.870313,loss:0.306419\n",
      "[epoch:16,batch:569]:acc: 0.870504,loss:0.305496\n",
      "[epoch:16,batch:599]:acc: 0.870781,loss:0.303067\n",
      "[epoch:16,batch:599]: val_loss:0.394981,val_acc:0.852390,val_total:4539\n",
      "[epoch:16,batch:629]:acc: 0.871181,loss:0.302404\n",
      "[epoch:16,batch:659]:acc: 0.872064,loss:0.301988\n",
      "[epoch:16,batch:689]:acc: 0.871558,loss:0.302911\n",
      "[epoch:16,batch:719]:acc: 0.871094,loss:0.303921\n",
      "[epoch:16,batch:749]:acc: 0.870792,loss:0.305364\n",
      "[epoch:16,batch:779]:acc: 0.870713,loss:0.303909\n",
      "[epoch:16,batch:809]:acc: 0.871026,loss:0.303249\n",
      "[epoch:16,batch:839]:acc: 0.871577,loss:0.301511\n",
      "[epoch:16,batch:869]:acc: 0.872198,loss:0.301077\n",
      "[epoch:16,batch:899]:acc: 0.871979,loss:0.301314\n",
      "[epoch:16,batch:899]: val_loss:0.393716,val_acc:0.852170,val_total:4539\n",
      "[epoch:16,batch:929]:acc: 0.872009,loss:0.301696\n",
      "[epoch:16,batch:959]:acc: 0.872363,loss:0.300994\n",
      "[epoch:16,batch:989]:acc: 0.872033,loss:0.301697\n",
      "[epoch:16] :acc: 0.872056,loss:0.301342,lr:0.000001,patience:1\n",
      "[epoch:16]: val_loss:0.394970,val_acc:0.855915,\n",
      "save new model loss,now loss is  0.39497026801109314\n",
      "save new model acc,now acc is  tensor(0.8559, device='cuda:0')\n",
      "Epoch 17/59\n",
      "----------\n",
      "[epoch:17,batch:29]:acc: 0.875000,loss:0.297661\n",
      "[epoch:17,batch:59]:acc: 0.869792,loss:0.295583\n",
      "[epoch:17,batch:89]:acc: 0.874653,loss:0.293551\n",
      "[epoch:17,batch:119]:acc: 0.874219,loss:0.292816\n",
      "[epoch:17,batch:149]:acc: 0.875417,loss:0.292043\n",
      "[epoch:17,batch:179]:acc: 0.874653,loss:0.293630\n",
      "[epoch:17,batch:209]:acc: 0.876190,loss:0.291469\n",
      "[epoch:17,batch:239]:acc: 0.877734,loss:0.290334\n",
      "[epoch:17,batch:269]:acc: 0.876389,loss:0.291428\n",
      "[epoch:17,batch:299]:acc: 0.875833,loss:0.293730\n",
      "[epoch:17,batch:299]: val_loss:0.397779,val_acc:0.851950,val_total:4539\n",
      "[epoch:17,batch:329]:acc: 0.875284,loss:0.295460\n",
      "[epoch:17,batch:359]:acc: 0.875781,loss:0.295899\n",
      "[epoch:17,batch:389]:acc: 0.876282,loss:0.295757\n",
      "[epoch:17,batch:419]:acc: 0.877679,loss:0.295249\n",
      "[epoch:17,batch:449]:acc: 0.875833,loss:0.297710\n",
      "[epoch:17,batch:479]:acc: 0.875521,loss:0.297845\n",
      "[epoch:17,batch:509]:acc: 0.875858,loss:0.296393\n",
      "[epoch:17,batch:539]:acc: 0.875116,loss:0.298110\n",
      "[epoch:17,batch:569]:acc: 0.875000,loss:0.297070\n",
      "[epoch:17,batch:599]:acc: 0.875000,loss:0.297750\n",
      "[epoch:17,batch:599]: val_loss:0.397293,val_acc:0.852170,val_total:4539\n",
      "[epoch:17,batch:629]:acc: 0.875099,loss:0.297415\n",
      "[epoch:17,batch:659]:acc: 0.874384,loss:0.298735\n",
      "[epoch:17,batch:689]:acc: 0.874139,loss:0.298614\n",
      "[epoch:17,batch:719]:acc: 0.874089,loss:0.298048\n",
      "[epoch:17,batch:749]:acc: 0.873875,loss:0.299253\n",
      "[epoch:17,batch:779]:acc: 0.874159,loss:0.298320\n",
      "[epoch:17,batch:809]:acc: 0.874653,loss:0.297031\n",
      "[epoch:17,batch:839]:acc: 0.874219,loss:0.297644\n",
      "[epoch:17,batch:869]:acc: 0.874533,loss:0.297234\n",
      "[epoch:17,batch:899]:acc: 0.874653,loss:0.297085\n",
      "[epoch:17,batch:899]: val_loss:0.395465,val_acc:0.854814,val_total:4539\n",
      "[epoch:17,batch:929]:acc: 0.874429,loss:0.297094\n",
      "[epoch:17,batch:959]:acc: 0.874479,loss:0.296816\n",
      "[epoch:17,batch:989]:acc: 0.874779,loss:0.296597\n",
      "[epoch:17] :acc: 0.874736,loss:0.296737,lr:0.000001,patience:0\n",
      "[epoch:17]: val_loss:0.397007,val_acc:0.851068,\n",
      "Epoch 18/59\n",
      "----------\n",
      "[epoch:18,batch:29]:acc: 0.859375,loss:0.304381\n",
      "[epoch:18,batch:59]:acc: 0.858333,loss:0.292095\n",
      "[epoch:18,batch:89]:acc: 0.863889,loss:0.286596\n",
      "[epoch:18,batch:119]:acc: 0.866146,loss:0.291211\n",
      "[epoch:18,batch:149]:acc: 0.865833,loss:0.296405\n",
      "[epoch:18,batch:179]:acc: 0.865799,loss:0.297817\n",
      "[epoch:18,batch:209]:acc: 0.868006,loss:0.298754\n",
      "[epoch:18,batch:239]:acc: 0.869922,loss:0.296540\n",
      "[epoch:18,batch:269]:acc: 0.869560,loss:0.295372\n",
      "[epoch:18,batch:299]:acc: 0.868021,loss:0.299326\n",
      "[epoch:18,batch:299]: val_loss:0.396439,val_acc:0.851729,val_total:4539\n",
      "[epoch:18,batch:329]:acc: 0.868466,loss:0.298842\n",
      "[epoch:18,batch:359]:acc: 0.868576,loss:0.299784\n",
      "[epoch:18,batch:389]:acc: 0.868670,loss:0.301250\n",
      "[epoch:18,batch:419]:acc: 0.868676,loss:0.302274\n",
      "[epoch:18,batch:449]:acc: 0.869167,loss:0.303012\n",
      "[epoch:18,batch:479]:acc: 0.869531,loss:0.302956\n",
      "[epoch:18,batch:509]:acc: 0.869608,loss:0.302550\n",
      "[epoch:18,batch:539]:acc: 0.869387,loss:0.302424\n",
      "[epoch:18,batch:569]:acc: 0.869792,loss:0.302374\n",
      "[epoch:18,batch:599]:acc: 0.869167,loss:0.303114\n",
      "[epoch:18,batch:599]: val_loss:0.394488,val_acc:0.856356,val_total:4539\n",
      "[epoch:18,batch:629]:acc: 0.870139,loss:0.300923\n",
      "[epoch:18,batch:659]:acc: 0.870975,loss:0.299890\n",
      "[epoch:18,batch:689]:acc: 0.871060,loss:0.298938\n",
      "[epoch:18,batch:719]:acc: 0.871267,loss:0.298020\n",
      "[epoch:18,batch:749]:acc: 0.871458,loss:0.298299\n",
      "[epoch:18,batch:779]:acc: 0.871635,loss:0.298091\n",
      "[epoch:18,batch:809]:acc: 0.871759,loss:0.297752\n",
      "[epoch:18,batch:839]:acc: 0.871912,loss:0.298659\n",
      "[epoch:18,batch:869]:acc: 0.872126,loss:0.298123\n",
      "[epoch:18,batch:899]:acc: 0.872153,loss:0.297613\n",
      "[epoch:18,batch:899]: val_loss:0.393654,val_acc:0.855695,val_total:4539\n",
      "[epoch:18,batch:929]:acc: 0.872480,loss:0.297589\n",
      "[epoch:18,batch:959]:acc: 0.872852,loss:0.296549\n",
      "[epoch:18,batch:989]:acc: 0.873011,loss:0.296607\n",
      "[epoch:18] :acc: 0.873002,loss:0.296854,lr:0.000001,patience:1\n",
      "[epoch:18]: val_loss:0.395555,val_acc:0.857678,\n",
      "save new model acc,now acc is  tensor(0.8577, device='cuda:0')\n",
      "Epoch 19/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:19,batch:29]:acc: 0.873958,loss:0.314138\n",
      "[epoch:19,batch:59]:acc: 0.878646,loss:0.301552\n",
      "[epoch:19,batch:89]:acc: 0.874653,loss:0.303440\n",
      "[epoch:19,batch:119]:acc: 0.875521,loss:0.309333\n",
      "[epoch:19,batch:149]:acc: 0.876875,loss:0.305380\n",
      "[epoch:19,batch:179]:acc: 0.877778,loss:0.302209\n",
      "[epoch:19,batch:209]:acc: 0.877827,loss:0.302300\n",
      "[epoch:19,batch:239]:acc: 0.875260,loss:0.304378\n",
      "[epoch:19,batch:269]:acc: 0.874421,loss:0.303898\n",
      "[epoch:19,batch:299]:acc: 0.873854,loss:0.305634\n",
      "[epoch:19,batch:299]: val_loss:0.394796,val_acc:0.854153,val_total:4539\n",
      "[epoch:19,batch:329]:acc: 0.875095,loss:0.302181\n",
      "[epoch:19,batch:359]:acc: 0.875434,loss:0.300596\n",
      "[epoch:19,batch:389]:acc: 0.874359,loss:0.300604\n",
      "[epoch:19,batch:419]:acc: 0.874107,loss:0.298864\n",
      "[epoch:19,batch:449]:acc: 0.875278,loss:0.296495\n",
      "[epoch:19,batch:479]:acc: 0.876107,loss:0.296216\n",
      "[epoch:19,batch:509]:acc: 0.875735,loss:0.294447\n",
      "[epoch:19,batch:539]:acc: 0.876215,loss:0.294083\n",
      "[epoch:19,batch:569]:acc: 0.876480,loss:0.293123\n",
      "[epoch:19,batch:599]:acc: 0.876458,loss:0.293454\n",
      "[epoch:19,batch:599]: val_loss:0.390754,val_acc:0.855254,val_total:4539\n",
      "[epoch:19,batch:629]:acc: 0.875595,loss:0.295643\n",
      "[epoch:19,batch:659]:acc: 0.875521,loss:0.295746\n",
      "[epoch:19,batch:689]:acc: 0.875136,loss:0.296337\n",
      "[epoch:19,batch:719]:acc: 0.874045,loss:0.298035\n",
      "[epoch:19,batch:749]:acc: 0.874750,loss:0.296001\n",
      "[epoch:19,batch:779]:acc: 0.874559,loss:0.296370\n",
      "[epoch:19,batch:809]:acc: 0.874151,loss:0.296796\n",
      "[epoch:19,batch:839]:acc: 0.874442,loss:0.296256\n",
      "[epoch:19,batch:869]:acc: 0.874174,loss:0.296726\n",
      "[epoch:19,batch:899]:acc: 0.874618,loss:0.295665\n",
      "[epoch:19,batch:899]: val_loss:0.396940,val_acc:0.853492,val_total:4539\n",
      "[epoch:19,batch:929]:acc: 0.874294,loss:0.296021\n",
      "[epoch:19,batch:959]:acc: 0.874154,loss:0.296719\n",
      "[epoch:19,batch:989]:acc: 0.873485,loss:0.297281\n",
      "[epoch:19] :acc: 0.873380,loss:0.299226,lr:0.000000,patience:0\n",
      "[epoch:19]: val_loss:0.404162,val_acc:0.850187,\n",
      "Epoch 20/59\n",
      "----------\n",
      "[epoch:20,batch:29]:acc: 0.877083,loss:0.306820\n",
      "[epoch:20,batch:59]:acc: 0.869792,loss:0.320895\n",
      "[epoch:20,batch:89]:acc: 0.867708,loss:0.317790\n",
      "[epoch:20,batch:119]:acc: 0.864583,loss:0.319476\n",
      "[epoch:20,batch:149]:acc: 0.863750,loss:0.319705\n",
      "[epoch:20,batch:179]:acc: 0.865972,loss:0.311426\n",
      "[epoch:20,batch:209]:acc: 0.870536,loss:0.307127\n",
      "[epoch:20,batch:239]:acc: 0.873047,loss:0.303748\n",
      "[epoch:20,batch:269]:acc: 0.872801,loss:0.304411\n",
      "[epoch:20,batch:299]:acc: 0.872500,loss:0.305072\n",
      "[epoch:20,batch:299]: val_loss:0.394753,val_acc:0.853051,val_total:4539\n",
      "[epoch:20,batch:329]:acc: 0.874148,loss:0.302807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:20,batch:359]:acc: 0.875608,loss:0.300039\n",
      "[epoch:20,batch:389]:acc: 0.874119,loss:0.302881\n",
      "[epoch:20,batch:419]:acc: 0.875149,loss:0.300281\n",
      "[epoch:20,batch:449]:acc: 0.874375,loss:0.301546\n",
      "[epoch:20,batch:479]:acc: 0.875195,loss:0.300841\n",
      "[epoch:20,batch:509]:acc: 0.875735,loss:0.298938\n",
      "[epoch:20,batch:539]:acc: 0.876157,loss:0.299359\n",
      "[epoch:20,batch:569]:acc: 0.876151,loss:0.299832\n",
      "[epoch:20,batch:599]:acc: 0.876406,loss:0.300149\n",
      "[epoch:20,batch:599]: val_loss:0.396479,val_acc:0.856356,val_total:4539\n",
      "[epoch:20,batch:629]:acc: 0.876587,loss:0.299436\n",
      "[epoch:20,batch:659]:acc: 0.876894,loss:0.299132\n",
      "[epoch:20,batch:689]:acc: 0.877400,loss:0.298977\n",
      "[epoch:20,batch:719]:acc: 0.876519,loss:0.301486\n",
      "[epoch:20,batch:749]:acc: 0.876708,loss:0.301160\n",
      "[epoch:20,batch:779]:acc: 0.877163,loss:0.300169\n",
      "[epoch:20,batch:809]:acc: 0.877083,loss:0.300136\n",
      "[epoch:20,batch:839]:acc: 0.876823,loss:0.299767\n",
      "[epoch:20,batch:869]:acc: 0.876545,loss:0.300162\n",
      "[epoch:20,batch:899]:acc: 0.876667,loss:0.299071\n",
      "[epoch:20,batch:899]: val_loss:0.398604,val_acc:0.851950,val_total:4539\n",
      "[epoch:20,batch:929]:acc: 0.876478,loss:0.298873\n",
      "[epoch:20,batch:959]:acc: 0.876042,loss:0.299086\n",
      "[epoch:20,batch:989]:acc: 0.875915,loss:0.298890\n",
      "[epoch:20] :acc: 0.875903,loss:0.299269,lr:0.000000,patience:1\n",
      "[epoch:20]: val_loss:0.393655,val_acc:0.852390,\n",
      "save new model loss,now loss is  0.3936554491519928\n",
      "Epoch 21/59\n",
      "----------\n",
      "[epoch:21,batch:29]:acc: 0.878125,loss:0.285337\n",
      "[epoch:21,batch:59]:acc: 0.878646,loss:0.293786\n",
      "[epoch:21,batch:89]:acc: 0.880556,loss:0.297887\n",
      "[epoch:21,batch:119]:acc: 0.883073,loss:0.286394\n",
      "[epoch:21,batch:149]:acc: 0.880833,loss:0.289927\n",
      "[epoch:21,batch:179]:acc: 0.878299,loss:0.289672\n",
      "[epoch:21,batch:209]:acc: 0.878274,loss:0.287870\n",
      "[epoch:21,batch:239]:acc: 0.880599,loss:0.288936\n",
      "[epoch:21,batch:269]:acc: 0.880787,loss:0.288430\n",
      "[epoch:21,batch:299]:acc: 0.880313,loss:0.290282\n",
      "[epoch:21,batch:299]: val_loss:0.396711,val_acc:0.855915,val_total:4539\n",
      "[epoch:21,batch:329]:acc: 0.878693,loss:0.291891\n",
      "[epoch:21,batch:359]:acc: 0.877431,loss:0.292307\n",
      "[epoch:21,batch:389]:acc: 0.877724,loss:0.294101\n",
      "[epoch:21,batch:419]:acc: 0.877976,loss:0.293200\n",
      "[epoch:21,batch:449]:acc: 0.877361,loss:0.294655\n",
      "[epoch:21,batch:479]:acc: 0.875977,loss:0.295042\n",
      "[epoch:21,batch:509]:acc: 0.876716,loss:0.293155\n",
      "[epoch:21,batch:539]:acc: 0.876620,loss:0.294524\n",
      "[epoch:21,batch:569]:acc: 0.875219,loss:0.296330\n",
      "[epoch:21,batch:599]:acc: 0.875052,loss:0.295353\n",
      "[epoch:21,batch:599]: val_loss:0.395385,val_acc:0.852611,val_total:4539\n",
      "[epoch:21,batch:629]:acc: 0.875149,loss:0.296772\n",
      "[epoch:21,batch:659]:acc: 0.875426,loss:0.295672\n",
      "[epoch:21,batch:689]:acc: 0.875317,loss:0.297047\n",
      "[epoch:21,batch:719]:acc: 0.874523,loss:0.297806\n",
      "[epoch:21,batch:749]:acc: 0.874250,loss:0.298205\n",
      "[epoch:21,batch:779]:acc: 0.874599,loss:0.297275\n",
      "[epoch:21,batch:809]:acc: 0.874421,loss:0.296834\n",
      "[epoch:21,batch:839]:acc: 0.874330,loss:0.297153\n",
      "[epoch:21,batch:869]:acc: 0.874246,loss:0.296801\n",
      "[epoch:21,batch:899]:acc: 0.874201,loss:0.296872\n",
      "[epoch:21,batch:899]: val_loss:0.395763,val_acc:0.853712,val_total:4539\n",
      "[epoch:21,batch:929]:acc: 0.873958,loss:0.296878\n",
      "[epoch:21,batch:959]:acc: 0.873730,loss:0.296842\n",
      "[epoch:21,batch:989]:acc: 0.873958,loss:0.296709\n",
      "[epoch:21] :acc: 0.873916,loss:0.296816,lr:0.000000,patience:0\n",
      "[epoch:21]: val_loss:0.395875,val_acc:0.855915,\n",
      "Epoch 22/59\n",
      "----------\n",
      "[epoch:22,batch:29]:acc: 0.872917,loss:0.315811\n",
      "[epoch:22,batch:59]:acc: 0.878125,loss:0.311289\n",
      "[epoch:22,batch:89]:acc: 0.879167,loss:0.297866\n",
      "[epoch:22,batch:119]:acc: 0.877344,loss:0.302223\n",
      "[epoch:22,batch:149]:acc: 0.878542,loss:0.302752\n",
      "[epoch:22,batch:179]:acc: 0.876563,loss:0.301345\n",
      "[epoch:22,batch:209]:acc: 0.874851,loss:0.300757\n",
      "[epoch:22,batch:239]:acc: 0.873568,loss:0.303434\n",
      "[epoch:22,batch:269]:acc: 0.870949,loss:0.309865\n",
      "[epoch:22,batch:299]:acc: 0.870521,loss:0.309206\n",
      "[epoch:22,batch:299]: val_loss:0.395751,val_acc:0.852170,val_total:4539\n",
      "[epoch:22,batch:329]:acc: 0.870265,loss:0.310006\n",
      "[epoch:22,batch:359]:acc: 0.871615,loss:0.306471\n",
      "[epoch:22,batch:389]:acc: 0.871875,loss:0.307406\n",
      "[epoch:22,batch:419]:acc: 0.870982,loss:0.308486\n",
      "[epoch:22,batch:449]:acc: 0.871944,loss:0.305714\n",
      "[epoch:22,batch:479]:acc: 0.873372,loss:0.302687\n",
      "[epoch:22,batch:509]:acc: 0.873897,loss:0.302297\n",
      "[epoch:22,batch:539]:acc: 0.874306,loss:0.301190\n",
      "[epoch:22,batch:569]:acc: 0.874397,loss:0.300763\n",
      "[epoch:22,batch:599]:acc: 0.874271,loss:0.301288\n",
      "[epoch:22,batch:599]: val_loss:0.390205,val_acc:0.856136,val_total:4539\n",
      "[epoch:22,batch:629]:acc: 0.874702,loss:0.301661\n",
      "[epoch:22,batch:659]:acc: 0.874432,loss:0.302358\n",
      "[epoch:22,batch:689]:acc: 0.874819,loss:0.300883\n",
      "[epoch:22,batch:719]:acc: 0.874609,loss:0.301313\n",
      "[epoch:22,batch:749]:acc: 0.874042,loss:0.302518\n",
      "[epoch:22,batch:779]:acc: 0.874119,loss:0.303077\n",
      "[epoch:22,batch:809]:acc: 0.874421,loss:0.302030\n",
      "[epoch:22,batch:839]:acc: 0.873921,loss:0.302619\n",
      "[epoch:22,batch:869]:acc: 0.874174,loss:0.302159\n",
      "[epoch:22,batch:899]:acc: 0.874132,loss:0.301178\n",
      "[epoch:22,batch:899]: val_loss:0.395201,val_acc:0.854373,val_total:4539\n",
      "[epoch:22,batch:929]:acc: 0.874395,loss:0.301151\n",
      "[epoch:22,batch:959]:acc: 0.874772,loss:0.300243\n",
      "[epoch:22,batch:989]:acc: 0.874148,loss:0.300244\n",
      "[epoch:22] :acc: 0.873948,loss:0.300875,lr:0.000000,patience:1\n",
      "[epoch:22]: val_loss:0.391689,val_acc:0.855915,\n",
      "save new model loss,now loss is  0.39168861508369446\n",
      "Epoch 23/59\n",
      "----------\n",
      "[epoch:23,batch:29]:acc: 0.887500,loss:0.268526\n",
      "[epoch:23,batch:59]:acc: 0.886458,loss:0.282373\n",
      "[epoch:23,batch:89]:acc: 0.882639,loss:0.280290\n",
      "[epoch:23,batch:119]:acc: 0.879948,loss:0.283874\n",
      "[epoch:23,batch:149]:acc: 0.876875,loss:0.290199\n",
      "[epoch:23,batch:179]:acc: 0.876042,loss:0.288383\n",
      "[epoch:23,batch:209]:acc: 0.874405,loss:0.295598\n",
      "[epoch:23,batch:239]:acc: 0.875651,loss:0.292099\n",
      "[epoch:23,batch:269]:acc: 0.877546,loss:0.289617\n",
      "[epoch:23,batch:299]:acc: 0.877604,loss:0.289519\n",
      "[epoch:23,batch:299]: val_loss:0.395680,val_acc:0.855915,val_total:4539\n",
      "[epoch:23,batch:329]:acc: 0.876705,loss:0.291312\n",
      "[epoch:23,batch:359]:acc: 0.876215,loss:0.293498\n",
      "[epoch:23,batch:389]:acc: 0.875401,loss:0.298071\n",
      "[epoch:23,batch:419]:acc: 0.874702,loss:0.299016\n",
      "[epoch:23,batch:449]:acc: 0.874931,loss:0.298383\n",
      "[epoch:23,batch:479]:acc: 0.874609,loss:0.297759\n",
      "[epoch:23,batch:509]:acc: 0.874939,loss:0.297715\n",
      "[epoch:23,batch:539]:acc: 0.875752,loss:0.297039\n",
      "[epoch:23,batch:569]:acc: 0.875822,loss:0.295652\n",
      "[epoch:23,batch:599]:acc: 0.875104,loss:0.296680\n",
      "[epoch:23,batch:599]: val_loss:0.393052,val_acc:0.854153,val_total:4539\n",
      "[epoch:23,batch:629]:acc: 0.874306,loss:0.298161\n",
      "[epoch:23,batch:659]:acc: 0.875095,loss:0.296668\n",
      "[epoch:23,batch:689]:acc: 0.875634,loss:0.295232\n",
      "[epoch:23,batch:719]:acc: 0.875434,loss:0.295392\n",
      "[epoch:23,batch:749]:acc: 0.874917,loss:0.295842\n",
      "[epoch:23,batch:779]:acc: 0.875200,loss:0.295878\n",
      "[epoch:23,batch:809]:acc: 0.874730,loss:0.296258\n",
      "[epoch:23,batch:839]:acc: 0.874814,loss:0.296341\n",
      "[epoch:23,batch:869]:acc: 0.874856,loss:0.296420\n",
      "[epoch:23,batch:899]:acc: 0.875799,loss:0.295351\n",
      "[epoch:23,batch:899]: val_loss:0.395233,val_acc:0.855034,val_total:4539\n",
      "[epoch:23,batch:929]:acc: 0.875672,loss:0.295684\n",
      "[epoch:23,batch:959]:acc: 0.875260,loss:0.296441\n",
      "[epoch:23,batch:989]:acc: 0.874874,loss:0.296964\n",
      "[epoch:23] :acc: 0.874925,loss:0.296723,lr:0.000000,patience:0\n",
      "[epoch:23]: val_loss:0.393555,val_acc:0.856576,\n",
      "Epoch 24/59\n",
      "----------\n",
      "[epoch:24,batch:29]:acc: 0.882292,loss:0.292078\n",
      "[epoch:24,batch:59]:acc: 0.868229,loss:0.325859\n",
      "[epoch:24,batch:89]:acc: 0.870833,loss:0.322252\n",
      "[epoch:24,batch:119]:acc: 0.873958,loss:0.320998\n",
      "[epoch:24,batch:149]:acc: 0.873958,loss:0.316240\n",
      "[epoch:24,batch:179]:acc: 0.876042,loss:0.307727\n",
      "[epoch:24,batch:209]:acc: 0.876935,loss:0.303894\n",
      "[epoch:24,batch:239]:acc: 0.876432,loss:0.302631\n",
      "[epoch:24,batch:269]:acc: 0.878704,loss:0.298091\n",
      "[epoch:24,batch:299]:acc: 0.878958,loss:0.298134\n",
      "[epoch:24,batch:299]: val_loss:0.392912,val_acc:0.857458,val_total:4539\n",
      "[epoch:24,batch:329]:acc: 0.878598,loss:0.297790\n",
      "[epoch:24,batch:359]:acc: 0.878646,loss:0.298356\n",
      "[epoch:24,batch:389]:acc: 0.878125,loss:0.299737\n",
      "[epoch:24,batch:419]:acc: 0.877604,loss:0.301312\n",
      "[epoch:24,batch:449]:acc: 0.877778,loss:0.300569\n",
      "[epoch:24,batch:479]:acc: 0.878255,loss:0.297875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:24,batch:509]:acc: 0.878002,loss:0.297491\n",
      "[epoch:24,batch:539]:acc: 0.877546,loss:0.296728\n",
      "[epoch:24,batch:569]:acc: 0.878289,loss:0.296444\n",
      "[epoch:24,batch:599]:acc: 0.878542,loss:0.296121\n",
      "[epoch:24,batch:599]: val_loss:0.393390,val_acc:0.855475,val_total:4539\n",
      "[epoch:24,batch:629]:acc: 0.877927,loss:0.295959\n",
      "[epoch:24,batch:659]:acc: 0.877178,loss:0.296124\n",
      "[epoch:24,batch:689]:acc: 0.876585,loss:0.296722\n",
      "[epoch:24,batch:719]:acc: 0.875694,loss:0.299095\n",
      "[epoch:24,batch:749]:acc: 0.876375,loss:0.297487\n",
      "[epoch:24,batch:779]:acc: 0.876482,loss:0.297372\n",
      "[epoch:24,batch:809]:acc: 0.876505,loss:0.297667\n",
      "[epoch:24,batch:839]:acc: 0.876079,loss:0.297696\n",
      "[epoch:24,batch:869]:acc: 0.876185,loss:0.297456\n",
      "[epoch:24,batch:899]:acc: 0.876146,loss:0.297403\n",
      "[epoch:24,batch:899]: val_loss:0.395079,val_acc:0.854153,val_total:4539\n",
      "[epoch:24,batch:929]:acc: 0.876008,loss:0.296833\n",
      "[epoch:24,batch:959]:acc: 0.875814,loss:0.296337\n",
      "[epoch:24,batch:989]:acc: 0.875600,loss:0.296273\n",
      "[epoch:24] :acc: 0.875682,loss:0.296121,lr:0.000000,patience:1\n",
      "[epoch:24]: val_loss:0.392082,val_acc:0.856356,\n",
      "Epoch 25/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:25,batch:29]:acc: 0.858333,loss:0.308913\n",
      "[epoch:25,batch:59]:acc: 0.866667,loss:0.300172\n",
      "[epoch:25,batch:89]:acc: 0.869792,loss:0.291952\n",
      "[epoch:25,batch:119]:acc: 0.869531,loss:0.285832\n",
      "[epoch:25,batch:149]:acc: 0.868125,loss:0.286019\n",
      "[epoch:25,batch:179]:acc: 0.866667,loss:0.295193\n",
      "[epoch:25,batch:209]:acc: 0.867113,loss:0.297879\n",
      "[epoch:25,batch:239]:acc: 0.867448,loss:0.303793\n",
      "[epoch:25,batch:269]:acc: 0.867014,loss:0.308003\n",
      "[epoch:25,batch:299]:acc: 0.867917,loss:0.306970\n",
      "[epoch:25,batch:299]: val_loss:0.394771,val_acc:0.853712,val_total:4539\n",
      "[epoch:25,batch:329]:acc: 0.868087,loss:0.304876\n",
      "[epoch:25,batch:359]:acc: 0.867969,loss:0.305835\n",
      "[epoch:25,batch:389]:acc: 0.867468,loss:0.307731\n",
      "[epoch:25,batch:419]:acc: 0.869420,loss:0.303282\n",
      "[epoch:25,batch:449]:acc: 0.870972,loss:0.301514\n",
      "[epoch:25,batch:479]:acc: 0.870833,loss:0.301978\n",
      "[epoch:25,batch:509]:acc: 0.871140,loss:0.300635\n",
      "[epoch:25,batch:539]:acc: 0.871181,loss:0.300568\n",
      "[epoch:25,batch:569]:acc: 0.871162,loss:0.300939\n",
      "[epoch:25,batch:599]:acc: 0.871563,loss:0.301130\n",
      "[epoch:25,batch:599]: val_loss:0.392829,val_acc:0.854814,val_total:4539\n",
      "[epoch:25,batch:629]:acc: 0.870784,loss:0.302225\n",
      "[epoch:25,batch:659]:acc: 0.870975,loss:0.301363\n",
      "[epoch:25,batch:689]:acc: 0.871105,loss:0.301217\n",
      "[epoch:25,batch:719]:acc: 0.870964,loss:0.301054\n",
      "[epoch:25,batch:749]:acc: 0.871583,loss:0.299457\n",
      "[epoch:25,batch:779]:acc: 0.871915,loss:0.299631\n",
      "[epoch:25,batch:809]:acc: 0.871721,loss:0.300061\n",
      "[epoch:25,batch:839]:acc: 0.871205,loss:0.301455\n",
      "[epoch:25,batch:869]:acc: 0.871336,loss:0.301680\n",
      "[epoch:25,batch:899]:acc: 0.871840,loss:0.300333\n",
      "[epoch:25,batch:899]: val_loss:0.393906,val_acc:0.854153,val_total:4539\n",
      "[epoch:25,batch:929]:acc: 0.872110,loss:0.300630\n",
      "[epoch:25,batch:959]:acc: 0.871940,loss:0.300306\n",
      "[epoch:25,batch:989]:acc: 0.871843,loss:0.300563\n",
      "[epoch:25] :acc: 0.871709,loss:0.301218,lr:0.000000,patience:0\n",
      "[epoch:25]: val_loss:0.399219,val_acc:0.852170,\n",
      "Epoch 26/59\n",
      "----------\n",
      "[epoch:26,batch:29]:acc: 0.891667,loss:0.247905\n",
      "[epoch:26,batch:59]:acc: 0.886458,loss:0.259643\n",
      "[epoch:26,batch:89]:acc: 0.878125,loss:0.284574\n",
      "[epoch:26,batch:119]:acc: 0.873698,loss:0.294980\n",
      "[epoch:26,batch:149]:acc: 0.873750,loss:0.294315\n",
      "[epoch:26,batch:179]:acc: 0.871528,loss:0.302120\n",
      "[epoch:26,batch:209]:acc: 0.871429,loss:0.303185\n",
      "[epoch:26,batch:239]:acc: 0.871484,loss:0.304347\n",
      "[epoch:26,batch:269]:acc: 0.870370,loss:0.305773\n",
      "[epoch:26,batch:299]:acc: 0.872083,loss:0.300383\n",
      "[epoch:26,batch:299]: val_loss:0.393751,val_acc:0.854814,val_total:4539\n",
      "[epoch:26,batch:329]:acc: 0.872633,loss:0.299818\n",
      "[epoch:26,batch:359]:acc: 0.871441,loss:0.301697\n",
      "[epoch:26,batch:389]:acc: 0.871635,loss:0.302369\n",
      "[epoch:26,batch:419]:acc: 0.871205,loss:0.303664\n",
      "[epoch:26,batch:449]:acc: 0.870347,loss:0.303286\n",
      "[epoch:26,batch:479]:acc: 0.870443,loss:0.304291\n",
      "[epoch:26,batch:509]:acc: 0.870466,loss:0.304423\n",
      "[epoch:26,batch:539]:acc: 0.870949,loss:0.303505\n",
      "[epoch:26,batch:569]:acc: 0.872588,loss:0.299609\n",
      "[epoch:26,batch:599]:acc: 0.872812,loss:0.298922\n",
      "[epoch:26,batch:599]: val_loss:0.396102,val_acc:0.854594,val_total:4539\n",
      "[epoch:26,batch:629]:acc: 0.872371,loss:0.299309\n",
      "[epoch:26,batch:659]:acc: 0.872159,loss:0.300680\n",
      "[epoch:26,batch:689]:acc: 0.871332,loss:0.302555\n",
      "[epoch:26,batch:719]:acc: 0.871615,loss:0.303660\n",
      "[epoch:26,batch:749]:acc: 0.871208,loss:0.305606\n",
      "[epoch:26,batch:779]:acc: 0.871434,loss:0.304043\n",
      "[epoch:26,batch:809]:acc: 0.871721,loss:0.303297\n",
      "[epoch:26,batch:839]:acc: 0.872247,loss:0.303002\n",
      "[epoch:26,batch:869]:acc: 0.871983,loss:0.303287\n",
      "[epoch:26,batch:899]:acc: 0.872083,loss:0.302991\n",
      "[epoch:26,batch:899]: val_loss:0.397890,val_acc:0.850848,val_total:4539\n",
      "[epoch:26,batch:929]:acc: 0.871976,loss:0.303134\n",
      "[epoch:26,batch:959]:acc: 0.872331,loss:0.302391\n",
      "[epoch:26,batch:989]:acc: 0.871938,loss:0.302302\n",
      "[epoch:26] :acc: 0.871898,loss:0.302384,lr:0.000000,patience:1\n",
      "[epoch:26]: val_loss:0.394257,val_acc:0.854153,\n",
      "Epoch 27/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:27,batch:29]:acc: 0.872917,loss:0.317391\n",
      "[epoch:27,batch:59]:acc: 0.862500,loss:0.316394\n",
      "[epoch:27,batch:89]:acc: 0.866319,loss:0.318067\n",
      "[epoch:27,batch:119]:acc: 0.871094,loss:0.305479\n",
      "[epoch:27,batch:149]:acc: 0.872083,loss:0.306357\n",
      "[epoch:27,batch:179]:acc: 0.869792,loss:0.301568\n",
      "[epoch:27,batch:209]:acc: 0.872619,loss:0.298731\n",
      "[epoch:27,batch:239]:acc: 0.872786,loss:0.300510\n",
      "[epoch:27,batch:269]:acc: 0.871875,loss:0.306315\n",
      "[epoch:27,batch:299]:acc: 0.872500,loss:0.304171\n",
      "[epoch:27,batch:299]: val_loss:0.399487,val_acc:0.850848,val_total:4539\n",
      "[epoch:27,batch:329]:acc: 0.872633,loss:0.305760\n",
      "[epoch:27,batch:359]:acc: 0.871962,loss:0.304613\n",
      "[epoch:27,batch:389]:acc: 0.873077,loss:0.301511\n",
      "[epoch:27,batch:419]:acc: 0.872470,loss:0.302463\n",
      "[epoch:27,batch:449]:acc: 0.873264,loss:0.300358\n",
      "[epoch:27,batch:479]:acc: 0.873177,loss:0.298164\n",
      "[epoch:27,batch:509]:acc: 0.873284,loss:0.296837\n",
      "[epoch:27,batch:539]:acc: 0.873090,loss:0.297032\n",
      "[epoch:27,batch:569]:acc: 0.872917,loss:0.296651\n",
      "[epoch:27,batch:599]:acc: 0.872083,loss:0.297854\n",
      "[epoch:27,batch:599]: val_loss:0.394600,val_acc:0.854594,val_total:4539\n",
      "[epoch:27,batch:629]:acc: 0.872222,loss:0.297098\n",
      "[epoch:27,batch:659]:acc: 0.872396,loss:0.296247\n",
      "[epoch:27,batch:689]:acc: 0.872871,loss:0.296829\n",
      "[epoch:27,batch:719]:acc: 0.873394,loss:0.295605\n",
      "[epoch:27,batch:749]:acc: 0.872667,loss:0.297876\n",
      "[epoch:27,batch:779]:acc: 0.872636,loss:0.298587\n",
      "[epoch:27,batch:809]:acc: 0.872415,loss:0.299373\n",
      "[epoch:27,batch:839]:acc: 0.872805,loss:0.299521\n",
      "[epoch:27,batch:869]:acc: 0.872881,loss:0.298917\n",
      "[epoch:27,batch:899]:acc: 0.872639,loss:0.299065\n",
      "[epoch:27,batch:899]: val_loss:0.390913,val_acc:0.857678,val_total:4539\n",
      "[epoch:27,batch:929]:acc: 0.872345,loss:0.299659\n",
      "[epoch:27,batch:959]:acc: 0.872493,loss:0.299975\n",
      "[epoch:27,batch:989]:acc: 0.872475,loss:0.299527\n",
      "[epoch:27] :acc: 0.872403,loss:0.299594,lr:0.000000,patience:0\n",
      "[epoch:27]: val_loss:0.401864,val_acc:0.851950,\n",
      "Epoch 28/59\n",
      "----------\n",
      "[epoch:28,batch:29]:acc: 0.870833,loss:0.300294\n",
      "[epoch:28,batch:59]:acc: 0.877604,loss:0.284231\n",
      "[epoch:28,batch:89]:acc: 0.872917,loss:0.292713\n",
      "[epoch:28,batch:119]:acc: 0.868490,loss:0.301114\n",
      "[epoch:28,batch:149]:acc: 0.872083,loss:0.294240\n",
      "[epoch:28,batch:179]:acc: 0.871528,loss:0.298028\n",
      "[epoch:28,batch:209]:acc: 0.871577,loss:0.299255\n",
      "[epoch:28,batch:239]:acc: 0.873047,loss:0.295651\n",
      "[epoch:28,batch:269]:acc: 0.874306,loss:0.295396\n",
      "[epoch:28,batch:299]:acc: 0.874583,loss:0.298873\n",
      "[epoch:28,batch:299]: val_loss:0.392919,val_acc:0.854814,val_total:4539\n",
      "[epoch:28,batch:329]:acc: 0.874621,loss:0.299265\n",
      "[epoch:28,batch:359]:acc: 0.875521,loss:0.297004\n",
      "[epoch:28,batch:389]:acc: 0.875000,loss:0.298175\n",
      "[epoch:28,batch:419]:acc: 0.874628,loss:0.298466\n",
      "[epoch:28,batch:449]:acc: 0.874653,loss:0.298608\n",
      "[epoch:28,batch:479]:acc: 0.875716,loss:0.296863\n",
      "[epoch:28,batch:509]:acc: 0.875184,loss:0.298380\n",
      "[epoch:28,batch:539]:acc: 0.874190,loss:0.301381\n",
      "[epoch:28,batch:569]:acc: 0.874287,loss:0.300346\n",
      "[epoch:28,batch:599]:acc: 0.874062,loss:0.301926\n",
      "[epoch:28,batch:599]: val_loss:0.395846,val_acc:0.852390,val_total:4539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:28,batch:629]:acc: 0.873859,loss:0.302438\n",
      "[epoch:28,batch:659]:acc: 0.873532,loss:0.301850\n",
      "[epoch:28,batch:689]:acc: 0.873687,loss:0.301464\n",
      "[epoch:28,batch:719]:acc: 0.873177,loss:0.302801\n",
      "[epoch:28,batch:749]:acc: 0.872958,loss:0.302610\n",
      "[epoch:28,batch:779]:acc: 0.873518,loss:0.302228\n",
      "[epoch:28,batch:809]:acc: 0.873727,loss:0.301122\n",
      "[epoch:28,batch:839]:acc: 0.873437,loss:0.301860\n",
      "[epoch:28,batch:869]:acc: 0.874425,loss:0.299664\n",
      "[epoch:28,batch:899]:acc: 0.874340,loss:0.299193\n",
      "[epoch:28,batch:899]: val_loss:0.392853,val_acc:0.853051,val_total:4539\n",
      "[epoch:28,batch:929]:acc: 0.873992,loss:0.299724\n",
      "[epoch:28,batch:959]:acc: 0.874251,loss:0.299140\n",
      "[epoch:28,batch:989]:acc: 0.874337,loss:0.299108\n",
      "[epoch:28] :acc: 0.874263,loss:0.299027,lr:0.000000,patience:1\n",
      "[epoch:28]: val_loss:0.394043,val_acc:0.856576,\n",
      "Epoch 29/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:29,batch:29]:acc: 0.886458,loss:0.251116\n",
      "[epoch:29,batch:59]:acc: 0.881250,loss:0.271795\n",
      "[epoch:29,batch:89]:acc: 0.873264,loss:0.295779\n",
      "[epoch:29,batch:119]:acc: 0.873177,loss:0.294169\n",
      "[epoch:29,batch:149]:acc: 0.870625,loss:0.302701\n",
      "[epoch:29,batch:179]:acc: 0.870313,loss:0.303102\n",
      "[epoch:29,batch:209]:acc: 0.867262,loss:0.307394\n",
      "[epoch:29,batch:239]:acc: 0.867188,loss:0.307347\n",
      "[epoch:29,batch:269]:acc: 0.867014,loss:0.307459\n",
      "[epoch:29,batch:299]:acc: 0.868542,loss:0.307827\n",
      "[epoch:29,batch:299]: val_loss:0.391061,val_acc:0.856136,val_total:4539\n",
      "[epoch:29,batch:329]:acc: 0.868087,loss:0.306011\n",
      "[epoch:29,batch:359]:acc: 0.868056,loss:0.305983\n",
      "[epoch:29,batch:389]:acc: 0.869151,loss:0.305883\n",
      "[epoch:29,batch:419]:acc: 0.870982,loss:0.302750\n",
      "[epoch:29,batch:449]:acc: 0.870208,loss:0.303897\n",
      "[epoch:29,batch:479]:acc: 0.870964,loss:0.302094\n",
      "[epoch:29,batch:509]:acc: 0.869975,loss:0.302757\n",
      "[epoch:29,batch:539]:acc: 0.869907,loss:0.303414\n",
      "[epoch:29,batch:569]:acc: 0.869846,loss:0.302653\n",
      "[epoch:29,batch:599]:acc: 0.870260,loss:0.301327\n",
      "[epoch:29,batch:599]: val_loss:0.399129,val_acc:0.852390,val_total:4539\n",
      "[epoch:29,batch:629]:acc: 0.869841,loss:0.303912\n",
      "[epoch:29,batch:659]:acc: 0.869934,loss:0.302312\n",
      "[epoch:29,batch:689]:acc: 0.870109,loss:0.302570\n",
      "[epoch:29,batch:719]:acc: 0.869661,loss:0.303246\n",
      "[epoch:29,batch:749]:acc: 0.869625,loss:0.302805\n",
      "[epoch:29,batch:779]:acc: 0.870553,loss:0.301661\n",
      "[epoch:29,batch:809]:acc: 0.870023,loss:0.302722\n",
      "[epoch:29,batch:839]:acc: 0.870052,loss:0.303397\n",
      "[epoch:29,batch:869]:acc: 0.869720,loss:0.304302\n",
      "[epoch:29,batch:899]:acc: 0.870104,loss:0.303205\n",
      "[epoch:29,batch:899]: val_loss:0.392345,val_acc:0.855695,val_total:4539\n",
      "[epoch:29,batch:929]:acc: 0.870397,loss:0.302925\n",
      "[epoch:29,batch:959]:acc: 0.870475,loss:0.303034\n",
      "[epoch:29,batch:989]:acc: 0.870044,loss:0.303888\n",
      "[epoch:29] :acc: 0.870133,loss:0.303656,lr:0.000000,patience:0\n",
      "[epoch:29]: val_loss:0.395169,val_acc:0.855695,\n",
      "Epoch 30/59\n",
      "----------\n",
      "[epoch:30,batch:29]:acc: 0.864583,loss:0.323614\n",
      "[epoch:30,batch:59]:acc: 0.872396,loss:0.312015\n",
      "[epoch:30,batch:89]:acc: 0.872222,loss:0.304394\n",
      "[epoch:30,batch:119]:acc: 0.873698,loss:0.305130\n",
      "[epoch:30,batch:149]:acc: 0.871875,loss:0.301885\n",
      "[epoch:30,batch:179]:acc: 0.872917,loss:0.296785\n",
      "[epoch:30,batch:209]:acc: 0.872619,loss:0.299042\n",
      "[epoch:30,batch:239]:acc: 0.871484,loss:0.304219\n",
      "[epoch:30,batch:269]:acc: 0.871528,loss:0.304583\n",
      "[epoch:30,batch:299]:acc: 0.872604,loss:0.304133\n",
      "[epoch:30,batch:299]: val_loss:0.393709,val_acc:0.856136,val_total:4539\n",
      "[epoch:30,batch:329]:acc: 0.874053,loss:0.300763\n",
      "[epoch:30,batch:359]:acc: 0.873958,loss:0.301263\n",
      "[epoch:30,batch:389]:acc: 0.873798,loss:0.300202\n",
      "[epoch:30,batch:419]:acc: 0.873363,loss:0.302030\n",
      "[epoch:30,batch:449]:acc: 0.872986,loss:0.301260\n",
      "[epoch:30,batch:479]:acc: 0.873568,loss:0.299939\n",
      "[epoch:30,batch:509]:acc: 0.874020,loss:0.298753\n",
      "[epoch:30,batch:539]:acc: 0.874363,loss:0.296966\n",
      "[epoch:30,batch:569]:acc: 0.874561,loss:0.296426\n",
      "[epoch:30,batch:599]:acc: 0.875260,loss:0.297027\n",
      "[epoch:30,batch:599]: val_loss:0.395200,val_acc:0.854153,val_total:4539\n",
      "[epoch:30,batch:629]:acc: 0.874752,loss:0.297301\n",
      "[epoch:30,batch:659]:acc: 0.874195,loss:0.298493\n",
      "[epoch:30,batch:689]:acc: 0.873777,loss:0.297367\n",
      "[epoch:30,batch:719]:acc: 0.873698,loss:0.297562\n",
      "[epoch:30,batch:749]:acc: 0.873625,loss:0.296731\n",
      "[epoch:30,batch:779]:acc: 0.872997,loss:0.298865\n",
      "[epoch:30,batch:809]:acc: 0.872840,loss:0.298568\n",
      "[epoch:30,batch:839]:acc: 0.872470,loss:0.299097\n",
      "[epoch:30,batch:869]:acc: 0.872486,loss:0.299597\n",
      "[epoch:30,batch:899]:acc: 0.872361,loss:0.299412\n",
      "[epoch:30,batch:899]: val_loss:0.392040,val_acc:0.857898,val_total:4539\n",
      "[epoch:30,batch:929]:acc: 0.872715,loss:0.299207\n",
      "[epoch:30,batch:959]:acc: 0.872982,loss:0.299183\n",
      "[epoch:30,batch:989]:acc: 0.873264,loss:0.298919\n",
      "[epoch:30] :acc: 0.873286,loss:0.299111,lr:0.000000,patience:1\n",
      "[epoch:30]: val_loss:0.397363,val_acc:0.853051,\n",
      "Epoch 31/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:31,batch:29]:acc: 0.864583,loss:0.318241\n",
      "[epoch:31,batch:59]:acc: 0.867188,loss:0.311928\n",
      "[epoch:31,batch:89]:acc: 0.860764,loss:0.328586\n",
      "[epoch:31,batch:119]:acc: 0.867188,loss:0.315351\n",
      "[epoch:31,batch:149]:acc: 0.869375,loss:0.309804\n",
      "[epoch:31,batch:179]:acc: 0.873785,loss:0.304102\n",
      "[epoch:31,batch:209]:acc: 0.873214,loss:0.307524\n",
      "[epoch:31,batch:239]:acc: 0.874089,loss:0.303804\n",
      "[epoch:31,batch:269]:acc: 0.872569,loss:0.303986\n",
      "[epoch:31,batch:299]:acc: 0.873333,loss:0.303416\n",
      "[epoch:31,batch:299]: val_loss:0.396089,val_acc:0.852831,val_total:4539\n",
      "[epoch:31,batch:329]:acc: 0.873769,loss:0.303467\n",
      "[epoch:31,batch:359]:acc: 0.873524,loss:0.304238\n",
      "[epoch:31,batch:389]:acc: 0.874038,loss:0.302233\n",
      "[epoch:31,batch:419]:acc: 0.875074,loss:0.302386\n",
      "[epoch:31,batch:449]:acc: 0.874722,loss:0.301281\n",
      "[epoch:31,batch:479]:acc: 0.873958,loss:0.303299\n",
      "[epoch:31,batch:509]:acc: 0.872978,loss:0.305027\n",
      "[epoch:31,batch:539]:acc: 0.872917,loss:0.305591\n",
      "[epoch:31,batch:569]:acc: 0.871985,loss:0.306286\n",
      "[epoch:31,batch:599]:acc: 0.871979,loss:0.306309\n",
      "[epoch:31,batch:599]: val_loss:0.395978,val_acc:0.855254,val_total:4539\n",
      "[epoch:31,batch:629]:acc: 0.873115,loss:0.304355\n",
      "[epoch:31,batch:659]:acc: 0.872775,loss:0.304612\n",
      "[epoch:31,batch:689]:acc: 0.872690,loss:0.303283\n",
      "[epoch:31,batch:719]:acc: 0.872743,loss:0.303003\n",
      "[epoch:31,batch:749]:acc: 0.873083,loss:0.301238\n",
      "[epoch:31,batch:779]:acc: 0.872436,loss:0.301411\n",
      "[epoch:31,batch:809]:acc: 0.872415,loss:0.300878\n",
      "[epoch:31,batch:839]:acc: 0.872693,loss:0.300224\n",
      "[epoch:31,batch:869]:acc: 0.872665,loss:0.299653\n",
      "[epoch:31,batch:899]:acc: 0.872743,loss:0.299016\n",
      "[epoch:31,batch:899]: val_loss:0.391344,val_acc:0.854153,val_total:4539\n",
      "[epoch:31,batch:929]:acc: 0.872917,loss:0.298973\n",
      "[epoch:31,batch:959]:acc: 0.872884,loss:0.299098\n",
      "[epoch:31,batch:989]:acc: 0.873138,loss:0.298632\n",
      "[epoch:31] :acc: 0.873223,loss:0.298542,lr:0.000000,patience:0\n",
      "[epoch:31]: val_loss:0.397039,val_acc:0.857237,\n",
      "Epoch 32/59\n",
      "----------\n",
      "[epoch:32,batch:29]:acc: 0.880208,loss:0.299821\n",
      "[epoch:32,batch:59]:acc: 0.877604,loss:0.304633\n",
      "[epoch:32,batch:89]:acc: 0.870139,loss:0.314901\n",
      "[epoch:32,batch:119]:acc: 0.872917,loss:0.309382\n",
      "[epoch:32,batch:149]:acc: 0.875000,loss:0.302432\n",
      "[epoch:32,batch:179]:acc: 0.875521,loss:0.303106\n",
      "[epoch:32,batch:209]:acc: 0.874256,loss:0.305721\n",
      "[epoch:32,batch:239]:acc: 0.874349,loss:0.306681\n",
      "[epoch:32,batch:269]:acc: 0.874884,loss:0.304743\n",
      "[epoch:32,batch:299]:acc: 0.874687,loss:0.303464\n",
      "[epoch:32,batch:299]: val_loss:0.393478,val_acc:0.855034,val_total:4539\n",
      "[epoch:32,batch:329]:acc: 0.875189,loss:0.303443\n",
      "[epoch:32,batch:359]:acc: 0.875608,loss:0.303421\n",
      "[epoch:32,batch:389]:acc: 0.875240,loss:0.305054\n",
      "[epoch:32,batch:419]:acc: 0.873884,loss:0.304703\n",
      "[epoch:32,batch:449]:acc: 0.873542,loss:0.305528\n",
      "[epoch:32,batch:479]:acc: 0.872786,loss:0.305199\n",
      "[epoch:32,batch:509]:acc: 0.871507,loss:0.305926\n",
      "[epoch:32,batch:539]:acc: 0.871296,loss:0.306846\n",
      "[epoch:32,batch:569]:acc: 0.871491,loss:0.306359\n",
      "[epoch:32,batch:599]:acc: 0.872396,loss:0.304566\n",
      "[epoch:32,batch:599]: val_loss:0.394190,val_acc:0.855475,val_total:4539\n",
      "[epoch:32,batch:629]:acc: 0.872619,loss:0.304608\n",
      "[epoch:32,batch:659]:acc: 0.872254,loss:0.305838\n",
      "[epoch:32,batch:689]:acc: 0.873279,loss:0.303956\n",
      "[epoch:32,batch:719]:acc: 0.873655,loss:0.304278\n",
      "[epoch:32,batch:749]:acc: 0.874208,loss:0.302114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:32,batch:779]:acc: 0.874679,loss:0.301308\n",
      "[epoch:32,batch:809]:acc: 0.874769,loss:0.301808\n",
      "[epoch:32,batch:839]:acc: 0.874888,loss:0.300712\n",
      "[epoch:32,batch:869]:acc: 0.874856,loss:0.299855\n",
      "[epoch:32,batch:899]:acc: 0.874931,loss:0.300211\n",
      "[epoch:32,batch:899]: val_loss:0.392517,val_acc:0.854594,val_total:4539\n",
      "[epoch:32,batch:929]:acc: 0.875134,loss:0.299426\n",
      "[epoch:32,batch:959]:acc: 0.875000,loss:0.299929\n",
      "[epoch:32,batch:989]:acc: 0.874684,loss:0.300497\n",
      "[epoch:32] :acc: 0.874736,loss:0.300230,lr:0.000000,patience:1\n",
      "[epoch:32]: val_loss:0.398267,val_acc:0.856356,\n",
      "Epoch 33/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:33,batch:29]:acc: 0.869792,loss:0.283873\n",
      "[epoch:33,batch:59]:acc: 0.866146,loss:0.289259\n",
      "[epoch:33,batch:89]:acc: 0.875694,loss:0.288436\n",
      "[epoch:33,batch:119]:acc: 0.876563,loss:0.289902\n",
      "[epoch:33,batch:149]:acc: 0.876875,loss:0.288348\n",
      "[epoch:33,batch:179]:acc: 0.873958,loss:0.291939\n",
      "[epoch:33,batch:209]:acc: 0.876488,loss:0.286429\n",
      "[epoch:33,batch:239]:acc: 0.877474,loss:0.284941\n",
      "[epoch:33,batch:269]:acc: 0.877199,loss:0.287587\n",
      "[epoch:33,batch:299]:acc: 0.876146,loss:0.289498\n",
      "[epoch:33,batch:299]: val_loss:0.391745,val_acc:0.855254,val_total:4539\n",
      "[epoch:33,batch:329]:acc: 0.875379,loss:0.288274\n",
      "[epoch:33,batch:359]:acc: 0.876476,loss:0.287831\n",
      "[epoch:33,batch:389]:acc: 0.875240,loss:0.287373\n",
      "[epoch:33,batch:419]:acc: 0.876637,loss:0.287743\n",
      "[epoch:33,batch:449]:acc: 0.874931,loss:0.289959\n",
      "[epoch:33,batch:479]:acc: 0.875195,loss:0.288965\n",
      "[epoch:33,batch:509]:acc: 0.874387,loss:0.290737\n",
      "[epoch:33,batch:539]:acc: 0.873900,loss:0.292072\n",
      "[epoch:33,batch:569]:acc: 0.873465,loss:0.293536\n",
      "[epoch:33,batch:599]:acc: 0.873594,loss:0.294132\n",
      "[epoch:33,batch:599]: val_loss:0.391446,val_acc:0.853933,val_total:4539\n",
      "[epoch:33,batch:629]:acc: 0.874107,loss:0.294284\n",
      "[epoch:33,batch:659]:acc: 0.874100,loss:0.296979\n",
      "[epoch:33,batch:689]:acc: 0.874411,loss:0.296467\n",
      "[epoch:33,batch:719]:acc: 0.874132,loss:0.296565\n",
      "[epoch:33,batch:749]:acc: 0.875000,loss:0.296031\n",
      "[epoch:33,batch:779]:acc: 0.875080,loss:0.295888\n",
      "[epoch:33,batch:809]:acc: 0.874383,loss:0.296999\n",
      "[epoch:33,batch:839]:acc: 0.874628,loss:0.296490\n",
      "[epoch:33,batch:869]:acc: 0.875036,loss:0.295179\n",
      "[epoch:33,batch:899]:acc: 0.875451,loss:0.294126\n",
      "[epoch:33,batch:899]: val_loss:0.391396,val_acc:0.853933,val_total:4539\n",
      "[epoch:33,batch:929]:acc: 0.875134,loss:0.295022\n",
      "[epoch:33,batch:959]:acc: 0.875163,loss:0.295525\n",
      "[epoch:33,batch:989]:acc: 0.875221,loss:0.294968\n",
      "[epoch:33] :acc: 0.875272,loss:0.294899,lr:0.000000,patience:0\n",
      "[epoch:33]: val_loss:0.396595,val_acc:0.853051,\n",
      "Epoch 34/59\n",
      "----------\n",
      "[epoch:34,batch:29]:acc: 0.870833,loss:0.280827\n",
      "[epoch:34,batch:59]:acc: 0.869271,loss:0.289628\n",
      "[epoch:34,batch:89]:acc: 0.878819,loss:0.279151\n",
      "[epoch:34,batch:119]:acc: 0.876042,loss:0.285393\n",
      "[epoch:34,batch:149]:acc: 0.877917,loss:0.282215\n",
      "[epoch:34,batch:179]:acc: 0.879687,loss:0.281363\n",
      "[epoch:34,batch:209]:acc: 0.878125,loss:0.282161\n",
      "[epoch:34,batch:239]:acc: 0.878385,loss:0.284251\n",
      "[epoch:34,batch:269]:acc: 0.878241,loss:0.284317\n",
      "[epoch:34,batch:299]:acc: 0.879479,loss:0.282299\n",
      "[epoch:34,batch:299]: val_loss:0.395003,val_acc:0.854814,val_total:4539\n",
      "[epoch:34,batch:329]:acc: 0.878883,loss:0.284062\n",
      "[epoch:34,batch:359]:acc: 0.877344,loss:0.287274\n",
      "[epoch:34,batch:389]:acc: 0.876522,loss:0.289432\n",
      "[epoch:34,batch:419]:acc: 0.876563,loss:0.289802\n",
      "[epoch:34,batch:449]:acc: 0.875903,loss:0.290570\n",
      "[epoch:34,batch:479]:acc: 0.874740,loss:0.293739\n",
      "[epoch:34,batch:509]:acc: 0.874877,loss:0.292772\n",
      "[epoch:34,batch:539]:acc: 0.874132,loss:0.292664\n",
      "[epoch:34,batch:569]:acc: 0.873629,loss:0.293853\n",
      "[epoch:34,batch:599]:acc: 0.873177,loss:0.293821\n",
      "[epoch:34,batch:599]: val_loss:0.395292,val_acc:0.855695,val_total:4539\n",
      "[epoch:34,batch:629]:acc: 0.874157,loss:0.294474\n",
      "[epoch:34,batch:659]:acc: 0.872917,loss:0.295562\n",
      "[epoch:34,batch:689]:acc: 0.872237,loss:0.297610\n",
      "[epoch:34,batch:719]:acc: 0.872352,loss:0.297726\n",
      "[epoch:34,batch:749]:acc: 0.872583,loss:0.296377\n",
      "[epoch:34,batch:779]:acc: 0.872596,loss:0.295086\n",
      "[epoch:34,batch:809]:acc: 0.872724,loss:0.296623\n",
      "[epoch:34,batch:839]:acc: 0.873251,loss:0.296116\n",
      "[epoch:34,batch:869]:acc: 0.872845,loss:0.296186\n",
      "[epoch:34,batch:899]:acc: 0.872951,loss:0.295883\n",
      "[epoch:34,batch:899]: val_loss:0.391526,val_acc:0.855475,val_total:4539\n",
      "[epoch:34,batch:929]:acc: 0.873555,loss:0.296041\n",
      "[epoch:34,batch:959]:acc: 0.874251,loss:0.294932\n",
      "[epoch:34,batch:989]:acc: 0.874274,loss:0.295324\n",
      "[epoch:34] :acc: 0.874326,loss:0.295224,lr:0.000000,patience:1\n",
      "[epoch:34]: val_loss:0.392495,val_acc:0.855034,\n",
      "Epoch 35/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:35,batch:29]:acc: 0.864583,loss:0.311307\n",
      "[epoch:35,batch:59]:acc: 0.865625,loss:0.324490\n",
      "[epoch:35,batch:89]:acc: 0.862847,loss:0.318395\n",
      "[epoch:35,batch:119]:acc: 0.864323,loss:0.315125\n",
      "[epoch:35,batch:149]:acc: 0.865625,loss:0.308475\n",
      "[epoch:35,batch:179]:acc: 0.865625,loss:0.305659\n",
      "[epoch:35,batch:209]:acc: 0.866964,loss:0.306167\n",
      "[epoch:35,batch:239]:acc: 0.866406,loss:0.307480\n",
      "[epoch:35,batch:269]:acc: 0.867014,loss:0.303655\n",
      "[epoch:35,batch:299]:acc: 0.869167,loss:0.299152\n",
      "[epoch:35,batch:299]: val_loss:0.393570,val_acc:0.853933,val_total:4539\n",
      "[epoch:35,batch:329]:acc: 0.868655,loss:0.301917\n",
      "[epoch:35,batch:359]:acc: 0.869010,loss:0.299030\n",
      "[epoch:35,batch:389]:acc: 0.869071,loss:0.298501\n",
      "[epoch:35,batch:419]:acc: 0.870015,loss:0.298052\n",
      "[epoch:35,batch:449]:acc: 0.869236,loss:0.298161\n",
      "[epoch:35,batch:479]:acc: 0.871419,loss:0.295140\n",
      "[epoch:35,batch:509]:acc: 0.871569,loss:0.296342\n",
      "[epoch:35,batch:539]:acc: 0.872049,loss:0.294614\n",
      "[epoch:35,batch:569]:acc: 0.872314,loss:0.294672\n",
      "[epoch:35,batch:599]:acc: 0.871823,loss:0.296357\n",
      "[epoch:35,batch:599]: val_loss:0.398971,val_acc:0.851729,val_total:4539\n",
      "[epoch:35,batch:629]:acc: 0.871875,loss:0.296306\n",
      "[epoch:35,batch:659]:acc: 0.872396,loss:0.296023\n",
      "[epoch:35,batch:689]:acc: 0.872554,loss:0.297213\n",
      "[epoch:35,batch:719]:acc: 0.871918,loss:0.297613\n",
      "[epoch:35,batch:749]:acc: 0.872375,loss:0.296386\n",
      "[epoch:35,batch:779]:acc: 0.872636,loss:0.296477\n",
      "[epoch:35,batch:809]:acc: 0.872994,loss:0.296246\n",
      "[epoch:35,batch:839]:acc: 0.873624,loss:0.295682\n",
      "[epoch:35,batch:869]:acc: 0.873384,loss:0.295966\n",
      "[epoch:35,batch:899]:acc: 0.874062,loss:0.294275\n",
      "[epoch:35,batch:899]: val_loss:0.395438,val_acc:0.853933,val_total:4539\n",
      "[epoch:35,batch:929]:acc: 0.873690,loss:0.294815\n",
      "[epoch:35,batch:959]:acc: 0.873893,loss:0.294781\n",
      "[epoch:35,batch:989]:acc: 0.874116,loss:0.295284\n",
      "[epoch:35] :acc: 0.874011,loss:0.295449,lr:0.000000,patience:0\n",
      "[epoch:35]: val_loss:0.397015,val_acc:0.853051,\n",
      "Epoch 36/59\n",
      "----------\n",
      "[epoch:36,batch:29]:acc: 0.883333,loss:0.269477\n",
      "[epoch:36,batch:59]:acc: 0.877604,loss:0.275172\n",
      "[epoch:36,batch:89]:acc: 0.876389,loss:0.281441\n",
      "[epoch:36,batch:119]:acc: 0.877604,loss:0.282945\n",
      "[epoch:36,batch:149]:acc: 0.876667,loss:0.282619\n",
      "[epoch:36,batch:179]:acc: 0.877083,loss:0.283509\n",
      "[epoch:36,batch:209]:acc: 0.876488,loss:0.287244\n",
      "[epoch:36,batch:239]:acc: 0.875651,loss:0.287946\n",
      "[epoch:36,batch:269]:acc: 0.876736,loss:0.290018\n",
      "[epoch:36,batch:299]:acc: 0.877604,loss:0.290204\n",
      "[epoch:36,batch:299]: val_loss:0.393107,val_acc:0.855034,val_total:4539\n",
      "[epoch:36,batch:329]:acc: 0.878125,loss:0.291777\n",
      "[epoch:36,batch:359]:acc: 0.877170,loss:0.295111\n",
      "[epoch:36,batch:389]:acc: 0.876843,loss:0.296304\n",
      "[epoch:36,batch:419]:acc: 0.876935,loss:0.295138\n",
      "[epoch:36,batch:449]:acc: 0.877569,loss:0.292785\n",
      "[epoch:36,batch:479]:acc: 0.876758,loss:0.293129\n",
      "[epoch:36,batch:509]:acc: 0.876716,loss:0.293733\n",
      "[epoch:36,batch:539]:acc: 0.876447,loss:0.294727\n",
      "[epoch:36,batch:569]:acc: 0.876590,loss:0.294476\n",
      "[epoch:36,batch:599]:acc: 0.876510,loss:0.293931\n",
      "[epoch:36,batch:599]: val_loss:0.392307,val_acc:0.855254,val_total:4539\n",
      "[epoch:36,batch:629]:acc: 0.875843,loss:0.295416\n",
      "[epoch:36,batch:659]:acc: 0.876468,loss:0.293428\n",
      "[epoch:36,batch:689]:acc: 0.876178,loss:0.293556\n",
      "[epoch:36,batch:719]:acc: 0.875521,loss:0.294354\n",
      "[epoch:36,batch:749]:acc: 0.875208,loss:0.294483\n",
      "[epoch:36,batch:779]:acc: 0.875401,loss:0.294718\n",
      "[epoch:36,batch:809]:acc: 0.875386,loss:0.296476\n",
      "[epoch:36,batch:839]:acc: 0.875260,loss:0.296626\n",
      "[epoch:36,batch:869]:acc: 0.875072,loss:0.296706\n",
      "[epoch:36,batch:899]:acc: 0.874931,loss:0.296683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:36,batch:899]: val_loss:0.393467,val_acc:0.854814,val_total:4539\n",
      "[epoch:36,batch:929]:acc: 0.874933,loss:0.297351\n",
      "[epoch:36,batch:959]:acc: 0.874740,loss:0.297938\n",
      "[epoch:36,batch:989]:acc: 0.874400,loss:0.297969\n",
      "[epoch:36] :acc: 0.874452,loss:0.297923,lr:0.000000,patience:1\n",
      "[epoch:36]: val_loss:0.398257,val_acc:0.854153,\n",
      "Epoch 37/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:37,batch:29]:acc: 0.864583,loss:0.304333\n",
      "[epoch:37,batch:59]:acc: 0.873437,loss:0.300373\n",
      "[epoch:37,batch:89]:acc: 0.875000,loss:0.302600\n",
      "[epoch:37,batch:119]:acc: 0.877344,loss:0.293932\n",
      "[epoch:37,batch:149]:acc: 0.878958,loss:0.286497\n",
      "[epoch:37,batch:179]:acc: 0.879514,loss:0.286098\n",
      "[epoch:37,batch:209]:acc: 0.874702,loss:0.294263\n",
      "[epoch:37,batch:239]:acc: 0.875260,loss:0.296539\n",
      "[epoch:37,batch:269]:acc: 0.876157,loss:0.295788\n",
      "[epoch:37,batch:299]:acc: 0.875625,loss:0.297429\n",
      "[epoch:37,batch:299]: val_loss:0.392455,val_acc:0.853051,val_total:4539\n",
      "[epoch:37,batch:329]:acc: 0.875095,loss:0.299823\n",
      "[epoch:37,batch:359]:acc: 0.874566,loss:0.300071\n",
      "[epoch:37,batch:389]:acc: 0.875481,loss:0.297744\n",
      "[epoch:37,batch:419]:acc: 0.875744,loss:0.297498\n",
      "[epoch:37,batch:449]:acc: 0.876319,loss:0.295704\n",
      "[epoch:37,batch:479]:acc: 0.877083,loss:0.294795\n",
      "[epoch:37,batch:509]:acc: 0.877390,loss:0.293328\n",
      "[epoch:37,batch:539]:acc: 0.876852,loss:0.294680\n",
      "[epoch:37,batch:569]:acc: 0.876700,loss:0.294368\n",
      "[epoch:37,batch:599]:acc: 0.875833,loss:0.296344\n",
      "[epoch:37,batch:599]: val_loss:0.394674,val_acc:0.855475,val_total:4539\n",
      "[epoch:37,batch:629]:acc: 0.875694,loss:0.296421\n",
      "[epoch:37,batch:659]:acc: 0.875710,loss:0.296250\n",
      "[epoch:37,batch:689]:acc: 0.875498,loss:0.297769\n",
      "[epoch:37,batch:719]:acc: 0.874740,loss:0.299203\n",
      "[epoch:37,batch:749]:acc: 0.874875,loss:0.299332\n",
      "[epoch:37,batch:779]:acc: 0.875080,loss:0.298105\n",
      "[epoch:37,batch:809]:acc: 0.875386,loss:0.298318\n",
      "[epoch:37,batch:839]:acc: 0.874777,loss:0.298162\n",
      "[epoch:37,batch:869]:acc: 0.874461,loss:0.298554\n",
      "[epoch:37,batch:899]:acc: 0.874375,loss:0.299842\n",
      "[epoch:37,batch:899]: val_loss:0.394550,val_acc:0.854153,val_total:4539\n",
      "[epoch:37,batch:929]:acc: 0.874261,loss:0.299423\n",
      "[epoch:37,batch:959]:acc: 0.874740,loss:0.298314\n",
      "[epoch:37,batch:989]:acc: 0.874590,loss:0.298777\n",
      "[epoch:37] :acc: 0.874578,loss:0.300185,lr:0.000000,patience:0\n",
      "[epoch:37]: val_loss:0.399562,val_acc:0.855915,\n",
      "Epoch 38/59\n",
      "----------\n",
      "[epoch:38,batch:29]:acc: 0.877083,loss:0.304205\n",
      "[epoch:38,batch:59]:acc: 0.875000,loss:0.291793\n",
      "[epoch:38,batch:89]:acc: 0.873958,loss:0.286328\n",
      "[epoch:38,batch:119]:acc: 0.876823,loss:0.283477\n",
      "[epoch:38,batch:149]:acc: 0.876250,loss:0.288116\n",
      "[epoch:38,batch:179]:acc: 0.877778,loss:0.284786\n",
      "[epoch:38,batch:209]:acc: 0.879315,loss:0.284273\n",
      "[epoch:38,batch:239]:acc: 0.876432,loss:0.290568\n",
      "[epoch:38,batch:269]:acc: 0.875116,loss:0.291499\n",
      "[epoch:38,batch:299]:acc: 0.876042,loss:0.291457\n",
      "[epoch:38,batch:299]: val_loss:0.393783,val_acc:0.852611,val_total:4539\n",
      "[epoch:38,batch:329]:acc: 0.874905,loss:0.291549\n",
      "[epoch:38,batch:359]:acc: 0.874392,loss:0.292805\n",
      "[epoch:38,batch:389]:acc: 0.874199,loss:0.293542\n",
      "[epoch:38,batch:419]:acc: 0.874554,loss:0.294157\n",
      "[epoch:38,batch:449]:acc: 0.874722,loss:0.293113\n",
      "[epoch:38,batch:479]:acc: 0.875000,loss:0.291984\n",
      "[epoch:38,batch:509]:acc: 0.875061,loss:0.292906\n",
      "[epoch:38,batch:539]:acc: 0.873843,loss:0.296469\n",
      "[epoch:38,batch:569]:acc: 0.873410,loss:0.296734\n",
      "[epoch:38,batch:599]:acc: 0.873333,loss:0.298611\n",
      "[epoch:38,batch:599]: val_loss:0.398043,val_acc:0.851729,val_total:4539\n",
      "[epoch:38,batch:629]:acc: 0.873512,loss:0.297625\n",
      "[epoch:38,batch:659]:acc: 0.873011,loss:0.297041\n",
      "[epoch:38,batch:689]:acc: 0.873143,loss:0.296358\n",
      "[epoch:38,batch:719]:acc: 0.872960,loss:0.296452\n",
      "[epoch:38,batch:749]:acc: 0.872542,loss:0.297289\n",
      "[epoch:38,batch:779]:acc: 0.872035,loss:0.298535\n",
      "[epoch:38,batch:809]:acc: 0.872068,loss:0.297490\n",
      "[epoch:38,batch:839]:acc: 0.871987,loss:0.297867\n",
      "[epoch:38,batch:869]:acc: 0.871731,loss:0.299052\n",
      "[epoch:38,batch:899]:acc: 0.871632,loss:0.299596\n",
      "[epoch:38,batch:899]: val_loss:0.397127,val_acc:0.854373,val_total:4539\n",
      "[epoch:38,batch:929]:acc: 0.871808,loss:0.299746\n",
      "[epoch:38,batch:959]:acc: 0.872005,loss:0.299035\n",
      "[epoch:38,batch:989]:acc: 0.872254,loss:0.298236\n",
      "[epoch:38] :acc: 0.872245,loss:0.299347,lr:0.000000,patience:1\n",
      "[epoch:38]: val_loss:0.395205,val_acc:0.855254,\n",
      "Epoch 39/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:39,batch:29]:acc: 0.884375,loss:0.296206\n",
      "[epoch:39,batch:59]:acc: 0.886979,loss:0.285134\n",
      "[epoch:39,batch:89]:acc: 0.887153,loss:0.284797\n",
      "[epoch:39,batch:119]:acc: 0.883854,loss:0.290002\n",
      "[epoch:39,batch:149]:acc: 0.883125,loss:0.286463\n",
      "[epoch:39,batch:179]:acc: 0.881597,loss:0.289217\n",
      "[epoch:39,batch:209]:acc: 0.880952,loss:0.286093\n",
      "[epoch:39,batch:239]:acc: 0.878776,loss:0.287806\n",
      "[epoch:39,batch:269]:acc: 0.878704,loss:0.289391\n",
      "[epoch:39,batch:299]:acc: 0.879687,loss:0.290724\n",
      "[epoch:39,batch:299]: val_loss:0.392002,val_acc:0.855695,val_total:4539\n",
      "[epoch:39,batch:329]:acc: 0.880587,loss:0.289550\n",
      "[epoch:39,batch:359]:acc: 0.879601,loss:0.291537\n",
      "[epoch:39,batch:389]:acc: 0.880689,loss:0.289221\n",
      "[epoch:39,batch:419]:acc: 0.880804,loss:0.289949\n",
      "[epoch:39,batch:449]:acc: 0.880972,loss:0.288860\n",
      "[epoch:39,batch:479]:acc: 0.879818,loss:0.290216\n",
      "[epoch:39,batch:509]:acc: 0.879167,loss:0.291957\n",
      "[epoch:39,batch:539]:acc: 0.879109,loss:0.292729\n",
      "[epoch:39,batch:569]:acc: 0.879715,loss:0.292087\n",
      "[epoch:39,batch:599]:acc: 0.878750,loss:0.293271\n",
      "[epoch:39,batch:599]: val_loss:0.392034,val_acc:0.856576,val_total:4539\n",
      "[epoch:39,batch:629]:acc: 0.878522,loss:0.293979\n",
      "[epoch:39,batch:659]:acc: 0.878504,loss:0.294216\n",
      "[epoch:39,batch:689]:acc: 0.878714,loss:0.293713\n",
      "[epoch:39,batch:719]:acc: 0.877734,loss:0.295714\n",
      "[epoch:39,batch:749]:acc: 0.878042,loss:0.295816\n",
      "[epoch:39,batch:779]:acc: 0.877564,loss:0.295297\n",
      "[epoch:39,batch:809]:acc: 0.877816,loss:0.295534\n",
      "[epoch:39,batch:839]:acc: 0.877902,loss:0.295418\n",
      "[epoch:39,batch:869]:acc: 0.877047,loss:0.295877\n",
      "[epoch:39,batch:899]:acc: 0.876563,loss:0.296107\n",
      "[epoch:39,batch:899]: val_loss:0.395311,val_acc:0.852390,val_total:4539\n",
      "[epoch:39,batch:929]:acc: 0.876378,loss:0.295848\n",
      "[epoch:39,batch:959]:acc: 0.876400,loss:0.295878\n",
      "[epoch:39,batch:989]:acc: 0.876705,loss:0.295318\n",
      "[epoch:39] :acc: 0.876691,loss:0.295265,lr:0.000000,patience:0\n",
      "[epoch:39]: val_loss:0.399718,val_acc:0.853933,\n",
      "Epoch 40/59\n",
      "----------\n",
      "[epoch:40,batch:29]:acc: 0.873958,loss:0.292959\n",
      "[epoch:40,batch:59]:acc: 0.867708,loss:0.285475\n",
      "[epoch:40,batch:89]:acc: 0.875000,loss:0.276412\n",
      "[epoch:40,batch:119]:acc: 0.874219,loss:0.282410\n",
      "[epoch:40,batch:149]:acc: 0.871458,loss:0.289704\n",
      "[epoch:40,batch:179]:acc: 0.872222,loss:0.290284\n",
      "[epoch:40,batch:209]:acc: 0.872917,loss:0.294694\n",
      "[epoch:40,batch:239]:acc: 0.872266,loss:0.292829\n",
      "[epoch:40,batch:269]:acc: 0.870949,loss:0.292851\n",
      "[epoch:40,batch:299]:acc: 0.871563,loss:0.292218\n",
      "[epoch:40,batch:299]: val_loss:0.395129,val_acc:0.856136,val_total:4539\n",
      "[epoch:40,batch:329]:acc: 0.872822,loss:0.293653\n",
      "[epoch:40,batch:359]:acc: 0.871962,loss:0.294504\n",
      "[epoch:40,batch:389]:acc: 0.872035,loss:0.293748\n",
      "[epoch:40,batch:419]:acc: 0.871205,loss:0.294406\n",
      "[epoch:40,batch:449]:acc: 0.871458,loss:0.293419\n",
      "[epoch:40,batch:479]:acc: 0.871745,loss:0.292908\n",
      "[epoch:40,batch:509]:acc: 0.871324,loss:0.293124\n",
      "[epoch:40,batch:539]:acc: 0.870775,loss:0.294695\n",
      "[epoch:40,batch:569]:acc: 0.871162,loss:0.293962\n",
      "[epoch:40,batch:599]:acc: 0.871458,loss:0.293856\n",
      "[epoch:40,batch:599]: val_loss:0.392197,val_acc:0.854153,val_total:4539\n",
      "[epoch:40,batch:629]:acc: 0.871577,loss:0.294079\n",
      "[epoch:40,batch:659]:acc: 0.871638,loss:0.294223\n",
      "[epoch:40,batch:689]:acc: 0.871377,loss:0.296422\n",
      "[epoch:40,batch:719]:acc: 0.871267,loss:0.296443\n",
      "[epoch:40,batch:749]:acc: 0.871042,loss:0.295619\n",
      "[epoch:40,batch:779]:acc: 0.871034,loss:0.294873\n",
      "[epoch:40,batch:809]:acc: 0.871528,loss:0.293943\n",
      "[epoch:40,batch:839]:acc: 0.871763,loss:0.293651\n",
      "[epoch:40,batch:869]:acc: 0.872306,loss:0.294400\n",
      "[epoch:40,batch:899]:acc: 0.871840,loss:0.295047\n",
      "[epoch:40,batch:899]: val_loss:0.394976,val_acc:0.855034,val_total:4539\n",
      "[epoch:40,batch:929]:acc: 0.872413,loss:0.294640\n",
      "[epoch:40,batch:959]:acc: 0.872526,loss:0.294813\n",
      "[epoch:40,batch:989]:acc: 0.872317,loss:0.295564\n",
      "[epoch:40] :acc: 0.872277,loss:0.296024,lr:0.000000,patience:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:40]: val_loss:0.403068,val_acc:0.851068,\n",
      "Epoch 41/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:41,batch:29]:acc: 0.882292,loss:0.289592\n",
      "[epoch:41,batch:59]:acc: 0.876042,loss:0.288929\n",
      "[epoch:41,batch:89]:acc: 0.879514,loss:0.285246\n",
      "[epoch:41,batch:119]:acc: 0.878125,loss:0.292522\n",
      "[epoch:41,batch:149]:acc: 0.878750,loss:0.285880\n",
      "[epoch:41,batch:179]:acc: 0.875000,loss:0.293945\n",
      "[epoch:41,batch:209]:acc: 0.874107,loss:0.298841\n",
      "[epoch:41,batch:239]:acc: 0.872917,loss:0.299276\n",
      "[epoch:41,batch:269]:acc: 0.874769,loss:0.293739\n",
      "[epoch:41,batch:299]:acc: 0.874479,loss:0.298060\n",
      "[epoch:41,batch:299]: val_loss:0.398792,val_acc:0.852831,val_total:4539\n",
      "[epoch:41,batch:329]:acc: 0.874811,loss:0.295539\n",
      "[epoch:41,batch:359]:acc: 0.874392,loss:0.297707\n",
      "[epoch:41,batch:389]:acc: 0.873558,loss:0.297534\n",
      "[epoch:41,batch:419]:acc: 0.875000,loss:0.294194\n",
      "[epoch:41,batch:449]:acc: 0.874931,loss:0.296600\n",
      "[epoch:41,batch:479]:acc: 0.874089,loss:0.298039\n",
      "[epoch:41,batch:509]:acc: 0.874449,loss:0.298656\n",
      "[epoch:41,batch:539]:acc: 0.874537,loss:0.298371\n",
      "[epoch:41,batch:569]:acc: 0.874287,loss:0.297413\n",
      "[epoch:41,batch:599]:acc: 0.874323,loss:0.297089\n",
      "[epoch:41,batch:599]: val_loss:0.390114,val_acc:0.855475,val_total:4539\n",
      "[epoch:41,batch:629]:acc: 0.873413,loss:0.298162\n",
      "[epoch:41,batch:659]:acc: 0.873627,loss:0.298427\n",
      "[epoch:41,batch:689]:acc: 0.873234,loss:0.300208\n",
      "[epoch:41,batch:719]:acc: 0.873611,loss:0.298533\n",
      "[epoch:41,batch:749]:acc: 0.873625,loss:0.298005\n",
      "[epoch:41,batch:779]:acc: 0.873037,loss:0.299543\n",
      "[epoch:41,batch:809]:acc: 0.873148,loss:0.299425\n",
      "[epoch:41,batch:839]:acc: 0.872582,loss:0.298685\n",
      "[epoch:41,batch:869]:acc: 0.873240,loss:0.298459\n",
      "[epoch:41,batch:899]:acc: 0.873090,loss:0.298096\n",
      "[epoch:41,batch:899]: val_loss:0.395693,val_acc:0.853492,val_total:4539\n",
      "[epoch:41,batch:929]:acc: 0.873286,loss:0.297303\n",
      "[epoch:41,batch:959]:acc: 0.873177,loss:0.297734\n",
      "[epoch:41,batch:989]:acc: 0.872822,loss:0.297830\n",
      "[epoch:41] :acc: 0.872844,loss:0.297677,lr:0.000000,patience:0\n",
      "[epoch:41]: val_loss:0.396089,val_acc:0.853492,\n",
      "Epoch 42/59\n",
      "----------\n",
      "[epoch:42,batch:29]:acc: 0.891667,loss:0.262663\n",
      "[epoch:42,batch:59]:acc: 0.881250,loss:0.280284\n",
      "[epoch:42,batch:89]:acc: 0.878125,loss:0.290005\n",
      "[epoch:42,batch:119]:acc: 0.879427,loss:0.284633\n",
      "[epoch:42,batch:149]:acc: 0.881667,loss:0.283439\n",
      "[epoch:42,batch:179]:acc: 0.880556,loss:0.286635\n",
      "[epoch:42,batch:209]:acc: 0.879315,loss:0.286767\n",
      "[epoch:42,batch:239]:acc: 0.878776,loss:0.288007\n",
      "[epoch:42,batch:269]:acc: 0.877083,loss:0.287343\n",
      "[epoch:42,batch:299]:acc: 0.877188,loss:0.290322\n",
      "[epoch:42,batch:299]: val_loss:0.395003,val_acc:0.855915,val_total:4539\n",
      "[epoch:42,batch:329]:acc: 0.878693,loss:0.290155\n",
      "[epoch:42,batch:359]:acc: 0.877170,loss:0.292715\n",
      "[epoch:42,batch:389]:acc: 0.876603,loss:0.294843\n",
      "[epoch:42,batch:419]:acc: 0.876042,loss:0.296737\n",
      "[epoch:42,batch:449]:acc: 0.875486,loss:0.296925\n",
      "[epoch:42,batch:479]:acc: 0.875977,loss:0.296551\n",
      "[epoch:42,batch:509]:acc: 0.876225,loss:0.295758\n",
      "[epoch:42,batch:539]:acc: 0.876042,loss:0.295755\n",
      "[epoch:42,batch:569]:acc: 0.875713,loss:0.295864\n",
      "[epoch:42,batch:599]:acc: 0.875990,loss:0.297282\n",
      "[epoch:42,batch:599]: val_loss:0.394919,val_acc:0.856136,val_total:4539\n",
      "[epoch:42,batch:629]:acc: 0.875694,loss:0.297339\n",
      "[epoch:42,batch:659]:acc: 0.875663,loss:0.296776\n",
      "[epoch:42,batch:689]:acc: 0.875226,loss:0.297300\n",
      "[epoch:42,batch:719]:acc: 0.875087,loss:0.296733\n",
      "[epoch:42,batch:749]:acc: 0.874833,loss:0.297148\n",
      "[epoch:42,batch:779]:acc: 0.874399,loss:0.297308\n",
      "[epoch:42,batch:809]:acc: 0.874113,loss:0.296287\n",
      "[epoch:42,batch:839]:acc: 0.874219,loss:0.295921\n",
      "[epoch:42,batch:869]:acc: 0.874856,loss:0.295750\n",
      "[epoch:42,batch:899]:acc: 0.875382,loss:0.295509\n",
      "[epoch:42,batch:899]: val_loss:0.397460,val_acc:0.852611,val_total:4539\n",
      "[epoch:42,batch:929]:acc: 0.875269,loss:0.295879\n",
      "[epoch:42,batch:959]:acc: 0.875488,loss:0.295726\n",
      "[epoch:42,batch:989]:acc: 0.875253,loss:0.296045\n",
      "[epoch:42] :acc: 0.875209,loss:0.296116,lr:0.000000,patience:1\n",
      "[epoch:42]: val_loss:0.399921,val_acc:0.854814,\n",
      "Epoch 43/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:43,batch:29]:acc: 0.875000,loss:0.334170\n",
      "[epoch:43,batch:59]:acc: 0.866667,loss:0.333338\n",
      "[epoch:43,batch:89]:acc: 0.872569,loss:0.312157\n",
      "[epoch:43,batch:119]:acc: 0.873698,loss:0.304816\n",
      "[epoch:43,batch:149]:acc: 0.873333,loss:0.303632\n",
      "[epoch:43,batch:179]:acc: 0.876736,loss:0.299353\n",
      "[epoch:43,batch:209]:acc: 0.874107,loss:0.304940\n",
      "[epoch:43,batch:239]:acc: 0.874870,loss:0.302373\n",
      "[epoch:43,batch:269]:acc: 0.875231,loss:0.302687\n",
      "[epoch:43,batch:299]:acc: 0.875000,loss:0.303105\n",
      "[epoch:43,batch:299]: val_loss:0.395296,val_acc:0.856136,val_total:4539\n",
      "[epoch:43,batch:329]:acc: 0.873390,loss:0.303245\n",
      "[epoch:43,batch:359]:acc: 0.873872,loss:0.304822\n",
      "[epoch:43,batch:389]:acc: 0.873878,loss:0.303372\n",
      "[epoch:43,batch:419]:acc: 0.874330,loss:0.301290\n",
      "[epoch:43,batch:449]:acc: 0.874306,loss:0.301216\n",
      "[epoch:43,batch:479]:acc: 0.874414,loss:0.300441\n",
      "[epoch:43,batch:509]:acc: 0.875919,loss:0.297868\n",
      "[epoch:43,batch:539]:acc: 0.875637,loss:0.297510\n",
      "[epoch:43,batch:569]:acc: 0.874232,loss:0.299324\n",
      "[epoch:43,batch:599]:acc: 0.874115,loss:0.300000\n",
      "[epoch:43,batch:599]: val_loss:0.394781,val_acc:0.854373,val_total:4539\n",
      "[epoch:43,batch:629]:acc: 0.874058,loss:0.300454\n",
      "[epoch:43,batch:659]:acc: 0.873864,loss:0.301616\n",
      "[epoch:43,batch:689]:acc: 0.873868,loss:0.301666\n",
      "[epoch:43,batch:719]:acc: 0.873698,loss:0.301437\n",
      "[epoch:43,batch:749]:acc: 0.874167,loss:0.300667\n",
      "[epoch:43,batch:779]:acc: 0.874760,loss:0.299862\n",
      "[epoch:43,batch:809]:acc: 0.875077,loss:0.299750\n",
      "[epoch:43,batch:839]:acc: 0.874814,loss:0.300115\n",
      "[epoch:43,batch:869]:acc: 0.875251,loss:0.299120\n",
      "[epoch:43,batch:899]:acc: 0.875313,loss:0.298673\n",
      "[epoch:43,batch:899]: val_loss:0.396447,val_acc:0.856576,val_total:4539\n",
      "[epoch:43,batch:929]:acc: 0.875302,loss:0.297933\n",
      "[epoch:43,batch:959]:acc: 0.874642,loss:0.298596\n",
      "[epoch:43,batch:989]:acc: 0.874747,loss:0.299052\n",
      "[epoch:43] :acc: 0.874767,loss:0.298938,lr:0.000000,patience:0\n",
      "[epoch:43]: val_loss:0.395739,val_acc:0.854814,\n",
      "Epoch 44/59\n",
      "----------\n",
      "[epoch:44,batch:29]:acc: 0.880208,loss:0.292563\n",
      "[epoch:44,batch:59]:acc: 0.883333,loss:0.282723\n",
      "[epoch:44,batch:89]:acc: 0.881250,loss:0.286859\n",
      "[epoch:44,batch:119]:acc: 0.872396,loss:0.297343\n",
      "[epoch:44,batch:149]:acc: 0.869375,loss:0.304906\n",
      "[epoch:44,batch:179]:acc: 0.871701,loss:0.302508\n",
      "[epoch:44,batch:209]:acc: 0.875149,loss:0.297249\n",
      "[epoch:44,batch:239]:acc: 0.876172,loss:0.297771\n",
      "[epoch:44,batch:269]:acc: 0.875579,loss:0.297802\n",
      "[epoch:44,batch:299]:acc: 0.873958,loss:0.299749\n",
      "[epoch:44,batch:299]: val_loss:0.393404,val_acc:0.854594,val_total:4539\n",
      "[epoch:44,batch:329]:acc: 0.874716,loss:0.299346\n",
      "[epoch:44,batch:359]:acc: 0.874132,loss:0.301703\n",
      "[epoch:44,batch:389]:acc: 0.873478,loss:0.301469\n",
      "[epoch:44,batch:419]:acc: 0.875074,loss:0.300376\n",
      "[epoch:44,batch:449]:acc: 0.875208,loss:0.300575\n",
      "[epoch:44,batch:479]:acc: 0.876107,loss:0.299550\n",
      "[epoch:44,batch:509]:acc: 0.876777,loss:0.297355\n",
      "[epoch:44,batch:539]:acc: 0.876736,loss:0.296944\n",
      "[epoch:44,batch:569]:acc: 0.877303,loss:0.294505\n",
      "[epoch:44,batch:599]:acc: 0.876771,loss:0.296246\n",
      "[epoch:44,batch:599]: val_loss:0.396545,val_acc:0.852170,val_total:4539\n",
      "[epoch:44,batch:629]:acc: 0.877183,loss:0.295600\n",
      "[epoch:44,batch:659]:acc: 0.876894,loss:0.294699\n",
      "[epoch:44,batch:689]:acc: 0.877310,loss:0.292967\n",
      "[epoch:44,batch:719]:acc: 0.877300,loss:0.292576\n",
      "[epoch:44,batch:749]:acc: 0.876625,loss:0.292536\n",
      "[epoch:44,batch:779]:acc: 0.876482,loss:0.292879\n",
      "[epoch:44,batch:809]:acc: 0.876273,loss:0.292751\n",
      "[epoch:44,batch:839]:acc: 0.876042,loss:0.293237\n",
      "[epoch:44,batch:869]:acc: 0.875898,loss:0.292671\n",
      "[epoch:44,batch:899]:acc: 0.875938,loss:0.293055\n",
      "[epoch:44,batch:899]: val_loss:0.394124,val_acc:0.855254,val_total:4539\n",
      "[epoch:44,batch:929]:acc: 0.876445,loss:0.292725\n",
      "[epoch:44,batch:959]:acc: 0.876725,loss:0.292184\n",
      "[epoch:44,batch:989]:acc: 0.876989,loss:0.292100\n",
      "[epoch:44] :acc: 0.876880,loss:0.292111,lr:0.000000,patience:1\n",
      "[epoch:44]: val_loss:0.403009,val_acc:0.850408,\n",
      "Epoch 45/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:45,batch:29]:acc: 0.893750,loss:0.262961\n",
      "[epoch:45,batch:59]:acc: 0.878646,loss:0.286966\n",
      "[epoch:45,batch:89]:acc: 0.875694,loss:0.295024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:45,batch:119]:acc: 0.877344,loss:0.292713\n",
      "[epoch:45,batch:149]:acc: 0.877500,loss:0.290506\n",
      "[epoch:45,batch:179]:acc: 0.875000,loss:0.291757\n",
      "[epoch:45,batch:209]:acc: 0.872917,loss:0.296476\n",
      "[epoch:45,batch:239]:acc: 0.871484,loss:0.298545\n",
      "[epoch:45,batch:269]:acc: 0.872454,loss:0.298477\n",
      "[epoch:45,batch:299]:acc: 0.873333,loss:0.295479\n",
      "[epoch:45,batch:299]: val_loss:0.392838,val_acc:0.855915,val_total:4539\n",
      "[epoch:45,batch:329]:acc: 0.873106,loss:0.294339\n",
      "[epoch:45,batch:359]:acc: 0.872830,loss:0.296468\n",
      "[epoch:45,batch:389]:acc: 0.873237,loss:0.295244\n",
      "[epoch:45,batch:419]:acc: 0.874107,loss:0.293255\n",
      "[epoch:45,batch:449]:acc: 0.874722,loss:0.292793\n",
      "[epoch:45,batch:479]:acc: 0.874154,loss:0.294420\n",
      "[epoch:45,batch:509]:acc: 0.874081,loss:0.293899\n",
      "[epoch:45,batch:539]:acc: 0.873900,loss:0.294273\n",
      "[epoch:45,batch:569]:acc: 0.874452,loss:0.293418\n",
      "[epoch:45,batch:599]:acc: 0.873646,loss:0.294485\n",
      "[epoch:45,batch:599]: val_loss:0.396038,val_acc:0.854594,val_total:4539\n",
      "[epoch:45,batch:629]:acc: 0.873710,loss:0.295183\n",
      "[epoch:45,batch:659]:acc: 0.874148,loss:0.295188\n",
      "[epoch:45,batch:689]:acc: 0.873958,loss:0.294469\n",
      "[epoch:45,batch:719]:acc: 0.873655,loss:0.297234\n",
      "[epoch:45,batch:749]:acc: 0.873667,loss:0.298377\n",
      "[epoch:45,batch:779]:acc: 0.873397,loss:0.297702\n",
      "[epoch:45,batch:809]:acc: 0.873534,loss:0.297168\n",
      "[epoch:45,batch:839]:acc: 0.874033,loss:0.296185\n",
      "[epoch:45,batch:869]:acc: 0.874497,loss:0.295113\n",
      "[epoch:45,batch:899]:acc: 0.873785,loss:0.296767\n",
      "[epoch:45,batch:899]: val_loss:0.393777,val_acc:0.854594,val_total:4539\n",
      "[epoch:45,batch:929]:acc: 0.873522,loss:0.296429\n",
      "[epoch:45,batch:959]:acc: 0.873210,loss:0.297259\n",
      "[epoch:45,batch:989]:acc: 0.873737,loss:0.295828\n",
      "[epoch:45] :acc: 0.873601,loss:0.296874,lr:0.000000,patience:0\n",
      "[epoch:45]: val_loss:0.401348,val_acc:0.852390,\n",
      "Epoch 46/59\n",
      "----------\n",
      "[epoch:46,batch:29]:acc: 0.894792,loss:0.256533\n",
      "[epoch:46,batch:59]:acc: 0.884375,loss:0.274550\n",
      "[epoch:46,batch:89]:acc: 0.884375,loss:0.282983\n",
      "[epoch:46,batch:119]:acc: 0.883073,loss:0.287064\n",
      "[epoch:46,batch:149]:acc: 0.882083,loss:0.285275\n",
      "[epoch:46,batch:179]:acc: 0.881771,loss:0.283099\n",
      "[epoch:46,batch:209]:acc: 0.878571,loss:0.290820\n",
      "[epoch:46,batch:239]:acc: 0.877344,loss:0.292431\n",
      "[epoch:46,batch:269]:acc: 0.877778,loss:0.292099\n",
      "[epoch:46,batch:299]:acc: 0.877188,loss:0.294414\n",
      "[epoch:46,batch:299]: val_loss:0.394225,val_acc:0.851729,val_total:4539\n",
      "[epoch:46,batch:329]:acc: 0.877462,loss:0.296610\n",
      "[epoch:46,batch:359]:acc: 0.877083,loss:0.294455\n",
      "[epoch:46,batch:389]:acc: 0.876442,loss:0.293892\n",
      "[epoch:46,batch:419]:acc: 0.875074,loss:0.296292\n",
      "[epoch:46,batch:449]:acc: 0.874306,loss:0.297196\n",
      "[epoch:46,batch:479]:acc: 0.874349,loss:0.296474\n",
      "[epoch:46,batch:509]:acc: 0.873897,loss:0.297427\n",
      "[epoch:46,batch:539]:acc: 0.874306,loss:0.298210\n",
      "[epoch:46,batch:569]:acc: 0.873410,loss:0.298911\n",
      "[epoch:46,batch:599]:acc: 0.873177,loss:0.298545\n",
      "[epoch:46,batch:599]: val_loss:0.392383,val_acc:0.854814,val_total:4539\n",
      "[epoch:46,batch:629]:acc: 0.872173,loss:0.298681\n",
      "[epoch:46,batch:659]:acc: 0.872112,loss:0.300752\n",
      "[epoch:46,batch:689]:acc: 0.872192,loss:0.299977\n",
      "[epoch:46,batch:719]:acc: 0.872439,loss:0.298638\n",
      "[epoch:46,batch:749]:acc: 0.872750,loss:0.297357\n",
      "[epoch:46,batch:779]:acc: 0.872837,loss:0.297878\n",
      "[epoch:46,batch:809]:acc: 0.872145,loss:0.299364\n",
      "[epoch:46,batch:839]:acc: 0.872433,loss:0.299246\n",
      "[epoch:46,batch:869]:acc: 0.872450,loss:0.300713\n",
      "[epoch:46,batch:899]:acc: 0.872535,loss:0.299450\n",
      "[epoch:46,batch:899]: val_loss:0.391528,val_acc:0.857237,val_total:4539\n",
      "[epoch:46,batch:929]:acc: 0.872917,loss:0.298505\n",
      "[epoch:46,batch:959]:acc: 0.872884,loss:0.297765\n",
      "[epoch:46,batch:989]:acc: 0.873106,loss:0.298696\n",
      "[epoch:46] :acc: 0.873096,loss:0.299249,lr:0.000000,patience:1\n",
      "[epoch:46]: val_loss:0.395077,val_acc:0.853933,\n",
      "Epoch 47/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:47,batch:29]:acc: 0.882292,loss:0.315981\n",
      "[epoch:47,batch:59]:acc: 0.864062,loss:0.322694\n",
      "[epoch:47,batch:89]:acc: 0.864583,loss:0.315473\n",
      "[epoch:47,batch:119]:acc: 0.865365,loss:0.311660\n",
      "[epoch:47,batch:149]:acc: 0.864583,loss:0.305573\n",
      "[epoch:47,batch:179]:acc: 0.865451,loss:0.304569\n",
      "[epoch:47,batch:209]:acc: 0.870982,loss:0.294083\n",
      "[epoch:47,batch:239]:acc: 0.870052,loss:0.299182\n",
      "[epoch:47,batch:269]:acc: 0.869444,loss:0.299517\n",
      "[epoch:47,batch:299]:acc: 0.867917,loss:0.301879\n",
      "[epoch:47,batch:299]: val_loss:0.394382,val_acc:0.854594,val_total:4539\n",
      "[epoch:47,batch:329]:acc: 0.868561,loss:0.301649\n",
      "[epoch:47,batch:359]:acc: 0.869705,loss:0.301087\n",
      "[epoch:47,batch:389]:acc: 0.870272,loss:0.298690\n",
      "[epoch:47,batch:419]:acc: 0.871205,loss:0.295694\n",
      "[epoch:47,batch:449]:acc: 0.870556,loss:0.298412\n",
      "[epoch:47,batch:479]:acc: 0.870703,loss:0.298922\n",
      "[epoch:47,batch:509]:acc: 0.871140,loss:0.298178\n",
      "[epoch:47,batch:539]:acc: 0.872569,loss:0.297442\n",
      "[epoch:47,batch:569]:acc: 0.872533,loss:0.297455\n",
      "[epoch:47,batch:599]:acc: 0.872031,loss:0.298906\n",
      "[epoch:47,batch:599]: val_loss:0.400990,val_acc:0.850628,val_total:4539\n",
      "[epoch:47,batch:629]:acc: 0.872917,loss:0.298078\n",
      "[epoch:47,batch:659]:acc: 0.873201,loss:0.299102\n",
      "[epoch:47,batch:689]:acc: 0.873324,loss:0.299096\n",
      "[epoch:47,batch:719]:acc: 0.874045,loss:0.298980\n",
      "[epoch:47,batch:749]:acc: 0.873958,loss:0.298938\n",
      "[epoch:47,batch:779]:acc: 0.875120,loss:0.297542\n",
      "[epoch:47,batch:809]:acc: 0.874614,loss:0.297542\n",
      "[epoch:47,batch:839]:acc: 0.874405,loss:0.298869\n",
      "[epoch:47,batch:869]:acc: 0.874677,loss:0.298286\n",
      "[epoch:47,batch:899]:acc: 0.874722,loss:0.298289\n",
      "[epoch:47,batch:899]: val_loss:0.400932,val_acc:0.849306,val_total:4539\n",
      "[epoch:47,batch:929]:acc: 0.874899,loss:0.298301\n",
      "[epoch:47,batch:959]:acc: 0.874837,loss:0.298413\n",
      "[epoch:47,batch:989]:acc: 0.874495,loss:0.298715\n",
      "[epoch:47] :acc: 0.874452,loss:0.298970,lr:0.000000,patience:0\n",
      "[epoch:47]: val_loss:0.396096,val_acc:0.854814,\n",
      "Epoch 48/59\n",
      "----------\n",
      "[epoch:48,batch:29]:acc: 0.882292,loss:0.280164\n",
      "[epoch:48,batch:59]:acc: 0.876042,loss:0.285682\n",
      "[epoch:48,batch:89]:acc: 0.878125,loss:0.279091\n",
      "[epoch:48,batch:119]:acc: 0.873177,loss:0.287857\n",
      "[epoch:48,batch:149]:acc: 0.876458,loss:0.282832\n",
      "[epoch:48,batch:179]:acc: 0.877257,loss:0.279462\n",
      "[epoch:48,batch:209]:acc: 0.876042,loss:0.283072\n",
      "[epoch:48,batch:239]:acc: 0.875130,loss:0.287445\n",
      "[epoch:48,batch:269]:acc: 0.875347,loss:0.285085\n",
      "[epoch:48,batch:299]:acc: 0.876042,loss:0.287164\n",
      "[epoch:48,batch:299]: val_loss:0.393483,val_acc:0.855254,val_total:4539\n",
      "[epoch:48,batch:329]:acc: 0.876989,loss:0.290741\n",
      "[epoch:48,batch:359]:acc: 0.877865,loss:0.289287\n",
      "[epoch:48,batch:389]:acc: 0.876763,loss:0.288985\n",
      "[epoch:48,batch:419]:acc: 0.876637,loss:0.291297\n",
      "[epoch:48,batch:449]:acc: 0.877847,loss:0.287854\n",
      "[epoch:48,batch:479]:acc: 0.877148,loss:0.289031\n",
      "[epoch:48,batch:509]:acc: 0.876654,loss:0.291106\n",
      "[epoch:48,batch:539]:acc: 0.876620,loss:0.293015\n",
      "[epoch:48,batch:569]:acc: 0.876425,loss:0.292500\n",
      "[epoch:48,batch:599]:acc: 0.876615,loss:0.292384\n",
      "[epoch:48,batch:599]: val_loss:0.393932,val_acc:0.853051,val_total:4539\n",
      "[epoch:48,batch:629]:acc: 0.875794,loss:0.292178\n",
      "[epoch:48,batch:659]:acc: 0.875900,loss:0.290798\n",
      "[epoch:48,batch:689]:acc: 0.875951,loss:0.290754\n",
      "[epoch:48,batch:719]:acc: 0.876345,loss:0.290552\n",
      "[epoch:48,batch:749]:acc: 0.876250,loss:0.291082\n",
      "[epoch:48,batch:779]:acc: 0.876402,loss:0.291035\n",
      "[epoch:48,batch:809]:acc: 0.876620,loss:0.291908\n",
      "[epoch:48,batch:839]:acc: 0.875558,loss:0.293121\n",
      "[epoch:48,batch:869]:acc: 0.876078,loss:0.293046\n",
      "[epoch:48,batch:899]:acc: 0.876250,loss:0.293094\n",
      "[epoch:48,batch:899]: val_loss:0.394279,val_acc:0.855915,val_total:4539\n",
      "[epoch:48,batch:929]:acc: 0.876075,loss:0.293434\n",
      "[epoch:48,batch:959]:acc: 0.876237,loss:0.293923\n",
      "[epoch:48,batch:989]:acc: 0.875410,loss:0.294906\n",
      "[epoch:48] :acc: 0.875335,loss:0.295437,lr:0.000000,patience:1\n",
      "[epoch:48]: val_loss:0.397505,val_acc:0.853051,\n",
      "Epoch 49/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:49,batch:29]:acc: 0.873958,loss:0.287473\n",
      "[epoch:49,batch:59]:acc: 0.873958,loss:0.301743\n",
      "[epoch:49,batch:89]:acc: 0.877083,loss:0.297436\n",
      "[epoch:49,batch:119]:acc: 0.873698,loss:0.303468\n",
      "[epoch:49,batch:149]:acc: 0.871458,loss:0.308991\n",
      "[epoch:49,batch:179]:acc: 0.868924,loss:0.309323\n",
      "[epoch:49,batch:209]:acc: 0.869345,loss:0.307962\n",
      "[epoch:49,batch:239]:acc: 0.871094,loss:0.302944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:49,batch:269]:acc: 0.870486,loss:0.302523\n",
      "[epoch:49,batch:299]:acc: 0.871146,loss:0.298996\n",
      "[epoch:49,batch:299]: val_loss:0.393752,val_acc:0.856356,val_total:4539\n",
      "[epoch:49,batch:329]:acc: 0.871970,loss:0.299936\n",
      "[epoch:49,batch:359]:acc: 0.873090,loss:0.298314\n",
      "[epoch:49,batch:389]:acc: 0.872596,loss:0.300399\n",
      "[epoch:49,batch:419]:acc: 0.874033,loss:0.297539\n",
      "[epoch:49,batch:449]:acc: 0.875139,loss:0.295629\n",
      "[epoch:49,batch:479]:acc: 0.875977,loss:0.294378\n",
      "[epoch:49,batch:509]:acc: 0.875368,loss:0.297276\n",
      "[epoch:49,batch:539]:acc: 0.874826,loss:0.298328\n",
      "[epoch:49,batch:569]:acc: 0.873958,loss:0.297869\n",
      "[epoch:49,batch:599]:acc: 0.873958,loss:0.297282\n",
      "[epoch:49,batch:599]: val_loss:0.396131,val_acc:0.854153,val_total:4539\n",
      "[epoch:49,batch:629]:acc: 0.874157,loss:0.297462\n",
      "[epoch:49,batch:659]:acc: 0.874479,loss:0.295932\n",
      "[epoch:49,batch:689]:acc: 0.874321,loss:0.296342\n",
      "[epoch:49,batch:719]:acc: 0.874653,loss:0.296263\n",
      "[epoch:49,batch:749]:acc: 0.874167,loss:0.296586\n",
      "[epoch:49,batch:779]:acc: 0.874880,loss:0.294773\n",
      "[epoch:49,batch:809]:acc: 0.875231,loss:0.294687\n",
      "[epoch:49,batch:839]:acc: 0.874516,loss:0.295217\n",
      "[epoch:49,batch:869]:acc: 0.874749,loss:0.294453\n",
      "[epoch:49,batch:899]:acc: 0.875347,loss:0.294208\n",
      "[epoch:49,batch:899]: val_loss:0.392500,val_acc:0.856797,val_total:4539\n",
      "[epoch:49,batch:929]:acc: 0.874899,loss:0.295041\n",
      "[epoch:49,batch:959]:acc: 0.874707,loss:0.296400\n",
      "[epoch:49,batch:989]:acc: 0.874968,loss:0.296029\n",
      "[epoch:49] :acc: 0.874925,loss:0.296678,lr:0.000000,patience:0\n",
      "[epoch:49]: val_loss:0.400547,val_acc:0.852611,\n",
      "Epoch 50/59\n",
      "----------\n",
      "[epoch:50,batch:29]:acc: 0.871875,loss:0.291723\n",
      "[epoch:50,batch:59]:acc: 0.869792,loss:0.300400\n",
      "[epoch:50,batch:89]:acc: 0.875694,loss:0.296729\n",
      "[epoch:50,batch:119]:acc: 0.874219,loss:0.299170\n",
      "[epoch:50,batch:149]:acc: 0.876042,loss:0.295579\n",
      "[epoch:50,batch:179]:acc: 0.875868,loss:0.294882\n",
      "[epoch:50,batch:209]:acc: 0.874405,loss:0.294174\n",
      "[epoch:50,batch:239]:acc: 0.872656,loss:0.298351\n",
      "[epoch:50,batch:269]:acc: 0.871759,loss:0.298316\n",
      "[epoch:50,batch:299]:acc: 0.873437,loss:0.295180\n",
      "[epoch:50,batch:299]: val_loss:0.392403,val_acc:0.855475,val_total:4539\n",
      "[epoch:50,batch:329]:acc: 0.873011,loss:0.296472\n",
      "[epoch:50,batch:359]:acc: 0.873003,loss:0.296541\n",
      "[epoch:50,batch:389]:acc: 0.872756,loss:0.296245\n",
      "[epoch:50,batch:419]:acc: 0.871577,loss:0.297329\n",
      "[epoch:50,batch:449]:acc: 0.872292,loss:0.297203\n",
      "[epoch:50,batch:479]:acc: 0.871354,loss:0.297766\n",
      "[epoch:50,batch:509]:acc: 0.871201,loss:0.297625\n",
      "[epoch:50,batch:539]:acc: 0.871701,loss:0.297298\n",
      "[epoch:50,batch:569]:acc: 0.871820,loss:0.296544\n",
      "[epoch:50,batch:599]:acc: 0.871667,loss:0.296835\n",
      "[epoch:50,batch:599]: val_loss:0.392203,val_acc:0.855254,val_total:4539\n",
      "[epoch:50,batch:629]:acc: 0.871329,loss:0.296375\n",
      "[epoch:50,batch:659]:acc: 0.871733,loss:0.296609\n",
      "[epoch:50,batch:689]:acc: 0.872147,loss:0.297241\n",
      "[epoch:50,batch:719]:acc: 0.871962,loss:0.297744\n",
      "[epoch:50,batch:749]:acc: 0.871083,loss:0.299531\n",
      "[epoch:50,batch:779]:acc: 0.870633,loss:0.300430\n",
      "[epoch:50,batch:809]:acc: 0.870602,loss:0.301371\n",
      "[epoch:50,batch:839]:acc: 0.870424,loss:0.301231\n",
      "[epoch:50,batch:869]:acc: 0.870582,loss:0.300469\n",
      "[epoch:50,batch:899]:acc: 0.871215,loss:0.299620\n",
      "[epoch:50,batch:899]: val_loss:0.395396,val_acc:0.856136,val_total:4539\n",
      "[epoch:50,batch:929]:acc: 0.871237,loss:0.299341\n",
      "[epoch:50,batch:959]:acc: 0.871126,loss:0.299274\n",
      "[epoch:50,batch:989]:acc: 0.871338,loss:0.298970\n",
      "[epoch:50] :acc: 0.871173,loss:0.300014,lr:0.000000,patience:1\n",
      "[epoch:50]: val_loss:0.400162,val_acc:0.851068,\n",
      "Epoch 51/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:51,batch:29]:acc: 0.879167,loss:0.303775\n",
      "[epoch:51,batch:59]:acc: 0.863021,loss:0.334425\n",
      "[epoch:51,batch:89]:acc: 0.868750,loss:0.325779\n",
      "[epoch:51,batch:119]:acc: 0.871875,loss:0.314684\n",
      "[epoch:51,batch:149]:acc: 0.866667,loss:0.319146\n",
      "[epoch:51,batch:179]:acc: 0.867188,loss:0.316826\n",
      "[epoch:51,batch:209]:acc: 0.867708,loss:0.316936\n",
      "[epoch:51,batch:239]:acc: 0.872526,loss:0.307887\n",
      "[epoch:51,batch:269]:acc: 0.871875,loss:0.308305\n",
      "[epoch:51,batch:299]:acc: 0.872604,loss:0.304541\n",
      "[epoch:51,batch:299]: val_loss:0.392238,val_acc:0.855915,val_total:4539\n",
      "[epoch:51,batch:329]:acc: 0.872633,loss:0.302857\n",
      "[epoch:51,batch:359]:acc: 0.873351,loss:0.299806\n",
      "[epoch:51,batch:389]:acc: 0.873397,loss:0.298684\n",
      "[epoch:51,batch:419]:acc: 0.872842,loss:0.299568\n",
      "[epoch:51,batch:449]:acc: 0.871250,loss:0.303473\n",
      "[epoch:51,batch:479]:acc: 0.871419,loss:0.302921\n",
      "[epoch:51,batch:509]:acc: 0.872365,loss:0.300632\n",
      "[epoch:51,batch:539]:acc: 0.872106,loss:0.300611\n",
      "[epoch:51,batch:569]:acc: 0.872368,loss:0.300715\n",
      "[epoch:51,batch:599]:acc: 0.873177,loss:0.299356\n",
      "[epoch:51,batch:599]: val_loss:0.394273,val_acc:0.856356,val_total:4539\n",
      "[epoch:51,batch:629]:acc: 0.873661,loss:0.299237\n",
      "[epoch:51,batch:659]:acc: 0.874100,loss:0.299263\n",
      "[epoch:51,batch:689]:acc: 0.874366,loss:0.298175\n",
      "[epoch:51,batch:719]:acc: 0.874262,loss:0.299506\n",
      "[epoch:51,batch:749]:acc: 0.873750,loss:0.300522\n",
      "[epoch:51,batch:779]:acc: 0.873478,loss:0.301270\n",
      "[epoch:51,batch:809]:acc: 0.873534,loss:0.300439\n",
      "[epoch:51,batch:839]:acc: 0.873326,loss:0.300991\n",
      "[epoch:51,batch:869]:acc: 0.873384,loss:0.300813\n",
      "[epoch:51,batch:899]:acc: 0.873889,loss:0.299573\n",
      "[epoch:51,batch:899]: val_loss:0.397323,val_acc:0.855034,val_total:4539\n",
      "[epoch:51,batch:929]:acc: 0.873421,loss:0.300780\n",
      "[epoch:51,batch:959]:acc: 0.873079,loss:0.301794\n",
      "[epoch:51,batch:989]:acc: 0.872948,loss:0.302234\n",
      "[epoch:51] :acc: 0.872939,loss:0.302242,lr:0.000000,patience:0\n",
      "[epoch:51]: val_loss:0.391510,val_acc:0.856136,\n",
      "save new model loss,now loss is  0.39150986075401306\n",
      "Epoch 52/59\n",
      "----------\n",
      "[epoch:52,batch:29]:acc: 0.870833,loss:0.316484\n",
      "[epoch:52,batch:59]:acc: 0.872917,loss:0.294841\n",
      "[epoch:52,batch:89]:acc: 0.870486,loss:0.305630\n",
      "[epoch:52,batch:119]:acc: 0.874219,loss:0.298541\n",
      "[epoch:52,batch:149]:acc: 0.875625,loss:0.296625\n",
      "[epoch:52,batch:179]:acc: 0.875000,loss:0.301725\n",
      "[epoch:52,batch:209]:acc: 0.873065,loss:0.302457\n",
      "[epoch:52,batch:239]:acc: 0.872266,loss:0.302667\n",
      "[epoch:52,batch:269]:acc: 0.872106,loss:0.302376\n",
      "[epoch:52,batch:299]:acc: 0.872188,loss:0.300428\n",
      "[epoch:52,batch:299]: val_loss:0.393223,val_acc:0.854153,val_total:4539\n",
      "[epoch:52,batch:329]:acc: 0.870549,loss:0.302748\n",
      "[epoch:52,batch:359]:acc: 0.872396,loss:0.298049\n",
      "[epoch:52,batch:389]:acc: 0.872917,loss:0.296724\n",
      "[epoch:52,batch:419]:acc: 0.873065,loss:0.297030\n",
      "[epoch:52,batch:449]:acc: 0.873056,loss:0.298705\n",
      "[epoch:52,batch:479]:acc: 0.873047,loss:0.297288\n",
      "[epoch:52,batch:509]:acc: 0.873407,loss:0.299047\n",
      "[epoch:52,batch:539]:acc: 0.873206,loss:0.298978\n",
      "[epoch:52,batch:569]:acc: 0.872533,loss:0.299000\n",
      "[epoch:52,batch:599]:acc: 0.872656,loss:0.298934\n",
      "[epoch:52,batch:599]: val_loss:0.392584,val_acc:0.855034,val_total:4539\n",
      "[epoch:52,batch:629]:acc: 0.872222,loss:0.298915\n",
      "[epoch:52,batch:659]:acc: 0.871023,loss:0.300363\n",
      "[epoch:52,batch:689]:acc: 0.871422,loss:0.298580\n",
      "[epoch:52,batch:719]:acc: 0.871484,loss:0.297419\n",
      "[epoch:52,batch:749]:acc: 0.871875,loss:0.296308\n",
      "[epoch:52,batch:779]:acc: 0.872276,loss:0.295991\n",
      "[epoch:52,batch:809]:acc: 0.872917,loss:0.295687\n",
      "[epoch:52,batch:839]:acc: 0.872917,loss:0.295492\n",
      "[epoch:52,batch:869]:acc: 0.872522,loss:0.296392\n",
      "[epoch:52,batch:899]:acc: 0.873333,loss:0.295098\n",
      "[epoch:52,batch:899]: val_loss:0.392143,val_acc:0.856576,val_total:4539\n",
      "[epoch:52,batch:929]:acc: 0.873958,loss:0.294402\n",
      "[epoch:52,batch:959]:acc: 0.873437,loss:0.295204\n",
      "[epoch:52,batch:989]:acc: 0.873390,loss:0.294804\n",
      "[epoch:52] :acc: 0.873286,loss:0.296332,lr:0.000000,patience:0\n",
      "[epoch:52]: val_loss:0.393757,val_acc:0.855915,\n",
      "Epoch 53/59\n",
      "----------\n",
      "[epoch:53,batch:29]:acc: 0.876042,loss:0.273718\n",
      "[epoch:53,batch:59]:acc: 0.874479,loss:0.283099\n",
      "[epoch:53,batch:89]:acc: 0.868750,loss:0.295867\n",
      "[epoch:53,batch:119]:acc: 0.869010,loss:0.297107\n",
      "[epoch:53,batch:149]:acc: 0.866042,loss:0.301387\n",
      "[epoch:53,batch:179]:acc: 0.868750,loss:0.300764\n",
      "[epoch:53,batch:209]:acc: 0.871726,loss:0.298352\n",
      "[epoch:53,batch:239]:acc: 0.872135,loss:0.300753\n",
      "[epoch:53,batch:269]:acc: 0.872917,loss:0.300795\n",
      "[epoch:53,batch:299]:acc: 0.873333,loss:0.301474\n",
      "[epoch:53,batch:299]: val_loss:0.394609,val_acc:0.856797,val_total:4539\n",
      "[epoch:53,batch:329]:acc: 0.874337,loss:0.297659\n",
      "[epoch:53,batch:359]:acc: 0.873177,loss:0.298418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:53,batch:389]:acc: 0.872035,loss:0.300698\n",
      "[epoch:53,batch:419]:acc: 0.871280,loss:0.300635\n",
      "[epoch:53,batch:449]:acc: 0.872500,loss:0.298464\n",
      "[epoch:53,batch:479]:acc: 0.872461,loss:0.298583\n",
      "[epoch:53,batch:509]:acc: 0.871630,loss:0.300871\n",
      "[epoch:53,batch:539]:acc: 0.871644,loss:0.302019\n",
      "[epoch:53,batch:569]:acc: 0.870833,loss:0.304022\n",
      "[epoch:53,batch:599]:acc: 0.870365,loss:0.304438\n",
      "[epoch:53,batch:599]: val_loss:0.396760,val_acc:0.851509,val_total:4539\n",
      "[epoch:53,batch:629]:acc: 0.871032,loss:0.303842\n",
      "[epoch:53,batch:659]:acc: 0.871591,loss:0.303812\n",
      "[epoch:53,batch:689]:acc: 0.871105,loss:0.304322\n",
      "[epoch:53,batch:719]:acc: 0.871571,loss:0.303794\n",
      "[epoch:53,batch:749]:acc: 0.871583,loss:0.302981\n",
      "[epoch:53,batch:779]:acc: 0.871354,loss:0.302054\n",
      "[epoch:53,batch:809]:acc: 0.871258,loss:0.301678\n",
      "[epoch:53,batch:839]:acc: 0.872173,loss:0.300188\n",
      "[epoch:53,batch:869]:acc: 0.872306,loss:0.300039\n",
      "[epoch:53,batch:899]:acc: 0.872153,loss:0.300075\n",
      "[epoch:53,batch:899]: val_loss:0.397002,val_acc:0.852611,val_total:4539\n",
      "[epoch:53,batch:929]:acc: 0.871976,loss:0.300110\n",
      "[epoch:53,batch:959]:acc: 0.872363,loss:0.299811\n",
      "[epoch:53,batch:989]:acc: 0.872380,loss:0.299748\n",
      "[epoch:53] :acc: 0.872277,loss:0.301802,lr:0.000000,patience:1\n",
      "[epoch:53]: val_loss:0.398286,val_acc:0.854373,\n",
      "Epoch 54/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:54,batch:29]:acc: 0.848958,loss:0.334604\n",
      "[epoch:54,batch:59]:acc: 0.854167,loss:0.322305\n",
      "[epoch:54,batch:89]:acc: 0.855903,loss:0.316879\n",
      "[epoch:54,batch:119]:acc: 0.864583,loss:0.313230\n",
      "[epoch:54,batch:149]:acc: 0.865625,loss:0.316802\n",
      "[epoch:54,batch:179]:acc: 0.862326,loss:0.318717\n",
      "[epoch:54,batch:209]:acc: 0.865625,loss:0.311884\n",
      "[epoch:54,batch:239]:acc: 0.866536,loss:0.309666\n",
      "[epoch:54,batch:269]:acc: 0.865625,loss:0.307935\n",
      "[epoch:54,batch:299]:acc: 0.866875,loss:0.307692\n",
      "[epoch:54,batch:299]: val_loss:0.391121,val_acc:0.857898,val_total:4539\n",
      "[epoch:54,batch:329]:acc: 0.865909,loss:0.310952\n",
      "[epoch:54,batch:359]:acc: 0.866233,loss:0.308728\n",
      "[epoch:54,batch:389]:acc: 0.869151,loss:0.303030\n",
      "[epoch:54,batch:419]:acc: 0.869866,loss:0.301153\n",
      "[epoch:54,batch:449]:acc: 0.870069,loss:0.302549\n",
      "[epoch:54,batch:479]:acc: 0.869206,loss:0.302443\n",
      "[epoch:54,batch:509]:acc: 0.868505,loss:0.304777\n",
      "[epoch:54,batch:539]:acc: 0.869213,loss:0.303477\n",
      "[epoch:54,batch:569]:acc: 0.869408,loss:0.302017\n",
      "[epoch:54,batch:599]:acc: 0.869219,loss:0.302654\n",
      "[epoch:54,batch:599]: val_loss:0.395366,val_acc:0.854594,val_total:4539\n",
      "[epoch:54,batch:629]:acc: 0.869048,loss:0.302577\n",
      "[epoch:54,batch:659]:acc: 0.869413,loss:0.301977\n",
      "[epoch:54,batch:689]:acc: 0.869611,loss:0.301943\n",
      "[epoch:54,batch:719]:acc: 0.870052,loss:0.301817\n",
      "[epoch:54,batch:749]:acc: 0.870292,loss:0.302701\n",
      "[epoch:54,batch:779]:acc: 0.870032,loss:0.302561\n",
      "[epoch:54,batch:809]:acc: 0.869753,loss:0.302074\n",
      "[epoch:54,batch:839]:acc: 0.870052,loss:0.301696\n",
      "[epoch:54,batch:869]:acc: 0.870726,loss:0.300902\n",
      "[epoch:54,batch:899]:acc: 0.870833,loss:0.300648\n",
      "[epoch:54,batch:899]: val_loss:0.397634,val_acc:0.853272,val_total:4539\n",
      "[epoch:54,batch:929]:acc: 0.870699,loss:0.301650\n",
      "[epoch:54,batch:959]:acc: 0.871094,loss:0.300321\n",
      "[epoch:54,batch:989]:acc: 0.870676,loss:0.300986\n",
      "[epoch:54] :acc: 0.870763,loss:0.300939,lr:0.000000,patience:0\n",
      "[epoch:54]: val_loss:0.395418,val_acc:0.851509,\n",
      "Epoch 55/59\n",
      "----------\n",
      "[epoch:55,batch:29]:acc: 0.867708,loss:0.316415\n",
      "[epoch:55,batch:59]:acc: 0.864583,loss:0.316254\n",
      "[epoch:55,batch:89]:acc: 0.867708,loss:0.310966\n",
      "[epoch:55,batch:119]:acc: 0.868490,loss:0.310200\n",
      "[epoch:55,batch:149]:acc: 0.870417,loss:0.303753\n",
      "[epoch:55,batch:179]:acc: 0.871528,loss:0.299326\n",
      "[epoch:55,batch:209]:acc: 0.873214,loss:0.296988\n",
      "[epoch:55,batch:239]:acc: 0.872656,loss:0.300169\n",
      "[epoch:55,batch:269]:acc: 0.872222,loss:0.300664\n",
      "[epoch:55,batch:299]:acc: 0.872083,loss:0.301021\n",
      "[epoch:55,batch:299]: val_loss:0.393855,val_acc:0.857237,val_total:4539\n",
      "[epoch:55,batch:329]:acc: 0.872538,loss:0.301760\n",
      "[epoch:55,batch:359]:acc: 0.873611,loss:0.299566\n",
      "[epoch:55,batch:389]:acc: 0.874199,loss:0.297230\n",
      "[epoch:55,batch:419]:acc: 0.873661,loss:0.300452\n",
      "[epoch:55,batch:449]:acc: 0.873403,loss:0.302122\n",
      "[epoch:55,batch:479]:acc: 0.874089,loss:0.301045\n",
      "[epoch:55,batch:509]:acc: 0.874203,loss:0.299053\n",
      "[epoch:55,batch:539]:acc: 0.874016,loss:0.299737\n",
      "[epoch:55,batch:569]:acc: 0.873794,loss:0.299415\n",
      "[epoch:55,batch:599]:acc: 0.874531,loss:0.297782\n",
      "[epoch:55,batch:599]: val_loss:0.393001,val_acc:0.855254,val_total:4539\n",
      "[epoch:55,batch:629]:acc: 0.874802,loss:0.296716\n",
      "[epoch:55,batch:659]:acc: 0.874100,loss:0.298932\n",
      "[epoch:55,batch:689]:acc: 0.873913,loss:0.300356\n",
      "[epoch:55,batch:719]:acc: 0.874262,loss:0.299208\n",
      "[epoch:55,batch:749]:acc: 0.874125,loss:0.299354\n",
      "[epoch:55,batch:779]:acc: 0.874159,loss:0.298871\n",
      "[epoch:55,batch:809]:acc: 0.874267,loss:0.297617\n",
      "[epoch:55,batch:839]:acc: 0.874963,loss:0.296359\n",
      "[epoch:55,batch:869]:acc: 0.874389,loss:0.297648\n",
      "[epoch:55,batch:899]:acc: 0.874167,loss:0.296996\n",
      "[epoch:55,batch:899]: val_loss:0.394038,val_acc:0.854373,val_total:4539\n",
      "[epoch:55,batch:929]:acc: 0.874530,loss:0.296087\n",
      "[epoch:55,batch:959]:acc: 0.874740,loss:0.295689\n",
      "[epoch:55,batch:989]:acc: 0.874937,loss:0.295656\n",
      "[epoch:55] :acc: 0.874925,loss:0.295993,lr:0.000000,patience:1\n",
      "[epoch:55]: val_loss:0.405812,val_acc:0.846883,\n",
      "Epoch 56/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:56,batch:29]:acc: 0.869792,loss:0.302883\n",
      "[epoch:56,batch:59]:acc: 0.870833,loss:0.313587\n",
      "[epoch:56,batch:89]:acc: 0.874306,loss:0.304192\n",
      "[epoch:56,batch:119]:acc: 0.869792,loss:0.307500\n",
      "[epoch:56,batch:149]:acc: 0.868333,loss:0.310447\n",
      "[epoch:56,batch:179]:acc: 0.869271,loss:0.310395\n",
      "[epoch:56,batch:209]:acc: 0.871429,loss:0.305365\n",
      "[epoch:56,batch:239]:acc: 0.873437,loss:0.302615\n",
      "[epoch:56,batch:269]:acc: 0.872454,loss:0.304712\n",
      "[epoch:56,batch:299]:acc: 0.871250,loss:0.307184\n",
      "[epoch:56,batch:299]: val_loss:0.393232,val_acc:0.855034,val_total:4539\n",
      "[epoch:56,batch:329]:acc: 0.871970,loss:0.305296\n",
      "[epoch:56,batch:359]:acc: 0.873264,loss:0.302346\n",
      "[epoch:56,batch:389]:acc: 0.872356,loss:0.302510\n",
      "[epoch:56,batch:419]:acc: 0.872247,loss:0.300804\n",
      "[epoch:56,batch:449]:acc: 0.872639,loss:0.301231\n",
      "[epoch:56,batch:479]:acc: 0.873242,loss:0.300485\n",
      "[epoch:56,batch:509]:acc: 0.873591,loss:0.299659\n",
      "[epoch:56,batch:539]:acc: 0.874306,loss:0.298496\n",
      "[epoch:56,batch:569]:acc: 0.874397,loss:0.298490\n",
      "[epoch:56,batch:599]:acc: 0.874740,loss:0.298301\n",
      "[epoch:56,batch:599]: val_loss:0.395993,val_acc:0.855475,val_total:4539\n",
      "[epoch:56,batch:629]:acc: 0.874802,loss:0.297435\n",
      "[epoch:56,batch:659]:acc: 0.874669,loss:0.297295\n",
      "[epoch:56,batch:689]:acc: 0.874547,loss:0.297867\n",
      "[epoch:56,batch:719]:acc: 0.874653,loss:0.297948\n",
      "[epoch:56,batch:749]:acc: 0.874917,loss:0.297426\n",
      "[epoch:56,batch:779]:acc: 0.874639,loss:0.298009\n",
      "[epoch:56,batch:809]:acc: 0.874653,loss:0.296842\n",
      "[epoch:56,batch:839]:acc: 0.875000,loss:0.296607\n",
      "[epoch:56,batch:869]:acc: 0.874713,loss:0.296497\n",
      "[epoch:56,batch:899]:acc: 0.875000,loss:0.295744\n",
      "[epoch:56,batch:899]: val_loss:0.395108,val_acc:0.852170,val_total:4539\n",
      "[epoch:56,batch:929]:acc: 0.874966,loss:0.295487\n",
      "[epoch:56,batch:959]:acc: 0.875098,loss:0.295291\n",
      "[epoch:56,batch:989]:acc: 0.874590,loss:0.296319\n",
      "[epoch:56] :acc: 0.874515,loss:0.296655,lr:0.000000,patience:0\n",
      "[epoch:56]: val_loss:0.395991,val_acc:0.855475,\n",
      "Epoch 57/59\n",
      "----------\n",
      "[epoch:57,batch:29]:acc: 0.859375,loss:0.306210\n",
      "[epoch:57,batch:59]:acc: 0.872396,loss:0.296136\n",
      "[epoch:57,batch:89]:acc: 0.871181,loss:0.308204\n",
      "[epoch:57,batch:119]:acc: 0.870833,loss:0.304035\n",
      "[epoch:57,batch:149]:acc: 0.870833,loss:0.300775\n",
      "[epoch:57,batch:179]:acc: 0.870486,loss:0.304310\n",
      "[epoch:57,batch:209]:acc: 0.871429,loss:0.304522\n",
      "[epoch:57,batch:239]:acc: 0.872005,loss:0.301621\n",
      "[epoch:57,batch:269]:acc: 0.871759,loss:0.300910\n",
      "[epoch:57,batch:299]:acc: 0.871771,loss:0.301048\n",
      "[epoch:57,batch:299]: val_loss:0.392697,val_acc:0.853272,val_total:4539\n",
      "[epoch:57,batch:329]:acc: 0.873580,loss:0.299368\n",
      "[epoch:57,batch:359]:acc: 0.873264,loss:0.299404\n",
      "[epoch:57,batch:389]:acc: 0.873077,loss:0.299001\n",
      "[epoch:57,batch:419]:acc: 0.872247,loss:0.299754\n",
      "[epoch:57,batch:449]:acc: 0.872431,loss:0.299564\n",
      "[epoch:57,batch:479]:acc: 0.872982,loss:0.298402\n",
      "[epoch:57,batch:509]:acc: 0.873223,loss:0.296376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:57,batch:539]:acc: 0.872917,loss:0.298441\n",
      "[epoch:57,batch:569]:acc: 0.871820,loss:0.299315\n",
      "[epoch:57,batch:599]:acc: 0.871563,loss:0.299192\n",
      "[epoch:57,batch:599]: val_loss:0.392487,val_acc:0.855475,val_total:4539\n",
      "[epoch:57,batch:629]:acc: 0.871825,loss:0.299508\n",
      "[epoch:57,batch:659]:acc: 0.872917,loss:0.299224\n",
      "[epoch:57,batch:689]:acc: 0.873777,loss:0.298790\n",
      "[epoch:57,batch:719]:acc: 0.873568,loss:0.298488\n",
      "[epoch:57,batch:749]:acc: 0.873500,loss:0.298565\n",
      "[epoch:57,batch:779]:acc: 0.873958,loss:0.297621\n",
      "[epoch:57,batch:809]:acc: 0.873727,loss:0.296862\n",
      "[epoch:57,batch:839]:acc: 0.874107,loss:0.296311\n",
      "[epoch:57,batch:869]:acc: 0.874569,loss:0.295949\n",
      "[epoch:57,batch:899]:acc: 0.874479,loss:0.296634\n",
      "[epoch:57,batch:899]: val_loss:0.397065,val_acc:0.851509,val_total:4539\n",
      "[epoch:57,batch:929]:acc: 0.874798,loss:0.296551\n",
      "[epoch:57,batch:959]:acc: 0.874382,loss:0.296968\n",
      "[epoch:57,batch:989]:acc: 0.874463,loss:0.296957\n",
      "[epoch:57] :acc: 0.874421,loss:0.297086,lr:0.000000,patience:1\n",
      "[epoch:57]: val_loss:0.396987,val_acc:0.854594,\n",
      "Epoch 58/59\n",
      "----------\n",
      "loss has increased lr divide 10 lr now is :0.000000\n",
      "[epoch:58,batch:29]:acc: 0.883333,loss:0.281903\n",
      "[epoch:58,batch:59]:acc: 0.873437,loss:0.301744\n",
      "[epoch:58,batch:89]:acc: 0.875694,loss:0.292729\n",
      "[epoch:58,batch:119]:acc: 0.875260,loss:0.300542\n",
      "[epoch:58,batch:149]:acc: 0.876042,loss:0.298003\n",
      "[epoch:58,batch:179]:acc: 0.872743,loss:0.303623\n",
      "[epoch:58,batch:209]:acc: 0.872024,loss:0.304243\n",
      "[epoch:58,batch:239]:acc: 0.872266,loss:0.300797\n",
      "[epoch:58,batch:269]:acc: 0.870255,loss:0.303843\n",
      "[epoch:58,batch:299]:acc: 0.869479,loss:0.306941\n",
      "[epoch:58,batch:299]: val_loss:0.392314,val_acc:0.855254,val_total:4539\n",
      "[epoch:58,batch:329]:acc: 0.871117,loss:0.305925\n",
      "[epoch:58,batch:359]:acc: 0.871875,loss:0.305450\n",
      "[epoch:58,batch:389]:acc: 0.871795,loss:0.304219\n",
      "[epoch:58,batch:419]:acc: 0.871801,loss:0.303082\n",
      "[epoch:58,batch:449]:acc: 0.870764,loss:0.303472\n",
      "[epoch:58,batch:479]:acc: 0.872135,loss:0.302621\n",
      "[epoch:58,batch:509]:acc: 0.871201,loss:0.303110\n",
      "[epoch:58,batch:539]:acc: 0.870544,loss:0.302328\n",
      "[epoch:58,batch:569]:acc: 0.870559,loss:0.302691\n",
      "[epoch:58,batch:599]:acc: 0.870938,loss:0.302250\n",
      "[epoch:58,batch:599]: val_loss:0.395448,val_acc:0.854594,val_total:4539\n",
      "[epoch:58,batch:629]:acc: 0.870288,loss:0.303529\n",
      "[epoch:58,batch:659]:acc: 0.869555,loss:0.304127\n",
      "[epoch:58,batch:689]:acc: 0.869882,loss:0.303391\n",
      "[epoch:58,batch:719]:acc: 0.869488,loss:0.303340\n",
      "[epoch:58,batch:749]:acc: 0.869333,loss:0.303477\n",
      "[epoch:58,batch:779]:acc: 0.869471,loss:0.302482\n",
      "[epoch:58,batch:809]:acc: 0.869097,loss:0.303540\n",
      "[epoch:58,batch:839]:acc: 0.869568,loss:0.302847\n",
      "[epoch:58,batch:869]:acc: 0.869828,loss:0.302211\n",
      "[epoch:58,batch:899]:acc: 0.870139,loss:0.300780\n",
      "[epoch:58,batch:899]: val_loss:0.391883,val_acc:0.857237,val_total:4539\n",
      "[epoch:58,batch:929]:acc: 0.870329,loss:0.300186\n",
      "[epoch:58,batch:959]:acc: 0.870215,loss:0.300349\n",
      "[epoch:58,batch:989]:acc: 0.870865,loss:0.299348\n",
      "[epoch:58] :acc: 0.870826,loss:0.300656,lr:0.000000,patience:0\n",
      "[epoch:58]: val_loss:0.398334,val_acc:0.855475,\n",
      "Epoch 59/59\n",
      "----------\n",
      "[epoch:59,batch:29]:acc: 0.843750,loss:0.337499\n",
      "[epoch:59,batch:59]:acc: 0.858333,loss:0.330717\n",
      "[epoch:59,batch:89]:acc: 0.861806,loss:0.324583\n",
      "[epoch:59,batch:119]:acc: 0.863802,loss:0.320131\n",
      "[epoch:59,batch:149]:acc: 0.869375,loss:0.308608\n",
      "[epoch:59,batch:179]:acc: 0.873611,loss:0.304101\n",
      "[epoch:59,batch:209]:acc: 0.874554,loss:0.303286\n",
      "[epoch:59,batch:239]:acc: 0.875781,loss:0.305107\n",
      "[epoch:59,batch:269]:acc: 0.875810,loss:0.310399\n",
      "[epoch:59,batch:299]:acc: 0.874167,loss:0.312030\n",
      "[epoch:59,batch:299]: val_loss:0.393717,val_acc:0.854814,val_total:4539\n",
      "[epoch:59,batch:329]:acc: 0.872727,loss:0.310393\n",
      "[epoch:59,batch:359]:acc: 0.873872,loss:0.307549\n",
      "[epoch:59,batch:389]:acc: 0.874519,loss:0.305649\n",
      "[epoch:59,batch:419]:acc: 0.875595,loss:0.304500\n",
      "[epoch:59,batch:449]:acc: 0.873750,loss:0.307475\n",
      "[epoch:59,batch:479]:acc: 0.873958,loss:0.307206\n",
      "[epoch:59,batch:509]:acc: 0.873284,loss:0.305678\n",
      "[epoch:59,batch:539]:acc: 0.873206,loss:0.305977\n",
      "[epoch:59,batch:569]:acc: 0.872971,loss:0.304291\n",
      "[epoch:59,batch:599]:acc: 0.872135,loss:0.305236\n"
     ]
    }
   ],
   "source": [
    "train(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainWithRawData(path,epochNum):\n",
    "    train_dataset=MyDataSet(json_Description=ANNOTATION_TRAIN,transform=preprocess(normalize_05,IMAGE_SIZE),path_pre=IMAGE_TRAIN_PRE)\n",
    "    val_dataset=MyDataSet(json_Description=ANNOTATION_VAL,transform=preprocess(normalize_05,IMAGE_SIZE),path_pre=IMAGE_VAL_PRE)\n",
    "    train_dataLoader=DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE,num_workers=16,shuffle=True)\n",
    "    val_dataLoader=DataLoader(dataset=val_dataset,batch_size=BATCH_SIZE,num_workers=1,shuffle=False)\n",
    "    model=getmodel()\n",
    "    criterion=nn.CrossEntropyLoss().cuda()\n",
    "    modelParams=torch.load(path)\n",
    "    model.load_state_dict(modelParams['state_dict'])\n",
    "    min_loss=modelParams['val_loss']\n",
    "    print('min_loss is :%f'%(min_loss))\n",
    "    print('val_correct is %f'%(modelParams['val_correct']))\n",
    "    min_acc=max(modelParams['val_correct'],0.81)\n",
    "    optinizerSave=modelParams['optimizer']\n",
    "    patience=0\n",
    "    lr=1e-4\n",
    "    momentum=0.9\n",
    "    beginepoch=modelParams['epoch']\n",
    "    for epoch in range(beginepoch,epochNum):\n",
    "        print('Epoch {}/{}'.format(epoch, epochNum - 1))\n",
    "        print('-' * 10)\n",
    "        if patience==3:\n",
    "            patience=0\n",
    "            model.load_state_dict(torch.load('../model/NasnetMobile/'+date+'_loss_best.pth')['state_dict'])\n",
    "            lr=lr/5\n",
    "            print('lr desencd')\n",
    "        if epoch==beginepoch:\n",
    "            optimizer=torch.optim.SGD(params=model.parameters(),lr=lr,momentum=momentum)\n",
    "#             optimizer.load_state_dict(optinizerSave)\n",
    "#             lr=optimizer['lr']\n",
    "#             momentum=optimizer['momentum']\n",
    "            print('begin lr is ',lr)\n",
    "            \n",
    "        else:\n",
    "            optimizer=torch.optim.SGD(params=model.parameters(),lr=lr,momentum=momentum)\n",
    "                   \n",
    "        running_loss = RunningMean()\n",
    "        running_corrects = RunningMean()\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_dataLoader):\n",
    "            model.train(True)\n",
    "            n_batchsize=inputs.size(0)\n",
    "            inputs = Variable(inputs).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            if isinstance(outputs,tuple):\n",
    "                loss=sum((criterion(o,labels)) for o in outputs)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss.update(loss.item(),1)\n",
    "            running_corrects.update(torch.sum(preds == labels.data).data,n_batchsize)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx%30==29:\n",
    "                print('[epoch:%d,batch:%d]:acc: %f,loss:%f'%(epoch,batch_idx,running_corrects.value,running_loss.value))\n",
    "                if batch_idx%300==299: \n",
    "                    niter = epoch * len(train_dataset)/BATCH_SIZE + batch_idx\n",
    "                    lx,px=utils.predict(model,val_dataLoader)\n",
    "                    log_loss = criterion(Variable(px), Variable(lx))\n",
    "                    log_loss = log_loss.item()\n",
    "                    _, preds = torch.max(px, dim=1)\n",
    "                    accuracy = torch.mean((preds == lx).float())\n",
    "                    print('[epoch:%d,batch:%d]: val_loss:%f,val_acc:%f,val_total:%d'%(epoch,batch_idx,log_loss,accuracy,len(val_dataset)))\n",
    "                    if  log_loss < min_loss:\n",
    "                        utils.snapshot('../model/', 'NasnetMobile', {\n",
    "                               'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optimizer': optimizer.state_dict(),\n",
    "                               'val_loss': log_loss,\n",
    "                               'val_correct':accuracy })          \n",
    "\n",
    "                        min_loss=log_loss\n",
    "                        patience=0\n",
    "                        print('save new model loss,now loss is ',min_loss)\n",
    "\n",
    "                    if accuracy>min_acc:\n",
    "                        utils.snapshot('../model/', 'NasnetMobile', {\n",
    "                               'epoch': epoch + 1,\n",
    "                               'state_dict': model.state_dict(),\n",
    "                               'optimizer': optimizer.state_dict(),\n",
    "                               'val_loss': log_loss,\n",
    "                               'val_correct':accuracy },key='acc') \n",
    "                        min_acc=accuracy\n",
    "                        print('save new model acc,now acc is ',min_acc)\n",
    "        print('[epoch:%d] :acc: %f,loss:%f,lr:%f,patience:%d'%(epoch,running_corrects.value,running_loss.value,lr,patience))         \n",
    "        lx,px=utils.predict(model,val_dataLoader)\n",
    "        log_loss = criterion(Variable(px), Variable(lx))\n",
    "        log_loss = log_loss.item()\n",
    "        _, preds = torch.max(px, dim=1)\n",
    "        accuracy = torch.mean((preds == lx).float())\n",
    "        print('[epoch:%d]: val_loss:%f,val_acc:%f,'%(epoch,log_loss,accuracy))\n",
    "        if  log_loss < min_loss:\n",
    "            utils.snapshot('../model/', 'NasnetMobile', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy })          \n",
    "            patience = 0\n",
    "            min_loss=log_loss\n",
    "            print('save new model loss,now loss is ',min_loss)\n",
    "        else:\n",
    "            patience += 1\n",
    "        if accuracy>min_acc:\n",
    "            utils.snapshot('../model/', 'NasnetMobile', {\n",
    "                   'epoch': epoch + 1,\n",
    "                   'state_dict': model.state_dict(),\n",
    "                   'optimizer': optimizer.state_dict(),\n",
    "                   'val_loss': log_loss,\n",
    "                   'val_correct':accuracy },key='acc') \n",
    "            min_acc=accuracy\n",
    "            print('save new model acc,now acc is ',min_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] loading model... Done\n",
      "min_loss is :0.395555\n",
      "val_correct is 0.857678\n",
      "Epoch 19/59\n",
      "----------\n",
      "begin lr is  0.0001\n",
      "[epoch:19,batch:29]:acc: 0.865625,loss:0.311833\n",
      "[epoch:19,batch:59]:acc: 0.877604,loss:0.296242\n",
      "[epoch:19,batch:89]:acc: 0.878819,loss:0.290369\n",
      "[epoch:19,batch:119]:acc: 0.876302,loss:0.290033\n",
      "[epoch:19,batch:149]:acc: 0.876042,loss:0.288834\n",
      "[epoch:19,batch:179]:acc: 0.877431,loss:0.288586\n",
      "[epoch:19,batch:209]:acc: 0.879762,loss:0.282727\n",
      "[epoch:19,batch:239]:acc: 0.878255,loss:0.283751\n",
      "[epoch:19,batch:269]:acc: 0.877083,loss:0.284995\n",
      "[epoch:19,batch:299]:acc: 0.875625,loss:0.286338\n",
      "[epoch:19,batch:299]: val_loss:0.370539,val_acc:0.855695,val_total:4539\n",
      "save new model loss,now loss is  0.3705390393733978\n",
      "[epoch:19,batch:329]:acc: 0.876042,loss:0.285321\n",
      "[epoch:19,batch:359]:acc: 0.876389,loss:0.284622\n",
      "[epoch:19,batch:389]:acc: 0.877404,loss:0.283591\n",
      "[epoch:19,batch:419]:acc: 0.877902,loss:0.281815\n",
      "[epoch:19,batch:449]:acc: 0.877986,loss:0.281527\n",
      "[epoch:19,batch:479]:acc: 0.877669,loss:0.282412\n",
      "[epoch:19,batch:509]:acc: 0.878676,loss:0.282269\n",
      "[epoch:19,batch:539]:acc: 0.878877,loss:0.281212\n",
      "[epoch:19,batch:569]:acc: 0.879002,loss:0.281769\n",
      "[epoch:19,batch:599]:acc: 0.879635,loss:0.281460\n",
      "[epoch:19,batch:599]: val_loss:0.364270,val_acc:0.854814,val_total:4539\n",
      "save new model loss,now loss is  0.36427026987075806\n",
      "[epoch:19,batch:629]:acc: 0.879613,loss:0.281800\n",
      "[epoch:19,batch:659]:acc: 0.879924,loss:0.281029\n",
      "[epoch:19,batch:689]:acc: 0.880797,loss:0.280079\n",
      "[epoch:19,batch:719]:acc: 0.880035,loss:0.281192\n",
      "[epoch:19,batch:749]:acc: 0.879333,loss:0.282592\n",
      "[epoch:19,batch:779]:acc: 0.879687,loss:0.281656\n",
      "[epoch:19,batch:809]:acc: 0.879823,loss:0.280834\n",
      "[epoch:19,batch:839]:acc: 0.879687,loss:0.280879\n",
      "[epoch:19,batch:869]:acc: 0.879670,loss:0.280881\n",
      "[epoch:19,batch:899]:acc: 0.880035,loss:0.279551\n",
      "[epoch:19,batch:899]: val_loss:0.361642,val_acc:0.859220,val_total:4539\n",
      "save new model loss,now loss is  0.3616417944431305\n",
      "save new model acc,now acc is  tensor(0.8592, device='cuda:0')\n",
      "[epoch:19,batch:929]:acc: 0.880376,loss:0.278968\n",
      "[epoch:19,batch:959]:acc: 0.880859,loss:0.278156\n",
      "[epoch:19,batch:989]:acc: 0.881471,loss:0.277180\n",
      "[epoch:19] :acc: 0.881515,loss:0.277057,lr:0.000100,patience:0\n",
      "[epoch:19]: val_loss:0.365840,val_acc:0.857458,\n",
      "Epoch 20/59\n",
      "----------\n",
      "[epoch:20,batch:29]:acc: 0.883333,loss:0.265619\n",
      "[epoch:20,batch:59]:acc: 0.889062,loss:0.260186\n",
      "[epoch:20,batch:89]:acc: 0.889931,loss:0.257761\n",
      "[epoch:20,batch:119]:acc: 0.889844,loss:0.255842\n",
      "[epoch:20,batch:149]:acc: 0.890417,loss:0.259248\n",
      "[epoch:20,batch:179]:acc: 0.891840,loss:0.256218\n",
      "[epoch:20,batch:209]:acc: 0.890476,loss:0.259179\n",
      "[epoch:20,batch:239]:acc: 0.891146,loss:0.258900\n",
      "[epoch:20,batch:269]:acc: 0.891435,loss:0.259382\n",
      "[epoch:20,batch:299]:acc: 0.889792,loss:0.263345\n",
      "[epoch:20,batch:299]: val_loss:0.361289,val_acc:0.857678,val_total:4539\n",
      "save new model loss,now loss is  0.36128857731819153\n",
      "[epoch:20,batch:329]:acc: 0.891477,loss:0.260736\n",
      "[epoch:20,batch:359]:acc: 0.892448,loss:0.257649\n",
      "[epoch:20,batch:389]:acc: 0.892708,loss:0.257367\n",
      "[epoch:20,batch:419]:acc: 0.891741,loss:0.259770\n",
      "[epoch:20,batch:449]:acc: 0.891806,loss:0.259305\n",
      "[epoch:20,batch:479]:acc: 0.891862,loss:0.258352\n",
      "[epoch:20,batch:509]:acc: 0.891238,loss:0.260070\n",
      "[epoch:20,batch:539]:acc: 0.891493,loss:0.258629\n",
      "[epoch:20,batch:569]:acc: 0.891886,loss:0.257093\n",
      "[epoch:20,batch:599]:acc: 0.892396,loss:0.256367\n",
      "[epoch:20,batch:599]: val_loss:0.360388,val_acc:0.857458,val_total:4539\n",
      "save new model loss,now loss is  0.3603876233100891\n",
      "[epoch:20,batch:629]:acc: 0.892063,loss:0.257579\n",
      "[epoch:20,batch:659]:acc: 0.892140,loss:0.258216\n",
      "[epoch:20,batch:689]:acc: 0.892572,loss:0.257757\n",
      "[epoch:20,batch:719]:acc: 0.893056,loss:0.256207\n",
      "[epoch:20,batch:749]:acc: 0.893250,loss:0.255933\n",
      "[epoch:20,batch:779]:acc: 0.893429,loss:0.255521\n",
      "[epoch:20,batch:809]:acc: 0.893596,loss:0.255605\n",
      "[epoch:20,batch:839]:acc: 0.893527,loss:0.255138\n",
      "[epoch:20,batch:869]:acc: 0.893822,loss:0.254265\n",
      "[epoch:20,batch:899]:acc: 0.894479,loss:0.253203\n",
      "[epoch:20,batch:899]: val_loss:0.362274,val_acc:0.860542,val_total:4539\n",
      "save new model acc,now acc is  tensor(0.8605, device='cuda:0')\n",
      "[epoch:20,batch:929]:acc: 0.894388,loss:0.253338\n",
      "[epoch:20,batch:959]:acc: 0.894173,loss:0.253290\n",
      "[epoch:20,batch:989]:acc: 0.894697,loss:0.252104\n",
      "[epoch:20] :acc: 0.894725,loss:0.252218,lr:0.000100,patience:0\n",
      "[epoch:20]: val_loss:0.364260,val_acc:0.860101,\n",
      "Epoch 21/59\n",
      "----------\n",
      "[epoch:21,batch:29]:acc: 0.911458,loss:0.231949\n",
      "[epoch:21,batch:59]:acc: 0.911458,loss:0.239638\n",
      "[epoch:21,batch:89]:acc: 0.908681,loss:0.236942\n",
      "[epoch:21,batch:119]:acc: 0.902865,loss:0.240174\n",
      "[epoch:21,batch:149]:acc: 0.899792,loss:0.242129\n",
      "[epoch:21,batch:179]:acc: 0.899132,loss:0.241818\n",
      "[epoch:21,batch:209]:acc: 0.899554,loss:0.241241\n",
      "[epoch:21,batch:239]:acc: 0.899349,loss:0.242346\n",
      "[epoch:21,batch:269]:acc: 0.898843,loss:0.243556\n",
      "[epoch:21,batch:299]:acc: 0.898750,loss:0.243130\n",
      "[epoch:21,batch:299]: val_loss:0.363454,val_acc:0.860983,val_total:4539\n",
      "save new model acc,now acc is  tensor(0.8610, device='cuda:0')\n",
      "[epoch:21,batch:329]:acc: 0.898580,loss:0.243594\n",
      "[epoch:21,batch:359]:acc: 0.898958,loss:0.242812\n",
      "[epoch:21,batch:389]:acc: 0.899119,loss:0.241922\n",
      "[epoch:21,batch:419]:acc: 0.898735,loss:0.241352\n",
      "[epoch:21,batch:449]:acc: 0.899653,loss:0.240326\n",
      "[epoch:21,batch:479]:acc: 0.899805,loss:0.240422\n",
      "[epoch:21,batch:509]:acc: 0.899939,loss:0.239456\n",
      "[epoch:21,batch:539]:acc: 0.900058,loss:0.240142\n",
      "[epoch:21,batch:569]:acc: 0.900822,loss:0.239352\n",
      "[epoch:21,batch:599]:acc: 0.900469,loss:0.240083\n",
      "[epoch:21,batch:599]: val_loss:0.361501,val_acc:0.861423,val_total:4539\n",
      "save new model acc,now acc is  tensor(0.8614, device='cuda:0')\n",
      "[epoch:21,batch:629]:acc: 0.899752,loss:0.241397\n",
      "[epoch:21,batch:659]:acc: 0.899811,loss:0.240902\n",
      "[epoch:21,batch:689]:acc: 0.900589,loss:0.240127\n",
      "[epoch:21,batch:719]:acc: 0.900955,loss:0.239309\n",
      "[epoch:21,batch:749]:acc: 0.900833,loss:0.239867\n",
      "[epoch:21,batch:779]:acc: 0.900641,loss:0.240021\n",
      "[epoch:21,batch:809]:acc: 0.900887,loss:0.239881\n",
      "[epoch:21,batch:839]:acc: 0.901190,loss:0.238674\n",
      "[epoch:21,batch:869]:acc: 0.901832,loss:0.237249\n",
      "[epoch:21,batch:899]:acc: 0.901458,loss:0.237299\n",
      "[epoch:21,batch:899]: val_loss:0.361996,val_acc:0.860101,val_total:4539\n",
      "[epoch:21,batch:929]:acc: 0.901747,loss:0.236912\n",
      "[epoch:21,batch:959]:acc: 0.901790,loss:0.236500\n",
      "[epoch:21,batch:989]:acc: 0.901926,loss:0.236302\n",
      "[epoch:21] :acc: 0.901914,loss:0.236673,lr:0.000100,patience:1\n",
      "[epoch:21]: val_loss:0.362241,val_acc:0.861423,\n",
      "Epoch 22/59\n",
      "----------\n",
      "[epoch:22,batch:29]:acc: 0.907292,loss:0.235463\n",
      "[epoch:22,batch:59]:acc: 0.904167,loss:0.231325\n",
      "[epoch:22,batch:89]:acc: 0.899306,loss:0.238678\n",
      "[epoch:22,batch:119]:acc: 0.900260,loss:0.240773\n",
      "[epoch:22,batch:149]:acc: 0.899167,loss:0.243917\n",
      "[epoch:22,batch:179]:acc: 0.897049,loss:0.244496\n",
      "[epoch:22,batch:209]:acc: 0.897024,loss:0.246242\n",
      "[epoch:22,batch:239]:acc: 0.895573,loss:0.247362\n",
      "[epoch:22,batch:269]:acc: 0.898495,loss:0.244114\n",
      "[epoch:22,batch:299]:acc: 0.897396,loss:0.246914\n",
      "[epoch:22,batch:299]: val_loss:0.366036,val_acc:0.858559,val_total:4539\n",
      "[epoch:22,batch:329]:acc: 0.896591,loss:0.249044\n",
      "[epoch:22,batch:359]:acc: 0.895226,loss:0.252954\n",
      "[epoch:22,batch:389]:acc: 0.895513,loss:0.253340\n",
      "[epoch:22,batch:419]:acc: 0.895536,loss:0.253267\n",
      "[epoch:22,batch:449]:acc: 0.895000,loss:0.253959\n",
      "[epoch:22,batch:479]:acc: 0.895898,loss:0.252274\n",
      "[epoch:22,batch:509]:acc: 0.894608,loss:0.252823\n",
      "[epoch:22,batch:539]:acc: 0.893924,loss:0.252712\n",
      "[epoch:22,batch:569]:acc: 0.893586,loss:0.252414\n",
      "[epoch:22,batch:599]:acc: 0.893333,loss:0.252167\n",
      "[epoch:22,batch:599]: val_loss:0.359892,val_acc:0.862745,val_total:4539\n",
      "save new model loss,now loss is  0.35989248752593994\n",
      "save new model acc,now acc is  tensor(0.8627, device='cuda:0')\n",
      "[epoch:22,batch:629]:acc: 0.893204,loss:0.252680\n",
      "[epoch:22,batch:659]:acc: 0.893277,loss:0.252136\n",
      "[epoch:22,batch:689]:acc: 0.893388,loss:0.251662\n",
      "[epoch:22,batch:719]:acc: 0.893186,loss:0.251568\n",
      "[epoch:22,batch:749]:acc: 0.892750,loss:0.252301\n",
      "[epoch:22,batch:779]:acc: 0.893670,loss:0.250587\n",
      "[epoch:22,batch:809]:acc: 0.893287,loss:0.250698\n",
      "[epoch:22,batch:839]:acc: 0.893936,loss:0.249164\n",
      "[epoch:22,batch:869]:acc: 0.894361,loss:0.249365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:22,batch:899]:acc: 0.895382,loss:0.247747\n",
      "[epoch:22,batch:899]: val_loss:0.360367,val_acc:0.863186,val_total:4539\n",
      "save new model acc,now acc is  tensor(0.8632, device='cuda:0')\n",
      "[epoch:22,batch:929]:acc: 0.895262,loss:0.248014\n",
      "[epoch:22,batch:959]:acc: 0.895052,loss:0.247616\n",
      "[epoch:22,batch:989]:acc: 0.894729,loss:0.248430\n",
      "[epoch:22] :acc: 0.894725,loss:0.249884,lr:0.000100,patience:0\n",
      "[epoch:22]: val_loss:0.363611,val_acc:0.862965,\n",
      "Epoch 23/59\n",
      "----------\n",
      "[epoch:23,batch:29]:acc: 0.909375,loss:0.232563\n",
      "[epoch:23,batch:59]:acc: 0.902604,loss:0.237394\n",
      "[epoch:23,batch:89]:acc: 0.899653,loss:0.246408\n",
      "[epoch:23,batch:119]:acc: 0.898177,loss:0.241960\n",
      "[epoch:23,batch:149]:acc: 0.897917,loss:0.242914\n",
      "[epoch:23,batch:179]:acc: 0.898438,loss:0.244486\n",
      "[epoch:23,batch:209]:acc: 0.898661,loss:0.243714\n",
      "[epoch:23,batch:239]:acc: 0.899089,loss:0.244187\n",
      "[epoch:23,batch:269]:acc: 0.899306,loss:0.241106\n",
      "[epoch:23,batch:299]:acc: 0.898125,loss:0.241046\n",
      "[epoch:23,batch:299]: val_loss:0.362028,val_acc:0.862304,val_total:4539\n",
      "[epoch:23,batch:329]:acc: 0.899053,loss:0.241267\n",
      "[epoch:23,batch:359]:acc: 0.899913,loss:0.240160\n",
      "[epoch:23,batch:389]:acc: 0.899920,loss:0.239165\n",
      "[epoch:23,batch:419]:acc: 0.899926,loss:0.238113\n",
      "[epoch:23,batch:449]:acc: 0.899722,loss:0.238054\n",
      "[epoch:23,batch:479]:acc: 0.899609,loss:0.237434\n",
      "[epoch:23,batch:509]:acc: 0.898775,loss:0.237851\n",
      "[epoch:23,batch:539]:acc: 0.899653,loss:0.236217\n",
      "[epoch:23,batch:569]:acc: 0.899178,loss:0.236604\n",
      "[epoch:23,batch:599]:acc: 0.899062,loss:0.236692\n",
      "[epoch:23,batch:599]: val_loss:0.361893,val_acc:0.862525,val_total:4539\n",
      "[epoch:23,batch:629]:acc: 0.898958,loss:0.237757\n",
      "[epoch:23,batch:659]:acc: 0.898201,loss:0.238182\n",
      "[epoch:23,batch:689]:acc: 0.898370,loss:0.238495\n",
      "[epoch:23,batch:719]:acc: 0.898524,loss:0.237495\n",
      "[epoch:23,batch:749]:acc: 0.898917,loss:0.236846\n",
      "[epoch:23,batch:779]:acc: 0.899279,loss:0.236485\n",
      "[epoch:23,batch:809]:acc: 0.899691,loss:0.235750\n",
      "[epoch:23,batch:839]:acc: 0.898884,loss:0.237147\n",
      "[epoch:23,batch:869]:acc: 0.898563,loss:0.238297\n",
      "[epoch:23,batch:899]:acc: 0.898507,loss:0.238106\n",
      "[epoch:23,batch:899]: val_loss:0.363181,val_acc:0.862965,val_total:4539\n",
      "[epoch:23,batch:929]:acc: 0.898185,loss:0.238688\n",
      "[epoch:23,batch:959]:acc: 0.897917,loss:0.239427\n",
      "[epoch:23,batch:989]:acc: 0.898548,loss:0.238727\n",
      "[epoch:23] :acc: 0.898509,loss:0.238750,lr:0.000100,patience:1\n",
      "[epoch:23]: val_loss:0.362785,val_acc:0.862084,\n",
      "Epoch 24/59\n",
      "----------\n",
      "[epoch:24,batch:29]:acc: 0.909375,loss:0.225362\n",
      "[epoch:24,batch:59]:acc: 0.906250,loss:0.237376\n",
      "[epoch:24,batch:89]:acc: 0.903472,loss:0.237621\n",
      "[epoch:24,batch:119]:acc: 0.903385,loss:0.236521\n",
      "[epoch:24,batch:149]:acc: 0.901042,loss:0.238367\n",
      "[epoch:24,batch:179]:acc: 0.905208,loss:0.228854\n",
      "[epoch:24,batch:209]:acc: 0.906399,loss:0.225963\n",
      "[epoch:24,batch:239]:acc: 0.906641,loss:0.224686\n",
      "[epoch:24,batch:269]:acc: 0.907639,loss:0.222499\n",
      "[epoch:24,batch:299]:acc: 0.907813,loss:0.221166\n",
      "[epoch:24,batch:299]: val_loss:0.362939,val_acc:0.866270,val_total:4539\n",
      "save new model acc,now acc is  tensor(0.8663, device='cuda:0')\n",
      "[epoch:24,batch:329]:acc: 0.906818,loss:0.222219\n",
      "[epoch:24,batch:359]:acc: 0.905382,loss:0.222888\n",
      "[epoch:24,batch:389]:acc: 0.904647,loss:0.223414\n",
      "[epoch:24,batch:419]:acc: 0.903274,loss:0.225657\n",
      "[epoch:24,batch:449]:acc: 0.902361,loss:0.227362\n",
      "[epoch:24,batch:479]:acc: 0.901237,loss:0.228923\n",
      "[epoch:24,batch:509]:acc: 0.900797,loss:0.229586\n",
      "[epoch:24,batch:539]:acc: 0.900058,loss:0.230704\n",
      "[epoch:24,batch:569]:acc: 0.900164,loss:0.231755\n",
      "[epoch:24,batch:599]:acc: 0.899844,loss:0.232765\n",
      "[epoch:24,batch:599]: val_loss:0.361300,val_acc:0.864287,val_total:4539\n",
      "[epoch:24,batch:629]:acc: 0.900645,loss:0.231450\n",
      "[epoch:24,batch:659]:acc: 0.901278,loss:0.230839\n",
      "[epoch:24,batch:689]:acc: 0.901178,loss:0.231013\n",
      "[epoch:24,batch:719]:acc: 0.901215,loss:0.230561\n",
      "[epoch:24,batch:749]:acc: 0.901083,loss:0.230296\n",
      "[epoch:24,batch:779]:acc: 0.900921,loss:0.230408\n",
      "[epoch:24,batch:809]:acc: 0.900540,loss:0.231148\n",
      "[epoch:24,batch:839]:acc: 0.900372,loss:0.232027\n",
      "[epoch:24,batch:869]:acc: 0.900036,loss:0.232710\n",
      "[epoch:24,batch:899]:acc: 0.900174,loss:0.232699\n",
      "[epoch:24,batch:899]: val_loss:0.360910,val_acc:0.865829,val_total:4539\n",
      "[epoch:24,batch:929]:acc: 0.900034,loss:0.233481\n",
      "[epoch:24,batch:959]:acc: 0.899902,loss:0.233696\n",
      "[epoch:24,batch:989]:acc: 0.899779,loss:0.233857\n",
      "[epoch:24] :acc: 0.899770,loss:0.233969,lr:0.000100,patience:2\n",
      "[epoch:24]: val_loss:0.363062,val_acc:0.865169,\n",
      "Epoch 25/59\n",
      "----------\n",
      "lr desencd\n",
      "[epoch:25,batch:29]:acc: 0.920833,loss:0.214411\n",
      "[epoch:25,batch:59]:acc: 0.906771,loss:0.239686\n",
      "[epoch:25,batch:89]:acc: 0.904167,loss:0.242501\n",
      "[epoch:25,batch:119]:acc: 0.905208,loss:0.235210\n",
      "[epoch:25,batch:149]:acc: 0.905833,loss:0.230777\n",
      "[epoch:25,batch:179]:acc: 0.904167,loss:0.230942\n",
      "[epoch:25,batch:209]:acc: 0.906845,loss:0.226562\n",
      "[epoch:25,batch:239]:acc: 0.905599,loss:0.226740\n",
      "[epoch:25,batch:269]:acc: 0.903241,loss:0.231794\n",
      "[epoch:25,batch:299]:acc: 0.902188,loss:0.233447\n",
      "[epoch:25,batch:299]: val_loss:0.359893,val_acc:0.859881,val_total:4539\n",
      "[epoch:25,batch:329]:acc: 0.904261,loss:0.229794\n",
      "[epoch:25,batch:359]:acc: 0.904774,loss:0.228566\n",
      "[epoch:25,batch:389]:acc: 0.905369,loss:0.227807\n",
      "[epoch:25,batch:419]:acc: 0.906771,loss:0.225320\n",
      "[epoch:25,batch:449]:acc: 0.906528,loss:0.224599\n",
      "[epoch:25,batch:479]:acc: 0.907617,loss:0.222265\n",
      "[epoch:25,batch:509]:acc: 0.906863,loss:0.223326\n",
      "[epoch:25,batch:539]:acc: 0.907986,loss:0.221527\n",
      "[epoch:25,batch:569]:acc: 0.907895,loss:0.220977\n",
      "[epoch:25,batch:599]:acc: 0.908490,loss:0.219447\n",
      "[epoch:25,batch:599]: val_loss:0.360265,val_acc:0.860983,val_total:4539\n",
      "[epoch:25,batch:629]:acc: 0.909077,loss:0.218582\n",
      "[epoch:25,batch:659]:acc: 0.909186,loss:0.218740\n",
      "[epoch:25,batch:689]:acc: 0.908786,loss:0.219644\n",
      "[epoch:25,batch:719]:acc: 0.909245,loss:0.218777\n",
      "[epoch:25,batch:749]:acc: 0.909583,loss:0.218488\n",
      "[epoch:25,batch:779]:acc: 0.909135,loss:0.218281\n",
      "[epoch:25,batch:809]:acc: 0.909066,loss:0.218366\n",
      "[epoch:25,batch:839]:acc: 0.909115,loss:0.218767\n",
      "[epoch:25,batch:869]:acc: 0.909088,loss:0.218812\n",
      "[epoch:25,batch:899]:acc: 0.909028,loss:0.219105\n",
      "[epoch:25,batch:899]: val_loss:0.362155,val_acc:0.862745,val_total:4539\n",
      "[epoch:25,batch:929]:acc: 0.908871,loss:0.219314\n",
      "[epoch:25,batch:959]:acc: 0.909082,loss:0.218543\n",
      "[epoch:25,batch:989]:acc: 0.908744,loss:0.218739\n",
      "[epoch:25] :acc: 0.908756,loss:0.218795,lr:0.000020,patience:0\n",
      "[epoch:25]: val_loss:0.363633,val_acc:0.862745,\n",
      "Epoch 26/59\n",
      "----------\n",
      "[epoch:26,batch:29]:acc: 0.905208,loss:0.228834\n",
      "[epoch:26,batch:59]:acc: 0.893750,loss:0.240167\n",
      "[epoch:26,batch:89]:acc: 0.895833,loss:0.239297\n",
      "[epoch:26,batch:119]:acc: 0.893490,loss:0.241263\n",
      "[epoch:26,batch:149]:acc: 0.893333,loss:0.248479\n",
      "[epoch:26,batch:179]:acc: 0.893056,loss:0.249464\n",
      "[epoch:26,batch:209]:acc: 0.893750,loss:0.247379\n",
      "[epoch:26,batch:239]:acc: 0.893359,loss:0.250259\n",
      "[epoch:26,batch:269]:acc: 0.891204,loss:0.253151\n",
      "[epoch:26,batch:299]:acc: 0.890417,loss:0.255591\n",
      "[epoch:26,batch:299]: val_loss:0.361392,val_acc:0.863406,val_total:4539\n",
      "[epoch:26,batch:329]:acc: 0.890625,loss:0.254572\n",
      "[epoch:26,batch:359]:acc: 0.890104,loss:0.255294\n",
      "[epoch:26,batch:389]:acc: 0.890144,loss:0.255087\n",
      "[epoch:26,batch:419]:acc: 0.890402,loss:0.255357\n",
      "[epoch:26,batch:449]:acc: 0.888958,loss:0.257653\n",
      "[epoch:26,batch:479]:acc: 0.888477,loss:0.258015\n",
      "[epoch:26,batch:509]:acc: 0.890257,loss:0.256521\n",
      "[epoch:26,batch:539]:acc: 0.891030,loss:0.255103\n",
      "[epoch:26,batch:569]:acc: 0.890570,loss:0.255998\n",
      "[epoch:26,batch:599]:acc: 0.890000,loss:0.256980\n",
      "[epoch:26,batch:599]: val_loss:0.360296,val_acc:0.863406,val_total:4539\n",
      "[epoch:26,batch:629]:acc: 0.889980,loss:0.257276\n",
      "[epoch:26,batch:659]:acc: 0.889773,loss:0.257304\n",
      "[epoch:26,batch:689]:acc: 0.889764,loss:0.256810\n",
      "[epoch:26,batch:719]:acc: 0.890451,loss:0.255946\n",
      "[epoch:26,batch:749]:acc: 0.890208,loss:0.256134\n",
      "[epoch:26,batch:779]:acc: 0.890144,loss:0.256038\n",
      "[epoch:26,batch:809]:acc: 0.890278,loss:0.255809\n",
      "[epoch:26,batch:839]:acc: 0.890365,loss:0.255659\n",
      "[epoch:26,batch:869]:acc: 0.890876,loss:0.254539\n",
      "[epoch:26,batch:899]:acc: 0.890556,loss:0.254089\n",
      "[epoch:26,batch:899]: val_loss:0.358779,val_acc:0.862745,val_total:4539\n",
      "save new model loss,now loss is  0.35877910256385803\n",
      "[epoch:26,batch:929]:acc: 0.890591,loss:0.253814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:26,batch:959]:acc: 0.890755,loss:0.253670\n",
      "[epoch:26,batch:989]:acc: 0.890751,loss:0.253879\n",
      "[epoch:26] :acc: 0.890753,loss:0.255464,lr:0.000020,patience:0\n",
      "[epoch:26]: val_loss:0.369189,val_acc:0.860101,\n",
      "Epoch 27/59\n",
      "----------\n",
      "[epoch:27,batch:29]:acc: 0.895833,loss:0.234334\n",
      "[epoch:27,batch:59]:acc: 0.896875,loss:0.235567\n",
      "[epoch:27,batch:89]:acc: 0.891667,loss:0.246647\n",
      "[epoch:27,batch:119]:acc: 0.891667,loss:0.249157\n",
      "[epoch:27,batch:149]:acc: 0.892292,loss:0.249597\n",
      "[epoch:27,batch:179]:acc: 0.892535,loss:0.250566\n",
      "[epoch:27,batch:209]:acc: 0.891667,loss:0.250767\n",
      "[epoch:27,batch:239]:acc: 0.890755,loss:0.252361\n",
      "[epoch:27,batch:269]:acc: 0.890162,loss:0.252783\n",
      "[epoch:27,batch:299]:acc: 0.890312,loss:0.252026\n",
      "[epoch:27,batch:299]: val_loss:0.361916,val_acc:0.862304,val_total:4539\n",
      "[epoch:27,batch:329]:acc: 0.890057,loss:0.253942\n",
      "[epoch:27,batch:359]:acc: 0.891406,loss:0.251570\n",
      "[epoch:27,batch:389]:acc: 0.891827,loss:0.251546\n",
      "[epoch:27,batch:419]:acc: 0.891443,loss:0.252218\n",
      "[epoch:27,batch:449]:acc: 0.890833,loss:0.253179\n",
      "[epoch:27,batch:479]:acc: 0.890039,loss:0.254338\n",
      "[epoch:27,batch:509]:acc: 0.890196,loss:0.254435\n",
      "[epoch:27,batch:539]:acc: 0.889641,loss:0.256498\n",
      "[epoch:27,batch:569]:acc: 0.889803,loss:0.256780\n",
      "[epoch:27,batch:599]:acc: 0.890365,loss:0.255841\n",
      "[epoch:27,batch:599]: val_loss:0.361601,val_acc:0.862084,val_total:4539\n",
      "[epoch:27,batch:629]:acc: 0.890972,loss:0.255140\n",
      "[epoch:27,batch:659]:acc: 0.891098,loss:0.254792\n",
      "[epoch:27,batch:689]:acc: 0.891033,loss:0.255397\n",
      "[epoch:27,batch:719]:acc: 0.890061,loss:0.255830\n",
      "[epoch:27,batch:749]:acc: 0.890500,loss:0.256133\n",
      "[epoch:27,batch:779]:acc: 0.890825,loss:0.256273\n",
      "[epoch:27,batch:809]:acc: 0.890934,loss:0.256741\n",
      "[epoch:27,batch:839]:acc: 0.890699,loss:0.257061\n",
      "[epoch:27,batch:869]:acc: 0.891128,loss:0.255956\n",
      "[epoch:27,batch:899]:acc: 0.890833,loss:0.255998\n",
      "[epoch:27,batch:899]: val_loss:0.361884,val_acc:0.864948,val_total:4539\n",
      "[epoch:27,batch:929]:acc: 0.890323,loss:0.256270\n",
      "[epoch:27,batch:959]:acc: 0.890592,loss:0.256409\n",
      "[epoch:27,batch:989]:acc: 0.890909,loss:0.255816\n",
      "[epoch:27] :acc: 0.890847,loss:0.255960,lr:0.000020,patience:1\n",
      "[epoch:27]: val_loss:0.364362,val_acc:0.859661,\n",
      "Epoch 28/59\n",
      "----------\n",
      "[epoch:28,batch:29]:acc: 0.900000,loss:0.237193\n",
      "[epoch:28,batch:59]:acc: 0.893229,loss:0.242780\n",
      "[epoch:28,batch:89]:acc: 0.887153,loss:0.245063\n",
      "[epoch:28,batch:119]:acc: 0.884375,loss:0.253615\n",
      "[epoch:28,batch:149]:acc: 0.886458,loss:0.248965\n",
      "[epoch:28,batch:179]:acc: 0.884201,loss:0.256231\n",
      "[epoch:28,batch:209]:acc: 0.886458,loss:0.254199\n",
      "[epoch:28,batch:239]:acc: 0.887370,loss:0.253138\n",
      "[epoch:28,batch:269]:acc: 0.887847,loss:0.253856\n",
      "[epoch:28,batch:299]:acc: 0.889792,loss:0.251998\n",
      "[epoch:28,batch:299]: val_loss:0.360430,val_acc:0.865169,val_total:4539\n",
      "[epoch:28,batch:329]:acc: 0.890909,loss:0.250007\n",
      "[epoch:28,batch:359]:acc: 0.891319,loss:0.249145\n",
      "[epoch:28,batch:389]:acc: 0.891667,loss:0.249132\n",
      "[epoch:28,batch:419]:acc: 0.891071,loss:0.249125\n",
      "[epoch:28,batch:449]:acc: 0.890694,loss:0.250131\n",
      "[epoch:28,batch:479]:acc: 0.890104,loss:0.252000\n",
      "[epoch:28,batch:509]:acc: 0.890257,loss:0.251296\n",
      "[epoch:28,batch:539]:acc: 0.890509,loss:0.250428\n",
      "[epoch:28,batch:569]:acc: 0.891228,loss:0.249339\n",
      "[epoch:28,batch:599]:acc: 0.890469,loss:0.250634\n",
      "[epoch:28,batch:599]: val_loss:0.359841,val_acc:0.862745,val_total:4539\n",
      "[epoch:28,batch:629]:acc: 0.890873,loss:0.248843\n",
      "[epoch:28,batch:659]:acc: 0.891619,loss:0.248003\n",
      "[epoch:28,batch:689]:acc: 0.892120,loss:0.247476\n",
      "[epoch:28,batch:719]:acc: 0.891840,loss:0.247831\n",
      "[epoch:28,batch:749]:acc: 0.891917,loss:0.248062\n",
      "[epoch:28,batch:779]:acc: 0.891506,loss:0.248154\n",
      "[epoch:28,batch:809]:acc: 0.891551,loss:0.247753\n",
      "[epoch:28,batch:839]:acc: 0.891667,loss:0.247635\n",
      "[epoch:28,batch:869]:acc: 0.891523,loss:0.247960\n",
      "[epoch:28,batch:899]:acc: 0.891771,loss:0.248102\n",
      "[epoch:28,batch:899]: val_loss:0.360447,val_acc:0.865389,val_total:4539\n",
      "[epoch:28,batch:929]:acc: 0.891700,loss:0.248309\n",
      "[epoch:28,batch:959]:acc: 0.891927,loss:0.247820\n",
      "[epoch:28,batch:989]:acc: 0.891667,loss:0.248670\n",
      "[epoch:28] :acc: 0.891572,loss:0.248887,lr:0.000020,patience:2\n",
      "[epoch:28]: val_loss:0.360500,val_acc:0.861423,\n",
      "Epoch 29/59\n",
      "----------\n",
      "lr desencd\n",
      "[epoch:29,batch:29]:acc: 0.869792,loss:0.272295\n",
      "[epoch:29,batch:59]:acc: 0.872917,loss:0.271800\n",
      "[epoch:29,batch:89]:acc: 0.884722,loss:0.258261\n",
      "[epoch:29,batch:119]:acc: 0.891146,loss:0.247256\n",
      "[epoch:29,batch:149]:acc: 0.892917,loss:0.247597\n",
      "[epoch:29,batch:179]:acc: 0.893750,loss:0.243701\n",
      "[epoch:29,batch:209]:acc: 0.892411,loss:0.246881\n",
      "[epoch:29,batch:239]:acc: 0.893620,loss:0.244593\n",
      "[epoch:29,batch:269]:acc: 0.895139,loss:0.244462\n",
      "[epoch:29,batch:299]:acc: 0.895000,loss:0.244659\n",
      "[epoch:29,batch:299]: val_loss:0.363541,val_acc:0.863186,val_total:4539\n",
      "[epoch:29,batch:329]:acc: 0.895265,loss:0.245979\n",
      "[epoch:29,batch:359]:acc: 0.896181,loss:0.245174\n",
      "[epoch:29,batch:389]:acc: 0.895112,loss:0.246454\n",
      "[epoch:29,batch:419]:acc: 0.894866,loss:0.245469\n",
      "[epoch:29,batch:449]:acc: 0.895139,loss:0.244390\n",
      "[epoch:29,batch:479]:acc: 0.895378,loss:0.244435\n",
      "[epoch:29,batch:509]:acc: 0.895282,loss:0.245216\n",
      "[epoch:29,batch:539]:acc: 0.895081,loss:0.245581\n",
      "[epoch:29,batch:569]:acc: 0.894682,loss:0.246751\n",
      "[epoch:29,batch:599]:acc: 0.894167,loss:0.247666\n",
      "[epoch:29,batch:599]: val_loss:0.360516,val_acc:0.864287,val_total:4539\n",
      "[epoch:29,batch:629]:acc: 0.893899,loss:0.248266\n",
      "[epoch:29,batch:659]:acc: 0.893750,loss:0.248796\n",
      "[epoch:29,batch:689]:acc: 0.894429,loss:0.247862\n",
      "[epoch:29,batch:719]:acc: 0.894444,loss:0.247847\n",
      "[epoch:29,batch:749]:acc: 0.895083,loss:0.246915\n",
      "[epoch:29,batch:779]:acc: 0.894832,loss:0.247144\n",
      "[epoch:29,batch:809]:acc: 0.894522,loss:0.247060\n",
      "[epoch:29,batch:839]:acc: 0.894606,loss:0.246526\n",
      "[epoch:29,batch:869]:acc: 0.895115,loss:0.245915\n",
      "[epoch:29,batch:899]:acc: 0.894479,loss:0.246419\n",
      "[epoch:29,batch:899]: val_loss:0.360781,val_acc:0.864508,val_total:4539\n",
      "[epoch:29,batch:929]:acc: 0.894489,loss:0.246073\n",
      "[epoch:29,batch:959]:acc: 0.893978,loss:0.247533\n",
      "[epoch:29,batch:989]:acc: 0.893845,loss:0.247476\n",
      "[epoch:29] :acc: 0.893842,loss:0.247507,lr:0.000004,patience:0\n",
      "[epoch:29]: val_loss:0.362764,val_acc:0.860322,\n",
      "Epoch 30/59\n",
      "----------\n",
      "[epoch:30,batch:29]:acc: 0.879167,loss:0.296478\n",
      "[epoch:30,batch:59]:acc: 0.893750,loss:0.276567\n",
      "[epoch:30,batch:89]:acc: 0.893403,loss:0.265009\n",
      "[epoch:30,batch:119]:acc: 0.891667,loss:0.263628\n",
      "[epoch:30,batch:149]:acc: 0.891458,loss:0.259406\n",
      "[epoch:30,batch:179]:acc: 0.892014,loss:0.256738\n",
      "[epoch:30,batch:209]:acc: 0.893899,loss:0.255920\n",
      "[epoch:30,batch:239]:acc: 0.895182,loss:0.253670\n",
      "[epoch:30,batch:269]:acc: 0.892708,loss:0.255564\n",
      "[epoch:30,batch:299]:acc: 0.894167,loss:0.252065\n",
      "[epoch:30,batch:299]: val_loss:0.362203,val_acc:0.862525,val_total:4539\n",
      "[epoch:30,batch:329]:acc: 0.894129,loss:0.250794\n",
      "[epoch:30,batch:359]:acc: 0.894271,loss:0.250147\n",
      "[epoch:30,batch:389]:acc: 0.894551,loss:0.249266\n",
      "[epoch:30,batch:419]:acc: 0.892932,loss:0.251762\n",
      "[epoch:30,batch:449]:acc: 0.892083,loss:0.251628\n",
      "[epoch:30,batch:479]:acc: 0.891146,loss:0.252628\n",
      "[epoch:30,batch:509]:acc: 0.891973,loss:0.251834\n",
      "[epoch:30,batch:539]:acc: 0.891609,loss:0.253400\n",
      "[epoch:30,batch:569]:acc: 0.891557,loss:0.253921\n",
      "[epoch:30,batch:599]:acc: 0.891823,loss:0.252682\n",
      "[epoch:30,batch:599]: val_loss:0.361283,val_acc:0.866711,val_total:4539\n",
      "save new model acc,now acc is  tensor(0.8667, device='cuda:0')\n",
      "[epoch:30,batch:629]:acc: 0.892262,loss:0.252401\n",
      "[epoch:30,batch:659]:acc: 0.892803,loss:0.251855\n",
      "[epoch:30,batch:689]:acc: 0.893252,loss:0.251650\n",
      "[epoch:30,batch:719]:acc: 0.893880,loss:0.251089\n",
      "[epoch:30,batch:749]:acc: 0.893833,loss:0.250217\n",
      "[epoch:30,batch:779]:acc: 0.893910,loss:0.249209\n",
      "[epoch:30,batch:809]:acc: 0.893789,loss:0.249533\n",
      "[epoch:30,batch:839]:acc: 0.893936,loss:0.249145\n",
      "[epoch:30,batch:869]:acc: 0.893858,loss:0.248679\n",
      "[epoch:30,batch:899]:acc: 0.893854,loss:0.248656\n",
      "[epoch:30,batch:899]: val_loss:0.363540,val_acc:0.862084,val_total:4539\n",
      "[epoch:30,batch:929]:acc: 0.893784,loss:0.248603\n",
      "[epoch:30,batch:959]:acc: 0.893457,loss:0.248442\n",
      "[epoch:30,batch:989]:acc: 0.893308,loss:0.247754\n",
      "[epoch:30] :acc: 0.893338,loss:0.247984,lr:0.000004,patience:1\n",
      "[epoch:30]: val_loss:0.362746,val_acc:0.861864,\n",
      "Epoch 31/59\n",
      "----------\n",
      "[epoch:31,batch:29]:acc: 0.889583,loss:0.277777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:31,batch:59]:acc: 0.886458,loss:0.258226\n",
      "[epoch:31,batch:89]:acc: 0.883681,loss:0.266835\n",
      "[epoch:31,batch:119]:acc: 0.889583,loss:0.259451\n",
      "[epoch:31,batch:149]:acc: 0.892500,loss:0.253351\n",
      "[epoch:31,batch:179]:acc: 0.891146,loss:0.254871\n",
      "[epoch:31,batch:209]:acc: 0.890179,loss:0.254385\n",
      "[epoch:31,batch:239]:acc: 0.891797,loss:0.251262\n",
      "[epoch:31,batch:269]:acc: 0.893056,loss:0.248413\n",
      "[epoch:31,batch:299]:acc: 0.891458,loss:0.251650\n",
      "[epoch:31,batch:299]: val_loss:0.361629,val_acc:0.864948,val_total:4539\n",
      "[epoch:31,batch:329]:acc: 0.892235,loss:0.250076\n",
      "[epoch:31,batch:359]:acc: 0.891233,loss:0.251308\n",
      "[epoch:31,batch:389]:acc: 0.889984,loss:0.253836\n",
      "[epoch:31,batch:419]:acc: 0.890923,loss:0.252119\n",
      "[epoch:31,batch:449]:acc: 0.891528,loss:0.250367\n",
      "[epoch:31,batch:479]:acc: 0.891536,loss:0.249474\n",
      "[epoch:31,batch:509]:acc: 0.893076,loss:0.246739\n",
      "[epoch:31,batch:539]:acc: 0.893519,loss:0.246331\n",
      "[epoch:31,batch:569]:acc: 0.892050,loss:0.249392\n",
      "[epoch:31,batch:599]:acc: 0.892344,loss:0.249423\n",
      "[epoch:31,batch:599]: val_loss:0.361872,val_acc:0.861423,val_total:4539\n",
      "[epoch:31,batch:629]:acc: 0.893304,loss:0.248254\n",
      "[epoch:31,batch:659]:acc: 0.893750,loss:0.248264\n",
      "[epoch:31,batch:689]:acc: 0.894475,loss:0.247458\n",
      "[epoch:31,batch:719]:acc: 0.894358,loss:0.247264\n",
      "[epoch:31,batch:749]:acc: 0.894625,loss:0.246365\n",
      "[epoch:31,batch:779]:acc: 0.894591,loss:0.246579\n",
      "[epoch:31,batch:809]:acc: 0.894059,loss:0.246688\n",
      "[epoch:31,batch:839]:acc: 0.894792,loss:0.245364\n",
      "[epoch:31,batch:869]:acc: 0.894684,loss:0.245957\n",
      "[epoch:31,batch:899]:acc: 0.894792,loss:0.245625\n",
      "[epoch:31,batch:899]: val_loss:0.361375,val_acc:0.862525,val_total:4539\n",
      "[epoch:31,batch:929]:acc: 0.894624,loss:0.246112\n",
      "[epoch:31,batch:959]:acc: 0.894141,loss:0.246504\n",
      "[epoch:31,batch:989]:acc: 0.894192,loss:0.246292\n",
      "[epoch:31] :acc: 0.894032,loss:0.247224,lr:0.000004,patience:2\n",
      "[epoch:31]: val_loss:0.365131,val_acc:0.858339,\n",
      "Epoch 32/59\n",
      "----------\n",
      "lr desencd\n",
      "[epoch:32,batch:29]:acc: 0.880208,loss:0.269006\n",
      "[epoch:32,batch:59]:acc: 0.888542,loss:0.255327\n",
      "[epoch:32,batch:89]:acc: 0.885764,loss:0.257130\n",
      "[epoch:32,batch:119]:acc: 0.887240,loss:0.254557\n",
      "[epoch:32,batch:149]:acc: 0.889375,loss:0.247965\n",
      "[epoch:32,batch:179]:acc: 0.889583,loss:0.247669\n",
      "[epoch:32,batch:209]:acc: 0.890774,loss:0.249759\n",
      "[epoch:32,batch:239]:acc: 0.889974,loss:0.253411\n",
      "[epoch:32,batch:269]:acc: 0.889699,loss:0.253498\n",
      "[epoch:32,batch:299]:acc: 0.889167,loss:0.255395\n",
      "[epoch:32,batch:299]: val_loss:0.361024,val_acc:0.864728,val_total:4539\n",
      "[epoch:32,batch:329]:acc: 0.889678,loss:0.255429\n",
      "[epoch:32,batch:359]:acc: 0.891319,loss:0.253836\n",
      "[epoch:32,batch:389]:acc: 0.891426,loss:0.255336\n",
      "[epoch:32,batch:419]:acc: 0.891890,loss:0.254386\n",
      "[epoch:32,batch:449]:acc: 0.891528,loss:0.254888\n",
      "[epoch:32,batch:479]:acc: 0.891081,loss:0.255507\n",
      "[epoch:32,batch:509]:acc: 0.891973,loss:0.253826\n",
      "[epoch:32,batch:539]:acc: 0.891725,loss:0.253817\n",
      "[epoch:32,batch:569]:acc: 0.891393,loss:0.253927\n",
      "[epoch:32,batch:599]:acc: 0.891198,loss:0.253589\n",
      "[epoch:32,batch:599]: val_loss:0.362830,val_acc:0.864067,val_total:4539\n",
      "[epoch:32,batch:629]:acc: 0.891319,loss:0.253846\n",
      "[epoch:32,batch:659]:acc: 0.891241,loss:0.253170\n",
      "[epoch:32,batch:689]:acc: 0.890399,loss:0.254855\n",
      "[epoch:32,batch:719]:acc: 0.889844,loss:0.254846\n",
      "[epoch:32,batch:749]:acc: 0.890333,loss:0.253425\n",
      "[epoch:32,batch:779]:acc: 0.890104,loss:0.253861\n",
      "[epoch:32,batch:809]:acc: 0.889738,loss:0.254409\n",
      "[epoch:32,batch:839]:acc: 0.889509,loss:0.254923\n",
      "[epoch:32,batch:869]:acc: 0.889583,loss:0.254533\n",
      "[epoch:32,batch:899]:acc: 0.889201,loss:0.254745\n",
      "[epoch:32,batch:899]: val_loss:0.360606,val_acc:0.864067,val_total:4539\n",
      "[epoch:32,batch:929]:acc: 0.889180,loss:0.254540\n",
      "[epoch:32,batch:959]:acc: 0.889225,loss:0.254601\n",
      "[epoch:32,batch:989]:acc: 0.889836,loss:0.254074\n",
      "[epoch:32] :acc: 0.889870,loss:0.253920,lr:0.000001,patience:0\n",
      "[epoch:32]: val_loss:0.361486,val_acc:0.862304,\n",
      "Epoch 33/59\n",
      "----------\n",
      "[epoch:33,batch:29]:acc: 0.885417,loss:0.267326\n",
      "[epoch:33,batch:59]:acc: 0.888542,loss:0.268179\n",
      "[epoch:33,batch:89]:acc: 0.892361,loss:0.253712\n",
      "[epoch:33,batch:119]:acc: 0.893750,loss:0.254383\n",
      "[epoch:33,batch:149]:acc: 0.891458,loss:0.254834\n",
      "[epoch:33,batch:179]:acc: 0.892882,loss:0.251719\n",
      "[epoch:33,batch:209]:acc: 0.894345,loss:0.250079\n",
      "[epoch:33,batch:239]:acc: 0.893620,loss:0.250969\n",
      "[epoch:33,batch:269]:acc: 0.896065,loss:0.248564\n",
      "[epoch:33,batch:299]:acc: 0.894167,loss:0.252178\n",
      "[epoch:33,batch:299]: val_loss:0.360389,val_acc:0.859220,val_total:4539\n",
      "[epoch:33,batch:329]:acc: 0.894413,loss:0.251643\n",
      "[epoch:33,batch:359]:acc: 0.894010,loss:0.252241\n",
      "[epoch:33,batch:389]:acc: 0.895192,loss:0.250669\n",
      "[epoch:33,batch:419]:acc: 0.894122,loss:0.252836\n",
      "[epoch:33,batch:449]:acc: 0.894514,loss:0.252474\n",
      "[epoch:33,batch:479]:acc: 0.893294,loss:0.254298\n",
      "[epoch:33,batch:509]:acc: 0.892402,loss:0.254905\n",
      "[epoch:33,batch:539]:acc: 0.892245,loss:0.255244\n",
      "[epoch:33,batch:569]:acc: 0.892160,loss:0.254654\n",
      "[epoch:33,batch:599]:acc: 0.892292,loss:0.254645\n",
      "[epoch:33,batch:599]: val_loss:0.360083,val_acc:0.864508,val_total:4539\n",
      "[epoch:33,batch:629]:acc: 0.892163,loss:0.254845\n",
      "[epoch:33,batch:659]:acc: 0.892235,loss:0.255674\n",
      "[epoch:33,batch:689]:acc: 0.891803,loss:0.256368\n",
      "[epoch:33,batch:719]:acc: 0.891884,loss:0.255255\n",
      "[epoch:33,batch:749]:acc: 0.892292,loss:0.254683\n",
      "[epoch:33,batch:779]:acc: 0.892468,loss:0.254265\n",
      "[epoch:33,batch:809]:acc: 0.893094,loss:0.253808\n",
      "[epoch:33,batch:839]:acc: 0.892448,loss:0.255336\n",
      "[epoch:33,batch:869]:acc: 0.892313,loss:0.254870\n",
      "[epoch:33,batch:899]:acc: 0.892257,loss:0.254576\n",
      "[epoch:33,batch:899]: val_loss:0.360157,val_acc:0.863186,val_total:4539\n",
      "[epoch:33,batch:929]:acc: 0.892103,loss:0.254695\n",
      "[epoch:33,batch:959]:acc: 0.892318,loss:0.253947\n",
      "[epoch:33,batch:989]:acc: 0.892172,loss:0.254182\n",
      "[epoch:33] :acc: 0.892171,loss:0.253928,lr:0.000001,patience:1\n",
      "[epoch:33]: val_loss:0.362429,val_acc:0.859440,\n",
      "Epoch 34/59\n",
      "----------\n",
      "[epoch:34,batch:29]:acc: 0.884375,loss:0.271566\n",
      "[epoch:34,batch:59]:acc: 0.894271,loss:0.261251\n",
      "[epoch:34,batch:89]:acc: 0.887847,loss:0.268607\n",
      "[epoch:34,batch:119]:acc: 0.886719,loss:0.265613\n",
      "[epoch:34,batch:149]:acc: 0.882500,loss:0.272274\n",
      "[epoch:34,batch:179]:acc: 0.883681,loss:0.267986\n",
      "[epoch:34,batch:209]:acc: 0.883929,loss:0.267728\n",
      "[epoch:34,batch:239]:acc: 0.885156,loss:0.266449\n",
      "[epoch:34,batch:269]:acc: 0.886227,loss:0.264857\n",
      "[epoch:34,batch:299]:acc: 0.887708,loss:0.261601\n",
      "[epoch:34,batch:299]: val_loss:0.360990,val_acc:0.862745,val_total:4539\n",
      "[epoch:34,batch:329]:acc: 0.888163,loss:0.260615\n",
      "[epoch:34,batch:359]:acc: 0.889323,loss:0.257762\n",
      "[epoch:34,batch:389]:acc: 0.889183,loss:0.257781\n",
      "[epoch:34,batch:419]:acc: 0.888467,loss:0.258015\n",
      "[epoch:34,batch:449]:acc: 0.889028,loss:0.257245\n",
      "[epoch:34,batch:479]:acc: 0.888802,loss:0.257303\n",
      "[epoch:34,batch:509]:acc: 0.888971,loss:0.256485\n",
      "[epoch:34,batch:539]:acc: 0.888715,loss:0.255409\n",
      "[epoch:34,batch:569]:acc: 0.888816,loss:0.255547\n",
      "[epoch:34,batch:599]:acc: 0.888229,loss:0.256668\n",
      "[epoch:34,batch:599]: val_loss:0.359738,val_acc:0.862525,val_total:4539\n",
      "[epoch:34,batch:629]:acc: 0.889187,loss:0.254648\n",
      "[epoch:34,batch:659]:acc: 0.888778,loss:0.254934\n",
      "[epoch:34,batch:689]:acc: 0.889176,loss:0.254596\n",
      "[epoch:34,batch:719]:acc: 0.889106,loss:0.254926\n",
      "[epoch:34,batch:749]:acc: 0.889500,loss:0.254949\n",
      "[epoch:34,batch:779]:acc: 0.889984,loss:0.255097\n",
      "[epoch:34,batch:809]:acc: 0.890278,loss:0.255164\n",
      "[epoch:34,batch:839]:acc: 0.890885,loss:0.254019\n",
      "[epoch:34,batch:869]:acc: 0.890769,loss:0.254192\n",
      "[epoch:34,batch:899]:acc: 0.890521,loss:0.254442\n",
      "[epoch:34,batch:899]: val_loss:0.361621,val_acc:0.863626,val_total:4539\n",
      "[epoch:34,batch:929]:acc: 0.890188,loss:0.254643\n",
      "[epoch:34,batch:959]:acc: 0.890072,loss:0.254894\n",
      "[epoch:34,batch:989]:acc: 0.890467,loss:0.253887\n",
      "[epoch:34] :acc: 0.890437,loss:0.254036,lr:0.000001,patience:2\n",
      "[epoch:34]: val_loss:0.358454,val_acc:0.861643,\n",
      "save new model loss,now loss is  0.3584539592266083\n",
      "Epoch 35/59\n",
      "----------\n",
      "[epoch:35,batch:29]:acc: 0.894792,loss:0.260969\n",
      "[epoch:35,batch:59]:acc: 0.893229,loss:0.265602\n",
      "[epoch:35,batch:89]:acc: 0.894097,loss:0.261728\n",
      "[epoch:35,batch:119]:acc: 0.890625,loss:0.262803\n",
      "[epoch:35,batch:149]:acc: 0.889583,loss:0.259246\n",
      "[epoch:35,batch:179]:acc: 0.890104,loss:0.256847\n",
      "[epoch:35,batch:209]:acc: 0.891518,loss:0.253678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:35,batch:239]:acc: 0.890885,loss:0.254772\n",
      "[epoch:35,batch:269]:acc: 0.890278,loss:0.256499\n",
      "[epoch:35,batch:299]:acc: 0.890521,loss:0.254855\n",
      "[epoch:35,batch:299]: val_loss:0.361265,val_acc:0.862965,val_total:4539\n",
      "[epoch:35,batch:329]:acc: 0.890625,loss:0.254049\n",
      "[epoch:35,batch:359]:acc: 0.891406,loss:0.252584\n",
      "[epoch:35,batch:389]:acc: 0.891587,loss:0.252822\n",
      "[epoch:35,batch:419]:acc: 0.891815,loss:0.252713\n",
      "[epoch:35,batch:449]:acc: 0.891667,loss:0.252892\n",
      "[epoch:35,batch:479]:acc: 0.890495,loss:0.254079\n",
      "[epoch:35,batch:509]:acc: 0.890564,loss:0.253017\n",
      "[epoch:35,batch:539]:acc: 0.889525,loss:0.254952\n",
      "[epoch:35,batch:569]:acc: 0.889090,loss:0.255538\n",
      "[epoch:35,batch:599]:acc: 0.889010,loss:0.254361\n",
      "[epoch:35,batch:599]: val_loss:0.360334,val_acc:0.864067,val_total:4539\n",
      "[epoch:35,batch:629]:acc: 0.888542,loss:0.254251\n",
      "[epoch:35,batch:659]:acc: 0.888400,loss:0.254292\n",
      "[epoch:35,batch:689]:acc: 0.888089,loss:0.255411\n",
      "[epoch:35,batch:719]:acc: 0.888238,loss:0.255583\n",
      "[epoch:35,batch:749]:acc: 0.888042,loss:0.256497\n",
      "[epoch:35,batch:779]:acc: 0.887821,loss:0.256327\n",
      "[epoch:35,batch:809]:acc: 0.888117,loss:0.256191\n",
      "[epoch:35,batch:839]:acc: 0.888393,loss:0.255134\n",
      "[epoch:35,batch:869]:acc: 0.888506,loss:0.254291\n",
      "[epoch:35,batch:899]:acc: 0.888542,loss:0.254018\n",
      "[epoch:35,batch:899]: val_loss:0.359399,val_acc:0.863847,val_total:4539\n",
      "[epoch:35,batch:929]:acc: 0.888642,loss:0.254253\n",
      "[epoch:35,batch:959]:acc: 0.888639,loss:0.254117\n",
      "[epoch:35,batch:989]:acc: 0.888510,loss:0.255112\n",
      "[epoch:35] :acc: 0.888514,loss:0.254985,lr:0.000001,patience:0\n",
      "[epoch:35]: val_loss:0.364873,val_acc:0.860983,\n",
      "Epoch 36/59\n",
      "----------\n",
      "[epoch:36,batch:29]:acc: 0.891667,loss:0.265640\n",
      "[epoch:36,batch:59]:acc: 0.889583,loss:0.263591\n",
      "[epoch:36,batch:89]:acc: 0.887500,loss:0.258224\n",
      "[epoch:36,batch:119]:acc: 0.886198,loss:0.257730\n",
      "[epoch:36,batch:149]:acc: 0.885000,loss:0.258934\n",
      "[epoch:36,batch:179]:acc: 0.885417,loss:0.260683\n",
      "[epoch:36,batch:209]:acc: 0.886458,loss:0.258620\n",
      "[epoch:36,batch:239]:acc: 0.887630,loss:0.255004\n",
      "[epoch:36,batch:269]:acc: 0.888542,loss:0.254882\n",
      "[epoch:36,batch:299]:acc: 0.888854,loss:0.255639\n"
     ]
    }
   ],
   "source": [
    "TrainWithRawData('../model/NasnetMobile/2018-11-01_acc_best.pth',60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Conda_Env_Pytorch]",
   "language": "python",
   "name": "conda-env-Conda_Env_Pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
